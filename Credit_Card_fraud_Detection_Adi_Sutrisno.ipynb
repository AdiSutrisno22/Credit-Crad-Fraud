{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit Card fraud Detection_Adi Sutrisno",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "0Ku8Y8gIvpp9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective\n",
        "\n",
        "\n",
        "\n",
        "*   Membuat sebuah model prekstif untuk mendeteksi fraud\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N-HRCl7zvx3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instruction\n",
        "\n",
        "\n",
        "* Data understanding : Analisis data kemudian jelaskan<br>\n",
        "* Data preparation : jelaskan alasan melakukan suatu perubahan pada data<br>\n",
        "* Modeling : jelaskan alasan memilih suatu algoritma untuk dijadikan model<br>\n",
        "* Evaluasi : jelaskan evaluasi dari algoritma yang digunakan<br>\n",
        "* Insight : jelaskan insight yang didapatkan<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "qNtno2aEwPn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from plotly.subplots import make_subplots\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import make_scorer"
      ],
      "metadata": {
        "id": "NB2MMER7xIHQ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Describe Data"
      ],
      "metadata": {
        "id": "O22NrNz8wnwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "IwY8Qs5kwtMU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "kwu-r9qBnq1S",
        "outputId": "5dbcc3eb-b4ca-403b-b9c8-504f60ccef89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Row 284807  ,Total Feature 31 \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a243b99-b228-4160-af97-5f30deca4e70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a243b99-b228-4160-af97-5f30deca4e70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5a243b99-b228-4160-af97-5f30deca4e70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5a243b99-b228-4160-af97-5f30deca4e70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df = pd.read_csv('creditcard.csv')\n",
        "print('Total Row', df.shape[0], ' ,Total Feature', df.shape[1],'\\n')\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terdapat 284.807 baris dan 31 kolom. Data  merupakan data asli sebuah perusahaan, maka feature di rubah menjadi V1-V28. \n",
        "Target data adalah kolom class, dimana \n",
        "\n",
        "*   Nilai 1 adalah Fraud\n",
        "*   Nilai 0 adalah Bukan Fraud\n",
        "\n"
      ],
      "metadata": {
        "id": "rypiWOuExT4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Desccription"
      ],
      "metadata": {
        "id": "AwLgZXhfysnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yITQiNLMw_xO",
        "outputId": "2d157fea-d14d-4499-ec28-6fba4013e7bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "wv0EVOvz2pmA",
        "outputId": "3fb59209-7dba-45c8-b094-38ebdf3b5dee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Time            V1            V2            V3            V4  \\\n",
              "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
              "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
              "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
              "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
              "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
              "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
              "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
              "\n",
              "                 V5            V6            V7            V8            V9  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
              "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
              "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
              "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
              "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
              "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
              "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
              "\n",
              "       ...           V21           V22           V23           V24  \\\n",
              "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
              "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
              "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
              "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
              "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
              "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
              "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
              "\n",
              "                V25           V26           V27           V28         Amount  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
              "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
              "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
              "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
              "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
              "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
              "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
              "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
              "\n",
              "               Class  \n",
              "count  284807.000000  \n",
              "mean        0.001727  \n",
              "std         0.041527  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         0.000000  \n",
              "max         1.000000  \n",
              "\n",
              "[8 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1a82a09-ddf5-4d17-aa15-dc6690d99221\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>1.168375e-15</td>\n",
              "      <td>3.416908e-16</td>\n",
              "      <td>-1.379537e-15</td>\n",
              "      <td>2.074095e-15</td>\n",
              "      <td>9.604066e-16</td>\n",
              "      <td>1.487313e-15</td>\n",
              "      <td>-5.556467e-16</td>\n",
              "      <td>1.213481e-16</td>\n",
              "      <td>-2.406331e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.654067e-16</td>\n",
              "      <td>-3.568593e-16</td>\n",
              "      <td>2.578648e-16</td>\n",
              "      <td>4.473266e-15</td>\n",
              "      <td>5.340915e-16</td>\n",
              "      <td>1.683437e-15</td>\n",
              "      <td>-3.660091e-16</td>\n",
              "      <td>-1.227390e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1a82a09-ddf5-4d17-aa15-dc6690d99221')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1a82a09-ddf5-4d17-aa15-dc6690d99221 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1a82a09-ddf5-4d17-aa15-dc6690d99221');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berdasarkan data pada kolom  *Time* terdapat 284.807 transaksi yang terjadi selama 172.792 detik atau selama 2 hari.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AdZTH__M21DL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "T6qFO9cAy-r6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handle Missing Value"
      ],
      "metadata": {
        "id": "vgReOBz74ciy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h_izc_lywD-",
        "outputId": "4d2196f1-f947-42e7-b60e-8cfbc7e967fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      0\n",
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       0\n",
              "V11       0\n",
              "V12       0\n",
              "V13       0\n",
              "V14       0\n",
              "V15       0\n",
              "V16       0\n",
              "V17       0\n",
              "V18       0\n",
              "V19       0\n",
              "V20       0\n",
              "V21       0\n",
              "V22       0\n",
              "V23       0\n",
              "V24       0\n",
              "V25       0\n",
              "V26       0\n",
              "V27       0\n",
              "V28       0\n",
              "Amount    0\n",
              "Class     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handle Duplicated Data"
      ],
      "metadata": {
        "id": "G_bCxw2e5EYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKIosSYC0D6M",
        "outputId": "aede1f8f-b428-4648-80c9-637149abeb5a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1081"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tidak ada missing value dan terdapat 1081 baris duplicate. Maka hapus data duplicate"
      ],
      "metadata": {
        "id": "I8wtC4Ru0JsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "print (\"Shape of data frame : \",df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9gdtUzk0HU3",
        "outputId": "5e41f633-3889-4509-926b-96ae05b0ee2b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of data frame :  (283726, 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examine the class imbalance"
      ],
      "metadata": {
        "id": "P4_ifC4c5nnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8swy5FgH0qCn",
        "outputId": "9934371d-8d7b-4c48-8f9e-8bd2d26084b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    283253\n",
              "1       473\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "group = df.groupby('Class')['Time'].count()\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(name='counts',x=group.index, y=group.values, marker_line_color='black', marker_line_width=2,\n",
        "                     text=group.values,textposition='outside'))\n",
        "fig.update_yaxes(title_text='Number of Cases')\n",
        "fig.update_xaxes(title_text='Case',nticks=3)\n",
        "fig.update_layout(template='seaborn',hovermode='closest',title='Number of Fraud vs Non-Fraud Cases',\n",
        "                 width=700,height=400,xaxis=dict(mirror=True,linecolor='black',linewidth=2),\n",
        "                 yaxis=dict(mirror=True,linecolor='black',linewidth=2),margin=dict(t=50,b=0,l=70,r=0))\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "T2KH_FwN6Yem",
        "outputId": "c4475dcb-50a3-42fa-9bc6-a9d2c36a397b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"9d6cf9fe-470e-4df9-84ad-5b98213b4521\" class=\"plotly-graph-div\" style=\"height:400px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9d6cf9fe-470e-4df9-84ad-5b98213b4521\")) {                    Plotly.newPlot(                        \"9d6cf9fe-470e-4df9-84ad-5b98213b4521\",                        [{\"marker\":{\"line\":{\"color\":\"black\",\"width\":2}},\"name\":\"counts\",\"text\":[283253.0,473.0],\"textposition\":\"outside\",\"x\":[0,1],\"y\":[283253,473],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(234,234,242)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"rgb(234,234,242)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(231,231,240)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(183,183,191)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"rgb(67,103,167)\"},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"colorscale\":{\"sequential\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"sequentialminus\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]]},\"colorway\":[\"rgb(76,114,176)\",\"rgb(221,132,82)\",\"rgb(85,168,104)\",\"rgb(196,78,82)\",\"rgb(129,114,179)\",\"rgb(147,120,96)\",\"rgb(218,139,195)\",\"rgb(140,140,140)\",\"rgb(204,185,116)\",\"rgb(100,181,205)\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"rgb(234,234,242)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"rgb(234,234,242)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"bgcolor\":\"rgb(234,234,242)\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"fillcolor\":\"rgb(67,103,167)\",\"line\":{\"width\":0},\"opacity\":0.5},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"bgcolor\":\"rgb(234,234,242)\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"}},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"}}},\"yaxis\":{\"title\":{\"text\":\"Number of Cases\"},\"mirror\":true,\"linecolor\":\"black\",\"linewidth\":2},\"xaxis\":{\"title\":{\"text\":\"Case\"},\"nticks\":3,\"mirror\":true,\"linecolor\":\"black\",\"linewidth\":2},\"margin\":{\"t\":50,\"b\":0,\"l\":70,\"r\":0},\"hovermode\":\"closest\",\"title\":{\"text\":\"Number of Fraud vs Non-Fraud Cases\"},\"width\":700,\"height\":400},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9d6cf9fe-470e-4df9-84ad-5b98213b4521');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
        "print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0mZG0F65vpy",
        "outputId": "0f317021-9842-4ef1-f27e-a86a1c4900fa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Frauds 99.83 % of the dataset\n",
            "Frauds 0.17 % of the dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari histogram diatas dapat dilihat bahwa dataset yang digunakan sangat tidak seimbang"
      ],
      "metadata": {
        "id": "8XwkM-I2719q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('Class').agg(\n",
        "    transactions=('Class', 'count'),\n",
        "    total_revenue=('Amount', 'sum'),\n",
        ").round(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "T-248G-b8XZe",
        "outputId": "0d2d0a33-eb56-4ee5-f490-cad124764f19"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       transactions  total_revenue\n",
              "Class                             \n",
              "0            283253    25043410.29\n",
              "1               473       58591.39"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73ca1b1f-4e23-4053-a366-f463840793a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transactions</th>\n",
              "      <th>total_revenue</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>283253</td>\n",
              "      <td>25043410.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>473</td>\n",
              "      <td>58591.39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73ca1b1f-4e23-4053-a366-f463840793a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73ca1b1f-4e23-4053-a366-f463840793a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73ca1b1f-4e23-4053-a366-f463840793a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari data kita dapat mengelompokan bahwa kerugian yang ditimbulkan Fraud yaitu $ 58,591.39 selama 2 hari."
      ],
      "metadata": {
        "id": "L4zNbknr8crv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Scaling"
      ],
      "metadata": {
        "id": "bQfWcD8H9JrP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "dari analisa dataset diatas kita dapat melihat bahwa fitur-fitur yang ada sudah diskalakan, terkecuali fitur Amout dan Time."
      ],
      "metadata": {
        "id": "FzO4DVUC9kqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
        "#Feature Scaling\n",
        "rob_scaler = RobustScaler()\n",
        "df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
        "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
        "df.drop(['Time','Amount'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "YcXEsz4DDCA2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_amount = df['scaled_amount']\n",
        "scaled_time = df['scaled_time']\n",
        "\n",
        "#scaled_amount and scaled_time are added to the starting of the dataframe\n",
        "df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
        "df.insert(0, 'scaled_amount', scaled_amount)\n",
        "df.insert(1, 'scaled_time', scaled_time)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "9AEtGy6WDEbE",
        "outputId": "cbbf1021-b891-4801-d435-1762d0194049"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
              "0       1.774718    -0.995290 -1.359807 -0.072781  2.536347  1.378155   \n",
              "1      -0.268530    -0.995290  1.191857  0.266151  0.166480  0.448154   \n",
              "2       4.959811    -0.995279 -1.358354 -1.340163  1.773209  0.379780   \n",
              "3       1.411487    -0.995279 -0.966272 -0.185226  1.792993 -0.863291   \n",
              "4       0.667362    -0.995267 -1.158233  0.877737  1.548718  0.403034   \n",
              "\n",
              "         V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
              "0 -0.338321  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838   \n",
              "1  0.060018 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672   \n",
              "2 -0.503198  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679   \n",
              "3 -0.010309  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274   \n",
              "4 -0.407193  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278   \n",
              "\n",
              "        V23       V24       V25       V26       V27       V28  Class  \n",
              "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
              "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
              "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
              "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
              "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0812b98c-6d14-462e-b34d-6bab05b60618\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>scaled_amount</th>\n",
              "      <th>scaled_time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>...</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.774718</td>\n",
              "      <td>-0.995290</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>...</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.268530</td>\n",
              "      <td>-0.995290</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.959811</td>\n",
              "      <td>-0.995279</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>...</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.411487</td>\n",
              "      <td>-0.995279</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.667362</td>\n",
              "      <td>-0.995267</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>...</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0812b98c-6d14-462e-b34d-6bab05b60618')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0812b98c-6d14-462e-b34d-6bab05b60618 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0812b98c-6d14-462e-b34d-6bab05b60618');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the Data"
      ],
      "metadata": {
        "id": "on6GJs5iO-uG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sebelum melanjutkan dengan teknik Random UnderSampling kita harus memisahkan dataframe orginal. Mengapa? untuk tujuan pengujian, ingatlah meskipun kami membagi data saat menerapkan teknik Random UnderSampling , kami ingin menguji model kami pada set pengujian asli bukan pada set pengujian yang dibuat oleh salah satu teknik ini. Tujuan utamanya adalah untuk menyesuaikan model baik dengan dataframe yang undersample (agar model kami dapat mendeteksi pola), dan mengujinya pada set pengujian asli."
      ],
      "metadata": {
        "id": "ytWTIyN3PE20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Under Sampling"
      ],
      "metadata": {
        "id": "de8WtBr0TdVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Under Sampling\n",
        "\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_rs, y_rs = rus.fit_resample(X,y)"
      ],
      "metadata": {
        "id": "xwuMMVKeP06w"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Under-sampled Dataframe\n",
        "df_rs = pd.DataFrame(np.hstack((X_rs,y_rs[:, None])), columns=df.columns)\n",
        "df_rs.Class = df_rs.Class.astype(int)\n",
        "df_rs.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "z0Sf2SAYU7CN",
        "outputId": "7289a28c-3091-47ed-93d1-ac3be1363da0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning:\n",
            "\n",
            "Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
              "0      -0.270060     0.958308  0.032432  0.845050  0.161690 -0.798504   \n",
              "1      -0.152413    -0.256242  1.205443  0.289451  0.741620  0.746450   \n",
              "2      -0.281185    -0.517144 -0.275684  1.112403  0.942716 -0.136235   \n",
              "3       1.881380     0.196931  1.802716 -0.304729 -2.092921  0.191727   \n",
              "4       0.168544    -0.338811 -2.525869  2.202607  0.633063  0.584094   \n",
              "\n",
              "         V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
              "0  0.695579 -0.565116  0.933765 -0.062716  ...  0.013430 -0.229609 -0.491374   \n",
              "1 -0.682445 -1.276868  0.136546 -0.284828  ... -0.043590 -0.208169 -0.589665   \n",
              "2  0.427005 -0.504525  0.686810 -0.014106  ...  0.130043 -0.321393 -0.851229   \n",
              "3  0.553230 -1.079475  0.755031 -0.537489  ...  0.061476  0.078572  0.251564   \n",
              "4 -0.668050  0.201383  0.207289  0.336436  ...  0.166092 -0.191501 -0.238654   \n",
              "\n",
              "        V23       V24       V25       V26       V27       V28  Class  \n",
              "0  0.001259 -0.400306 -0.451544  0.143434  0.246293  0.084199      0  \n",
              "1  0.185183  0.933687  0.168355  0.058053 -0.025197  0.027646      0  \n",
              "2 -0.121964 -0.509255 -0.052742  0.124297  0.244629  0.089349      0  \n",
              "3 -0.165849 -0.392507  0.277481  0.121611 -0.135312 -0.068539      0  \n",
              "4 -0.115595 -0.024809 -0.158276 -0.669323 -1.506852 -0.739474      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ebd40b8-55ca-4a6d-8820-d31947a79d13\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>scaled_amount</th>\n",
              "      <th>scaled_time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>...</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.270060</td>\n",
              "      <td>0.958308</td>\n",
              "      <td>0.032432</td>\n",
              "      <td>0.845050</td>\n",
              "      <td>0.161690</td>\n",
              "      <td>-0.798504</td>\n",
              "      <td>0.695579</td>\n",
              "      <td>-0.565116</td>\n",
              "      <td>0.933765</td>\n",
              "      <td>-0.062716</td>\n",
              "      <td>...</td>\n",
              "      <td>0.013430</td>\n",
              "      <td>-0.229609</td>\n",
              "      <td>-0.491374</td>\n",
              "      <td>0.001259</td>\n",
              "      <td>-0.400306</td>\n",
              "      <td>-0.451544</td>\n",
              "      <td>0.143434</td>\n",
              "      <td>0.246293</td>\n",
              "      <td>0.084199</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.152413</td>\n",
              "      <td>-0.256242</td>\n",
              "      <td>1.205443</td>\n",
              "      <td>0.289451</td>\n",
              "      <td>0.741620</td>\n",
              "      <td>0.746450</td>\n",
              "      <td>-0.682445</td>\n",
              "      <td>-1.276868</td>\n",
              "      <td>0.136546</td>\n",
              "      <td>-0.284828</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.043590</td>\n",
              "      <td>-0.208169</td>\n",
              "      <td>-0.589665</td>\n",
              "      <td>0.185183</td>\n",
              "      <td>0.933687</td>\n",
              "      <td>0.168355</td>\n",
              "      <td>0.058053</td>\n",
              "      <td>-0.025197</td>\n",
              "      <td>0.027646</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.281185</td>\n",
              "      <td>-0.517144</td>\n",
              "      <td>-0.275684</td>\n",
              "      <td>1.112403</td>\n",
              "      <td>0.942716</td>\n",
              "      <td>-0.136235</td>\n",
              "      <td>0.427005</td>\n",
              "      <td>-0.504525</td>\n",
              "      <td>0.686810</td>\n",
              "      <td>-0.014106</td>\n",
              "      <td>...</td>\n",
              "      <td>0.130043</td>\n",
              "      <td>-0.321393</td>\n",
              "      <td>-0.851229</td>\n",
              "      <td>-0.121964</td>\n",
              "      <td>-0.509255</td>\n",
              "      <td>-0.052742</td>\n",
              "      <td>0.124297</td>\n",
              "      <td>0.244629</td>\n",
              "      <td>0.089349</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.881380</td>\n",
              "      <td>0.196931</td>\n",
              "      <td>1.802716</td>\n",
              "      <td>-0.304729</td>\n",
              "      <td>-2.092921</td>\n",
              "      <td>0.191727</td>\n",
              "      <td>0.553230</td>\n",
              "      <td>-1.079475</td>\n",
              "      <td>0.755031</td>\n",
              "      <td>-0.537489</td>\n",
              "      <td>...</td>\n",
              "      <td>0.061476</td>\n",
              "      <td>0.078572</td>\n",
              "      <td>0.251564</td>\n",
              "      <td>-0.165849</td>\n",
              "      <td>-0.392507</td>\n",
              "      <td>0.277481</td>\n",
              "      <td>0.121611</td>\n",
              "      <td>-0.135312</td>\n",
              "      <td>-0.068539</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.168544</td>\n",
              "      <td>-0.338811</td>\n",
              "      <td>-2.525869</td>\n",
              "      <td>2.202607</td>\n",
              "      <td>0.633063</td>\n",
              "      <td>0.584094</td>\n",
              "      <td>-0.668050</td>\n",
              "      <td>0.201383</td>\n",
              "      <td>0.207289</td>\n",
              "      <td>0.336436</td>\n",
              "      <td>...</td>\n",
              "      <td>0.166092</td>\n",
              "      <td>-0.191501</td>\n",
              "      <td>-0.238654</td>\n",
              "      <td>-0.115595</td>\n",
              "      <td>-0.024809</td>\n",
              "      <td>-0.158276</td>\n",
              "      <td>-0.669323</td>\n",
              "      <td>-1.506852</td>\n",
              "      <td>-0.739474</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ebd40b8-55ca-4a6d-8820-d31947a79d13')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ebd40b8-55ca-4a6d-8820-d31947a79d13 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ebd40b8-55ca-4a6d-8820-d31947a79d13');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Frauds vs. Non-Frauds for the new dataframe\n",
        "group = df_rs.groupby('Class')['scaled_time'].count()\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(name='counts',x=group.index, y=group.values, marker_line_color='black', marker_line_width=2,\n",
        "                     text=group.values,textposition='outside'))\n",
        "fig.update_yaxes(title_text='Number of Cases')\n",
        "fig.update_xaxes(title_text='Case',nticks=3)\n",
        "fig.update_layout(template='seaborn',hovermode='closest',title='Number of Fraud vs Non-Fraud Cases',\n",
        "                 width=700,height=400,xaxis=dict(mirror=True,linecolor='black',linewidth=2),\n",
        "                 yaxis=dict(mirror=True,linecolor='black',linewidth=2),margin=dict(t=50,b=0,l=70,r=0))\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "nrysVwDzVEiD",
        "outputId": "86b08113-6546-4c12-fb26-d5fadf2718b5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"2601b0e1-ad9c-4188-8608-c6a80207cbcd\" class=\"plotly-graph-div\" style=\"height:400px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2601b0e1-ad9c-4188-8608-c6a80207cbcd\")) {                    Plotly.newPlot(                        \"2601b0e1-ad9c-4188-8608-c6a80207cbcd\",                        [{\"marker\":{\"line\":{\"color\":\"black\",\"width\":2}},\"name\":\"counts\",\"text\":[473.0,473.0],\"textposition\":\"outside\",\"x\":[0,1],\"y\":[473,473],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(234,234,242)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"rgb(234,234,242)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(231,231,240)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(183,183,191)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"rgb(67,103,167)\"},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"colorscale\":{\"sequential\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"sequentialminus\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]]},\"colorway\":[\"rgb(76,114,176)\",\"rgb(221,132,82)\",\"rgb(85,168,104)\",\"rgb(196,78,82)\",\"rgb(129,114,179)\",\"rgb(147,120,96)\",\"rgb(218,139,195)\",\"rgb(140,140,140)\",\"rgb(204,185,116)\",\"rgb(100,181,205)\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"rgb(234,234,242)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"rgb(234,234,242)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"bgcolor\":\"rgb(234,234,242)\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"fillcolor\":\"rgb(67,103,167)\",\"line\":{\"width\":0},\"opacity\":0.5},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"bgcolor\":\"rgb(234,234,242)\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"}},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"}}},\"yaxis\":{\"title\":{\"text\":\"Number of Cases\"},\"mirror\":true,\"linecolor\":\"black\",\"linewidth\":2},\"xaxis\":{\"title\":{\"text\":\"Case\"},\"nticks\":3,\"mirror\":true,\"linecolor\":\"black\",\"linewidth\":2},\"margin\":{\"t\":50,\"b\":0,\"l\":70,\"r\":0},\"hovermode\":\"closest\",\"title\":{\"text\":\"Number of Fraud vs Non-Fraud Cases\"},\"width\":700,\"height\":400},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2601b0e1-ad9c-4188-8608-c6a80207cbcd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Percentage of No Frauds: {}%'.format(round(df_rs.Class.value_counts()[0]/len(df_rs) * 100.0,2)))\n",
        "print('Percentage of Frauds: {}%'.format(round(df_rs.Class.value_counts()[1]/len(df_rs) * 100.0,2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0G6IEJOWFC-",
        "outputId": "0965904e-2a50-4f90-8457-dd5663fb81c3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of No Frauds: 50.0%\n",
            "Percentage of Frauds: 50.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation heatmap"
      ],
      "metadata": {
        "id": "9QVu9PySV-Ng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heatmap 1\n",
        "\n",
        "\n",
        "ini dibangun di atas himpunan data asli. Himpunan data asli adalah himpunan data yang tidak seimbang dengan rasio 99,83:0,17 dari Non-fraudulant adalah untuk transaksi Fraudulant masing-masing. Oleh karena itu, ini bukan indikator yang baik tentang fitur apa yang mempengaruhi transaksi untuk menjadi penipu. Hal yang sama dapat dilihat melalui heapmap serta sebagian besar fitur tidak menunjukkan korelasi sama sekali.\n",
        "\n",
        "\n",
        "Heatmap 2 \n",
        "\n",
        "Untuk mendapatkan pandangan yang lebih baik tentang fitur apa yang memengaruhi transaksi untuk menjadi penipu, akan lebih baik untuk memplot heatmap di atas himpunan data yang dirusak secara acak di mana distribusi kelas (penipuan vs non-penipuan) sama. Seperti dapat dilihat melalui gambar heatmap ini menunjukkan banyak korelasi antara berbagai fitur. Oleh karena itu, grafik ini terbukti berguna dalam mempelajari fitur-fiturnya."
      ],
      "metadata": {
        "id": "wIMrsOslWwr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_subplots(rows=2, cols=1, \n",
        "                    subplot_titles=['Correlation Matrix for the original dataframe','Correlation Matrix for the undersampled dataframe'])\n",
        "\n",
        "fig.add_trace(go.Heatmap(name='original df',z=df.corr().values,x=df.corr().index,y=df.corr().index,\n",
        "                         coloraxis='coloraxis'),1,1)\n",
        "fig.add_trace(go.Heatmap(name='undersampled df',z=df_rs.corr().values,x=df_rs.corr().index,y=df_rs.corr().index,\n",
        "                         coloraxis='coloraxis'),2,1)\n",
        "fig.update_layout(height=800,width=700,coloraxis = {'colorscale':'YlOrRd'})\n",
        "fig.show() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "Faaq1JjAV8oF",
        "outputId": "1d9cb91a-e7f9-42c4-c7eb-09f0eaba93db"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"aae7656a-95cb-44a7-9cb7-fb9224f97455\" class=\"plotly-graph-div\" style=\"height:800px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"aae7656a-95cb-44a7-9cb7-fb9224f97455\")) {                    Plotly.newPlot(                        \"aae7656a-95cb-44a7-9cb7-fb9224f97455\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"original df\",\"x\":[\"scaled_amount\",\"scaled_time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Class\"],\"y\":[\"scaled_amount\",\"scaled_time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Class\"],\"z\":[[1.0,-0.010558833743213486,-0.23010530271668164,-0.5334280139266703,-0.2124100093117621,0.09951433829114571,-0.3876852739120033,0.21638879996016086,0.4004079784579472,-0.10466162183699171,-0.0441225069631552,-0.10225491978205853,-1.4745309458156229e-05,-0.009254234854543455,0.005208901256184813,0.03412161435159589,-0.0032646746452526477,-0.004488172115860928,0.007730194734469259,0.03577523702569335,-0.055993976399284245,0.34072858628941355,0.10805761601439308,-0.06496476330264295,-0.11283253310828839,0.005054927545183929,-0.047596060391279435,-0.0034248459605087252,0.027921726978628207,0.010143491540533232,0.005777019670480671],[-0.010558833743213486,1.0,0.11792660302276431,-0.010555571875426136,-0.4220538104113544,-0.10584489282621114,0.17322301115212554,-0.06327933757899663,0.08533518087392625,-0.038203126152270984,-0.007861473303691687,0.031068099587315066,-0.24853595728863534,0.1255002298234281,-0.06595811110552306,-0.10031604214337,-0.1843919855469501,0.011286429103373134,-0.07381921148674478,0.0903054253721652,0.029536703147179662,-0.05102151882103496,0.04591266340511989,0.14372725309517342,0.05147406679656309,-0.015954266841435895,-0.23326163903367295,-0.04181832491314898,-0.0051714164255086586,-0.009304983543485098,-0.012359339838080569],[-0.23010530271668164,0.11792660302276431,1.0,0.006874935526419426,-0.0081118121678291,0.0022573276391564083,-0.0070360157636033815,0.00041283568618039176,-0.009173080413415599,-0.0011682694376569708,0.0018280398253499636,0.0008152213891852068,0.0010280856222418626,-0.0015237428910409487,-0.0005675425908394059,-0.00266278895502623,-0.0006024774624418298,-0.00334540789384781,-0.0034909758217799023,-0.0035352301115608325,0.0009192076290548192,-0.0013928956574949967,0.0028175226840769776,-0.0014362517992120196,-0.0013304300392769047,-0.0007230448298401707,-0.00022249144197399148,-0.0006836594408822196,-0.015706191784068683,-0.0048605805640334725,-0.09448583378656274],[-0.5334280139266703,-0.010555571875426136,0.006874935526419426,1.0,0.00527825173761563,-0.00149526111360645,0.005209893541183653,-0.0005944498536884843,0.007424774033838251,0.0028992256555983834,-0.000273968682847043,0.0006204527334765875,-0.0006332422001300892,0.002266371812804505,0.000679634418527732,0.002711141992774252,0.0015377416324324979,0.004012757876910272,0.0032441614941839275,0.0024765547891234065,-0.0003582540758005265,-0.0012874591576682976,-0.004897164807167111,0.001237129661219597,-0.0038546637471704426,0.0007005669147255492,-0.0015691227244523094,0.0002532206861903867,0.007554740201984243,0.001611320698494387,0.08462444869117351],[-0.2124100093117621,-0.4220538104113544,-0.0081118121678291,0.00527825173761563,1.0,0.002828781887235172,-0.006878570751309485,-0.0015114820260679885,-0.011721387696630715,-0.001814669812211177,-0.0035789211859255277,-0.009632285620257914,0.0023390024296688133,-0.005900173370574252,0.0001132795258778838,-0.00302737343478468,-0.001230119035515296,-0.004430372202953226,-0.008159065477444463,-0.003494743840183453,-1.5795914878744604e-05,-0.0022685010145374563,0.0034998715560879304,-0.0002747376974692431,0.0004490739775692545,-7.219221427316464e-05,0.00042510378709767385,-9.43145501557379e-05,-0.0070506444593044166,-0.00013416243133487275,-0.18232224748340453],[0.09951433829114571,-0.10584489282621114,0.0022573276391564083,-0.00149526111360645,0.002828781887235172,1.0,0.0017442162438024282,-0.0008804138005239035,0.004656983704556169,0.0008904924205630152,0.002154399752364985,0.002752955770430743,-0.001222839153274635,0.0033657176049544124,0.0001774350252533336,0.0028006571624838304,0.0005723099873960436,0.0033463956939710497,0.003655499037334594,0.0023245465265008375,-0.0005603806335026222,0.00031814368907488375,-0.0010337817276862696,0.00011540141274068858,0.0007320910665364891,-0.00011988954340412765,0.0001616877309049471,0.0007769987555261176,0.0013219888401892698,0.0002310926109730117,0.12932583072677128],[-0.3876852739120033,0.17322301115212554,-0.0070360157636033815,0.005209893541183653,-0.006878570751309485,0.0017442162438024282,1.0,-0.0009375118026803868,-0.008708848396817254,0.0014304921486532228,-0.0012128308740592066,-0.006049529114165079,0.0004112367277689824,-0.0023416751741034292,1.9180768088287386e-05,-0.001000291956111468,-0.0011706668323148725,-0.0023730942132559546,-0.004466238099767102,-0.0026854202621077166,0.0004361496264668811,-0.0011847396408664588,0.0016223474565084965,-0.0005587086089826208,0.0011832297651566195,0.00019788530702163315,6.905195049959112e-05,0.0003904258882223096,-0.00579802732584942,-0.0008200771568128342,-0.08781244297489552],[0.21638879996016086,-0.06327933757899663,0.00041283568618039176,-0.0005944498536884843,-0.0015114820260679885,-0.0008804138005239035,-0.0009375118026803868,1.0,0.00043631051630188685,0.003035785649002894,-0.0007338978121966336,-0.002179664927199511,-0.00021108571422985643,-0.0011851526958976475,0.0003971070847501633,0.0001835358673879833,-0.000470107100634843,0.0001222524552099763,-0.0017161730770739987,0.0005406374945166352,0.00010571146005933293,-0.00018101279201828674,-0.002133682066311286,0.0011036270673049759,-0.0007553722692057088,0.0012021488027409502,0.0006970064101565102,-2.8038589542612846e-05,0.0002892464950036262,0.0009246284173767372,-0.043915409238085734],[0.4004079784579472,0.08533518087392625,-0.009173080413415599,0.007424774033838251,-0.011721387696630715,0.004656983704556169,-0.008708848396817254,0.00043631051630188685,1.0,-0.00641931498926704,-0.004921427799508061,-0.013617071699614935,0.002454389524744143,-0.006153104318386394,-0.0001700720574197431,-0.003815507711620032,-0.0013936031389349761,-0.005944410923274911,-0.008793767370252392,-0.00427913627524687,0.0008461490012228347,-0.0011921619298240857,0.009010101012951481,-0.0022802363666433213,0.0033034839182157,-0.0003844087612464727,-7.247179108844831e-05,0.000623884578430212,-0.004536866925704052,0.0016565689800311968,-0.17234653244006812],[-0.10466162183699171,-0.038203126152270984,-0.0011682694376569708,0.0028992256555983834,-0.001814669812211177,0.0008904924205630152,0.0014304921486532228,0.003035785649002894,-0.00641931498926704,1.0,0.0010383549502201864,0.0004809097807614368,0.004687840758807665,-0.004413662707800211,-0.00138107131132359,-0.008387034001511499,0.0010441073897902722,-0.00437554441562473,-0.005575898368280805,-0.0013234694143313636,-0.0006258693317342716,0.0002714637780973605,0.018892285715434554,-0.006156169319139048,0.004993689956566703,0.00011250619728093436,1.0623154795171527e-05,-0.0014067841240507362,0.0006132571162989338,-9.929006655380315e-05,0.03306802333281736],[-0.0441225069631552,-0.007861473303691687,0.0018280398253499636,-0.000273968682847043,-0.0035789211859255277,0.002154399752364985,-0.0012128308740592066,-0.0007338978121966336,-0.004921427799508061,0.0010383549502201864,1.0,-0.012612719895320526,-0.00021717644005768725,-0.0023845959897791863,0.0007450416352440461,0.001981400398180012,-0.00028299604931824197,-8.63526201567071e-05,-0.0023179010260471903,-0.00037299420565077075,0.0002472655674440802,-0.001837667573194655,0.0006787735467916778,0.0007845609940343668,0.0006768839530255376,-0.00010308329057548098,-0.0002751722833421242,0.0012534989519350879,0.0082210631180808,0.005591209829211807,-0.09402128731255407],[-0.10225491978205853,0.031068099587315066,0.0008152213891852068,0.0006204527334765875,-0.009632285620257914,0.002752955770430743,-0.006049529114165079,-0.002179664927199511,-0.013617071699614935,0.0004809097807614368,-0.012612719895320526,1.0,0.0008441105944609582,-0.006941843021571827,0.0013787936076923712,0.00016773905551490604,-0.0022927840074276023,-0.0037153648767873325,-0.007877238876526398,-0.0024500111459483066,0.0010665177859760825,-0.004448340957551856,0.0037771149647689026,-0.0004809226296363571,0.0019166171100527668,0.00015444559587360338,-0.0005646352792900435,0.0010888767982834059,0.010769304605269562,0.009158577391667302,-0.20697123823505903],[-1.4745309458156229e-05,-0.24853595728863534,0.0010280856222418626,-0.0006332422001300892,0.0023390024296688133,-0.001222839153274635,0.0004112367277689824,-0.00021108571422985643,0.002454389524744143,0.004687840758807665,-0.00021717644005768725,0.0008441105944609582,1.0,0.005568598011092186,0.0004551593007865121,0.007713499202580031,-0.0008717780913599406,0.004750958546111536,0.007353304436047845,0.0020952108165381207,-0.0004881236955308138,-0.0009890491440345608,-0.002760203439316694,-0.0001502572020376823,-3.669861416619262e-05,7.954333062514645e-05,4.720072400498326e-05,-0.00020384739348269424,0.001986851607753208,0.002562344344397288,0.14906710367009615],[-0.009254234854543455,0.1255002298234281,-0.0015237428910409487,0.002266371812804505,-0.005900173370574252,0.0033657176049544124,-0.0023416751741034292,-0.0011851526958976475,-0.006153104318386394,-0.004413662707800211,-0.0023845959897791863,-0.006941843021571827,0.005568598011092186,1.0,-0.000550053631997799,-0.010007267733039869,0.0008809023743919967,-0.007372014340777108,-0.012856437264530441,-0.0034636324576663683,0.0005929059591236318,0.0011687650346350327,0.003285266027488088,0.00015105954512132925,0.00048587195690326444,0.0005876584022505094,-0.00018074790446135757,-0.00013837785008018828,-0.0009285293662557876,-0.0006131803830766918,-0.25071117720572017],[0.005208901256184813,-0.06595811110552306,-0.0005675425908394059,0.000679634418527732,0.0001132795258778838,0.0001774350252533336,1.9180768088287386e-05,0.0003971070847501633,-0.0001700720574197431,-0.00138107131132359,0.0007450416352440461,0.0013787936076923712,0.0004551593007865121,-0.000550053631997799,1.0,-0.0011332040038427263,0.00023412699748537842,-0.0008073010205591225,-0.0001697639811625292,-0.00015528654425752778,8.61803677235237e-05,0.00037878143672678805,0.000522429117814035,1.6456093356258318e-05,0.0002518460684712973,-4.889666268313041e-05,0.000248032089335133,-0.00010147628002586647,-0.0015771829819177252,-0.0006039263714784479,-0.003896955111430142],[0.03412161435159589,-0.10031604214337,-0.00266278895502623,0.002711141992774252,-0.00302737343478468,0.0028006571624838304,-0.001000291956111468,0.0001835358673879833,-0.003815507711620032,-0.008387034001511499,0.001981400398180012,0.00016773905551490604,0.007713499202580031,-0.010007267733039869,-0.0011332040038427263,1.0,0.0008664876035930266,-0.009073780163101713,-0.013550833900086972,-0.0044828952675463295,0.0015871864127332519,0.0027255828700044104,0.005633478985517677,-0.0019063009637494744,0.0006656972876652788,-2.632084157299185e-05,0.00015538586503393827,-0.0007020277048752616,-0.004556005773713546,-0.0046642629458518515,-0.29337538479004244],[-0.0032646746452526477,-0.1843919855469501,-0.0006024774624418298,0.0015377416324324979,-0.001230119035515296,0.0005723099873960436,-0.0011706668323148725,-0.000470107100634843,-0.0013936031389349761,0.0010441073897902722,-0.00028299604931824197,-0.0022927840074276023,-0.0008717780913599406,0.0008809023743919967,0.00023412699748537842,0.0008664876035930266,1.0,-0.00028270323000670176,-0.00017359790672143779,-0.00042609714593935864,0.0005546181666845662,-0.0007540547321741072,-0.000270715999728039,-0.0011969348265726293,0.0009690519543636753,0.00011257826880787244,0.0004447776543112965,-0.0020340133952125154,-0.0006413875569910669,0.0008583620124208974,-0.0032995578711372373],[-0.004488172115860928,0.011286429103373134,-0.00334540789384781,0.004012757876910272,-0.004430372202953226,0.0033463956939710497,-0.0023730942132559546,0.0001222524552099763,-0.005944410923274911,-0.00437554441562473,-8.63526201567071e-05,-0.0037153648767873325,0.004750958546111536,-0.007372014340777108,-0.0008073010205591225,-0.009073780163101713,-0.00028270323000670176,1.0,-0.009062940251164447,-0.005427043024313857,0.0024317429926107737,0.0010670338155660255,0.0043264890950248614,-0.0008201712861955649,0.001208949862802246,-0.000481793663465755,0.00021493165118660282,-0.0012448302570294875,-0.003973719523256616,-0.0016287776618440569,-0.18718605284536083],[0.007730194734469259,-0.07381921148674478,-0.0034909758217799023,0.0032441614941839275,-0.008159065477444463,0.003655499037334594,-0.004466238099767102,-0.0017161730770739987,-0.008793767370252392,-0.005575898368280805,-0.0023179010260471903,-0.007877238876526398,0.007353304436047845,-0.012856437264530441,-0.0001697639811625292,-0.013550833900086972,-0.00017359790672143779,-0.009062940251164447,1.0,-0.005276652843220592,0.0009892274822335648,0.0015182392922292749,0.0035596126973395574,-0.00016210563035051688,0.000667395368792942,0.0010061384893589715,-0.0006845364870769069,0.0001568409179462451,-0.0034206019748422617,-0.002702573492757629,-0.3134982729556793],[0.03577523702569335,0.0903054253721652,-0.0035352301115608325,0.0024765547891234065,-0.003494743840183453,0.0023245465265008375,-0.0026854202621077166,0.0005406374945166352,-0.00427913627524687,-0.0013234694143313636,-0.00037299420565077075,-0.0024500111459483066,0.0020952108165381207,-0.0034636324576663683,-0.00015528654425752778,-0.0044828952675463295,-0.00042609714593935864,-0.005427043024313857,-0.005276652843220592,1.0,-0.00010035952573903391,-0.0002447824836732992,0.0016289501006633567,-0.000533296139279614,0.0002401796529205121,-0.0007102011965020371,-0.000558950489103054,-0.0005962489139916716,-0.004230566682580002,-0.0012564998781779064,-0.10533971521707305],[-0.055993976399284245,0.029536703147179662,0.0009192076290548192,-0.0003582540758005265,-1.5795914878744604e-05,-0.0005603806335026222,0.0004361496264668811,0.00010571146005933293,0.0008461490012228347,-0.0006258693317342716,0.0002472655674440802,0.0010665177859760825,-0.0004881236955308138,0.0005929059591236318,8.61803677235237e-05,0.0015871864127332519,0.0005546181666845662,0.0024317429926107737,0.0009892274822335648,-0.00010035952573903391,1.0,-0.00026939162184398425,0.00024353286940087852,0.00134166441662352,0.0003808830997685998,-0.00011186586698434719,-8.428858807678778e-05,0.0008557074186997845,-0.0005438293899230199,0.00035310699153178187,0.033631154442230346],[0.34072858628941355,-0.05102151882103496,-0.0013928956574949967,-0.0012874591576682976,-0.0022685010145374563,0.00031814368907488375,-0.0011847396408664588,-0.00018101279201828674,-0.0011921619298240857,0.0002714637780973605,-0.001837667573194655,-0.004448340957551856,-0.0009890491440345608,0.0011687650346350327,0.00037878143672678805,0.0027255828700044104,-0.0007540547321741072,0.0010670338155660255,0.0015182392922292749,-0.0002447824836732992,-0.00026939162184398425,1.0,0.005372444121996675,-0.0016165580908771206,-0.0010942309832734196,-0.00030266279081047373,-0.0006432089880944813,-0.0003104050465949517,-4.89369633317948e-05,0.002671098201648469,0.02148634032100875],[0.10805761601439308,0.04591266340511989,0.0028175226840769776,-0.004897164807167111,0.0034998715560879304,-0.0010337817276862696,0.0016223474565084965,-0.002133682066311286,0.009010101012951481,0.018892285715434554,0.0006787735467916778,0.0037771149647689026,-0.002760203439316694,0.003285266027488088,0.000522429117814035,0.005633478985517677,-0.000270715999728039,0.0043264890950248614,0.0035596126973395574,0.0016289501006633567,0.00024353286940087852,0.005372444121996675,1.0,0.009645297017555234,-0.0063911020976040855,0.0012102128937225222,-0.0008724678628704036,-0.0008738994580018577,-0.00521648778710321,-0.004436378810710145,0.026357438897066807],[-0.06496476330264295,0.14372725309517342,-0.0014362517992120196,0.001237129661219597,-0.0002747376974692431,0.00011540141274068858,-0.0005587086089826208,0.0011036270673049759,-0.0022802363666433213,-0.006156169319139048,0.0007845609940343668,-0.0004809226296363571,-0.0001502572020376823,0.00015105954512132925,1.6456093356258318e-05,-0.0019063009637494744,-0.0011969348265726293,-0.0008201712861955649,-0.00016210563035051688,-0.000533296139279614,0.00134166441662352,-0.0016165580908771206,0.009645297017555234,1.0,0.001929377252585751,-3.143969752916494e-05,0.00019744121024067708,-0.0014952641075571735,0.0030371549632088575,0.0013923896254467764,0.0048872321638307415],[-0.11283253310828839,0.05147406679656309,-0.0013304300392769047,-0.0038546637471704426,0.0004490739775692545,0.0007320910665364891,0.0011832297651566195,-0.0007553722692057088,0.0033034839182157,0.004993689956566703,0.0006768839530255376,0.0019166171100527668,-3.669861416619262e-05,0.00048587195690326444,0.0002518460684712973,0.0006656972876652788,0.0009690519543636753,0.001208949862802246,0.000667395368792942,0.0002401796529205121,0.0003808830997685998,-0.0010942309832734196,-0.0063911020976040855,0.001929377252585751,1.0,0.00027270445866602614,-0.0005319791364952711,-0.00018539127457151274,-0.0020277014016940676,-0.003223704469492328,-0.006333210643022919],[0.005054927545183929,-0.015954266841435895,-0.0007230448298401707,0.0007005669147255492,-7.219221427316464e-05,-0.00011988954340412765,0.00019788530702163315,0.0012021488027409502,-0.0003844087612464727,0.00011250619728093436,-0.00010308329057548098,0.00015444559587360338,7.954333062514645e-05,0.0005876584022505094,-4.889666268313041e-05,-2.632084157299185e-05,0.00011257826880787244,-0.000481793663465755,0.0010061384893589715,-0.0007102011965020371,-0.00011186586698434719,-0.00030266279081047373,0.0012102128937225222,-3.143969752916494e-05,0.00027270445866602614,1.0,-0.00018806571577577004,0.000567772420451268,-0.0008847187720215867,0.00032202938151089275,-0.007210125120706586],[-0.047596060391279435,-0.23326163903367295,-0.00022249144197399148,-0.0015691227244523094,0.00042510378709767385,0.0001616877309049471,6.905195049959112e-05,0.0006970064101565102,-7.247179108844831e-05,1.0623154795171527e-05,-0.0002751722833421242,-0.0005646352792900435,4.720072400498326e-05,-0.00018074790446135757,0.000248032089335133,0.00015538586503393827,0.0004447776543112965,0.00021493165118660282,-0.0006845364870769069,-0.000558950489103054,-8.428858807678778e-05,-0.0006432089880944813,-0.0008724678628704036,0.00019744121024067708,-0.0005319791364952711,-0.00018806571577577004,1.0,4.787741972194726e-05,-0.0013385553529365786,-0.000565466959238189,0.003202493530110167],[-0.0034248459605087252,-0.04181832491314898,-0.0006836594408822196,0.0002532206861903867,-9.43145501557379e-05,0.0007769987555261176,0.0003904258882223096,-2.8038589542612846e-05,0.000623884578430212,-0.0014067841240507362,0.0012534989519350879,0.0010888767982834059,-0.00020384739348269424,-0.00013837785008018828,-0.00010147628002586647,-0.0007020277048752616,-0.0020340133952125154,-0.0012448302570294875,0.0001568409179462451,-0.0005962489139916716,0.0008557074186997845,-0.0003104050465949517,-0.0008738994580018577,-0.0014952641075571735,-0.00018539127457151274,0.000567772420451268,4.787741972194726e-05,1.0,-0.003294446571853794,-0.0009989489588562428,0.004264576791248341],[0.027921726978628207,-0.0051714164255086586,-0.015706191784068683,0.007554740201984243,-0.0070506444593044166,0.0013219888401892698,-0.00579802732584942,0.0002892464950036262,-0.004536866925704052,0.0006132571162989338,0.0082210631180808,0.010769304605269562,0.001986851607753208,-0.0009285293662557876,-0.0015771829819177252,-0.004556005773713546,-0.0006413875569910669,-0.003973719523256616,-0.0034206019748422617,-0.004230566682580002,-0.0005438293899230199,-4.89369633317948e-05,-0.00521648778710321,0.0030371549632088575,-0.0020277014016940676,-0.0008847187720215867,-0.0013385553529365786,-0.003294446571853794,1.0,-0.013950425887165495,0.02189211330695945],[0.010143491540533232,-0.009304983543485098,-0.0048605805640334725,0.001611320698494387,-0.00013416243133487275,0.0002310926109730117,-0.0008200771568128342,0.0009246284173767372,0.0016565689800311968,-9.929006655380315e-05,0.005591209829211807,0.009158577391667302,0.002562344344397288,-0.0006131803830766918,-0.0006039263714784479,-0.0046642629458518515,0.0008583620124208974,-0.0016287776618440569,-0.002702573492757629,-0.0012564998781779064,0.00035310699153178187,0.002671098201648469,-0.004436378810710145,0.0013923896254467764,-0.003223704469492328,0.00032202938151089275,-0.000565466959238189,-0.0009989489588562428,-0.013950425887165495,1.0,0.009682426330025314],[0.005777019670480671,-0.012359339838080569,-0.09448583378656274,0.08462444869117351,-0.18232224748340453,0.12932583072677128,-0.08781244297489552,-0.043915409238085734,-0.17234653244006812,0.03306802333281736,-0.09402128731255407,-0.20697123823505903,0.14906710367009615,-0.25071117720572017,-0.003896955111430142,-0.29337538479004244,-0.0032995578711372373,-0.18718605284536083,-0.3134982729556793,-0.10533971521707305,0.033631154442230346,0.02148634032100875,0.026357438897066807,0.0048872321638307415,-0.006333210643022919,-0.007210125120706586,0.003202493530110167,0.004264576791248341,0.02189211330695945,0.009682426330025314,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"coloraxis\":\"coloraxis\",\"name\":\"undersampled df\",\"x\":[\"scaled_amount\",\"scaled_time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Class\"],\"y\":[\"scaled_amount\",\"scaled_time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Class\"],\"z\":[[1.0,0.025681201025800588,-0.03648247702259959,-0.2675972493841897,-0.020110371235593068,-0.011462762598615365,-0.10890334530651458,0.223829839619972,0.13989218016602814,-0.010707595771437584,0.025884768292290364,0.010759557300167729,-0.029746123148740235,0.03260220988318495,0.02395973183090916,0.06387858119799651,0.03779751253004603,-0.010117461874212202,-0.003081631978011285,0.006363434523502558,0.0546720276569547,0.2425003454209875,0.06191078844713242,-0.052336972295555506,-0.16872791275617904,0.03422384071024588,-0.08015537516740186,0.0056947611144727945,0.04776846519710266,-0.03244473826374118,0.044921015606160276],[0.025681201025800588,1.0,0.260807660110688,-0.2473726486566226,0.180672547347148,-0.24501096320275167,0.30893458887281555,0.1632595726157076,0.2438304005370029,-0.19833747642320354,0.19312878538961753,0.2474493124230139,-0.33752125690365725,0.29441731948840205,-0.0986335177611835,0.20024876902523572,-0.17161050075741832,0.2634050112882656,0.2667804528085626,0.28417448544154317,-0.11206050303151067,-0.0435448051745826,-0.05568522309454584,0.0943891888631758,0.0761329008760937,-4.3366447595242484e-05,-0.19717797816761146,-0.0482427097680955,-0.1352432886125526,0.018830136874302048,-0.17559571415070888],[-0.03648247702259959,0.260807660110688,1.0,-0.7811451899840388,0.8714367171562784,-0.5998119364115096,0.8594617498101693,0.3650087739099884,0.8672811915231685,-0.22755864908282875,0.636138103891895,0.7093566386890863,-0.5192818992111113,0.5874619566091304,-0.07850283084010609,0.43510339911887896,0.08938004858339574,0.6294845711926749,0.6722995817059164,0.676397368130107,-0.32721931718519004,-0.3480719043429145,0.10978334025739765,-0.09118529774144489,0.004506840074018094,-0.07449917823603203,-0.10796480987733327,0.05340034734849865,0.10488222915795282,0.15190122201809045,-0.4140652083107102],[-0.2675972493841897,-0.2473726486566226,-0.7811451899840388,1.0,-0.8462920859147789,0.6714465288313469,-0.7829573265111357,-0.3652865439645699,-0.8254800410042297,0.14331342236621578,-0.6802230965245804,-0.7498912719036497,0.6156902228399316,-0.6655722051341985,0.06988902842492566,-0.5649269431781906,-0.1595736338833067,-0.6175728280187531,-0.6374435441027602,-0.6160745454064465,0.23206716780655584,0.3357951421321843,-0.10168253103512599,0.10393152071906417,0.08769525024708694,-0.0034330974022567426,0.13522383281188124,-0.006762917819482421,-0.0948638885330264,0.024285377595784995,0.47347489940607695],[-0.020110371235593068,0.180672547347148,0.8714367171562784,-0.8462920859147789,1.0,-0.7578691464482235,0.8460663565642009,0.49577878737616293,0.8832272957772537,-0.28917327931475617,0.7486478679040065,0.837951406535343,-0.7183809752409444,0.755900102837628,-0.08492045137421834,0.6580059649408267,0.12640549347907765,0.7222828373471071,0.7329961891976753,0.6975623200762704,-0.32576070725905576,-0.3905553374747205,0.07245696592720566,-0.10431851768467852,0.0051481431757168464,0.029982794572505616,-0.10872832320409029,-0.03201629044032925,0.002407775443123276,0.09033199934504305,-0.557681994014988],[-0.011462762598615365,-0.24501096320275167,-0.5998119364115096,0.6714465288313469,-0.7578691464482235,1.0,-0.5622846857312244,-0.44008433865590724,-0.7104867707933304,0.13994144593674468,-0.785855681962521,-0.7804503350354763,0.7934267320836922,-0.8268507920606424,0.04785623237385567,-0.7870990113554551,-0.11815392298040009,-0.7135948770783092,-0.697199917407915,-0.6319268235240664,0.3129042160726141,0.3011282852094513,-0.04957275729793098,0.17488153605886717,0.016402480970636287,-0.1022876397086222,-0.011844901447120249,0.12734440444686865,0.05335539392188264,-0.0856535462215851,0.6966875060670571],[-0.10890334530651458,0.30893458887281555,0.8594617498101693,-0.7829573265111357,0.8460663565642009,-0.5622846857312244,1.0,0.30505620890407853,0.8346578237563419,-0.3169854142082567,0.6354333387328628,0.7348925316355985,-0.5165946351501908,0.6052790798590998,-0.14172704857462712,0.42374074586565535,0.06568098410300768,0.6883591525542724,0.7450192361856167,0.7380328115829556,-0.4190046214534636,-0.338418010142817,0.08562809379357948,-0.12364531866775805,-0.06606260735348173,-0.12409374360020445,-0.11094731811376349,0.053724310356477754,0.10163330923778294,0.13555104103490304,-0.3610550812177925],[0.223829839619972,0.1632595726157076,0.3650087739099884,-0.3652865439645699,0.49577878737616293,-0.44008433865590724,0.30505620890407853,1.0,0.35790036335327424,-0.5494849359453042,0.36657014482317735,0.4473082454699286,-0.5259236704446129,0.5141902374723404,-0.05694034921734938,0.5764255545229343,-0.08968584716078204,0.4654667018667956,0.4409187580400579,0.37560473178335047,-0.21328561089034423,-0.0423180056913961,-0.19832103645378138,0.1640019235676363,0.2562839214708963,-0.01778053997011176,-0.15792780240713733,-0.015148607383798599,-0.22426111827259418,-0.0705804722126513,-0.4353210159337436],[0.13989218016602814,0.2438304005370029,0.8672811915231685,-0.8254800410042297,0.8832272957772537,-0.7104867707933304,0.8346578237563419,0.35790036335327424,1.0,-0.0553551573260392,0.7696115045463705,0.8633069668077139,-0.6448107395052993,0.7300272197983505,-0.04893074274062227,0.5507508377043127,0.15582852041237086,0.7545836387250695,0.7842252545744581,0.7691646535971732,-0.3743526902049924,-0.42198362347225826,0.20089505355418527,-0.25283888590494646,-0.02300986352738762,-0.03948666856441891,0.04552138141327899,0.011934785330130543,0.1545337197354661,0.13197050325809564,-0.4714169559249283],[-0.010707595771437584,-0.19833747642320354,-0.22755864908282875,0.14331342236621578,-0.28917327931475617,0.13994144593674468,-0.3169854142082567,-0.5494849359453042,-0.0553551573260392,1.0,-0.0969141453189562,-0.10784310108756019,0.24351034187166185,-0.21203008552839883,0.22273736187607315,-0.2724273074325328,0.16194877455675244,-0.26256234864225125,-0.29143733304581754,-0.2646427995761057,0.23364539146029906,-0.16635441855300745,0.3536698745103665,-0.32626094256188504,-0.30566746167478376,0.03292196954539542,0.29325424239553544,0.01751725552042749,0.3823955125131211,0.06763824844332866,0.11941393139431287],[0.025884768292290364,0.19312878538961753,0.636138103891895,-0.6802230965245804,0.7486478679040065,-0.785855681962521,0.6354333387328628,0.36657014482317735,0.7696115045463705,-0.0969141453189562,1.0,0.8475979862610907,-0.706826257490801,0.763483753539596,-0.03247764709869714,0.6831647279097894,0.11159349595438199,0.7306754283129139,0.7545264203922345,0.7015321772034538,-0.35338852022487244,-0.3722877843205808,0.17243649350657253,-0.27059657612934407,-0.05521255760958656,0.038376972809255,-0.011200028248449657,-0.14164243509323532,0.0543245669191876,0.1256157435633611,-0.5525023937721794],[0.010759557300167729,0.2474493124230139,0.7093566386890863,-0.7498912719036497,0.837951406535343,-0.7804503350354763,0.7348925316355985,0.4473082454699286,0.8633069668077139,-0.10784310108756019,0.8475979862610907,1.0,-0.8059397405510992,0.8802275004147716,-0.025128525441423633,0.7674157220244278,0.13506459879171612,0.8549994274917525,0.8527574029838525,0.7963272516813783,-0.4215771077982637,-0.3880075778818805,0.11991787253893085,-0.2727231985470627,-0.03611774909514328,0.02673926064071297,0.014741469748355192,-0.04566863864618433,0.05333373006629888,0.1080111948840187,-0.6290537687396351],[-0.029746123148740235,-0.33752125690365725,-0.5192818992111113,0.6156902228399316,-0.7183809752409444,0.7934267320836922,-0.5165946351501908,-0.5259236704446129,-0.6448107395052993,0.24351034187166185,-0.706826257490801,-0.8059397405510992,1.0,-0.8978405410095963,0.06352261286486266,-0.8906170934012653,-0.07189922839782634,-0.8029747431856894,-0.7648022499662573,-0.6674719735210397,0.39770328880643824,0.2233350985635395,0.12480015096996191,0.08433261481307001,-0.06398689615089916,-0.12490630339798699,0.026155189696097217,0.14151331028962366,0.2197072521656195,0.03350945188878915,0.6896368975884982],[0.03260220988318495,0.29441731948840205,0.5874619566091304,-0.6655722051341985,0.755900102837628,-0.8268507920606424,0.6052790798590998,0.5141902374723404,0.7300272197983505,-0.21203008552839883,0.763483753539596,0.8802275004147716,-0.8978405410095963,1.0,-0.0756648450306652,0.8802771011933488,0.07209696917213175,0.8980285096871252,0.8707884682679062,0.7941158590168661,-0.4487227853043467,-0.24045079161196992,-0.0778950137046864,-0.16803146915526693,0.013408752210874984,0.06907266143057308,0.03654435472147385,-0.09822806130720747,-0.0869221238240027,-0.005741632248737184,-0.6780600242851847],[0.02395973183090916,-0.0986335177611835,-0.07850283084010609,0.06988902842492566,-0.08492045137421834,0.04785623237385567,-0.14172704857462712,-0.05694034921734938,-0.04893074274062227,0.22273736187607315,-0.03247764709869714,-0.025128525441423633,0.06352261286486266,-0.0756648450306652,1.0,-0.009726625104228115,-0.02619208821881583,-0.1176309016943228,-0.1291957189819088,-0.13287384090896373,0.1719765083194583,-0.04251329114925541,0.11904599452674054,-0.07248998647285194,-0.04028434116911356,0.01923037583985011,0.0038934254876982007,0.02962024227485123,0.0646487692390909,-0.07581419979661447,-0.06188734852264803],[0.06387858119799651,0.20024876902523572,0.43510339911887896,-0.5649269431781906,0.6580059649408267,-0.7870990113554551,0.42374074586565535,0.5764255545229343,0.5507508377043127,-0.2724273074325328,0.6831647279097894,0.7674157220244278,-0.8906170934012653,0.8802771011933488,-0.009726625104228115,1.0,0.012937409249244813,0.772827212499862,0.7228581645897648,0.6122698555789399,-0.35654887619457565,-0.1503912017383243,-0.20948294656352967,-0.014870877058270173,0.04935750167467896,0.1626681000294187,-0.07343224503835075,-0.14897012971939905,-0.2342262049432511,-0.10910160025834865,-0.7448551993802949],[0.03779751253004603,-0.17161050075741832,0.08938004858339574,-0.1595736338833067,0.12640549347907765,-0.11815392298040009,0.06568098410300768,-0.08968584716078204,0.15582852041237086,0.16194877455675244,0.11159349595438199,0.13506459879171612,-0.07189922839782634,0.07209696917213175,-0.02619208821881583,0.012937409249244813,1.0,0.0015396637311461208,0.033312520307694424,0.03089182532493982,0.2420465829729501,-0.1408834757132344,0.16975969256400986,-0.06951914435724571,-0.057162707585664406,0.018579328779992313,-0.018234003072623864,0.04269886456230123,0.13446624051929848,0.07243031946231669,-0.03326981485064767],[-0.010117461874212202,0.2634050112882656,0.6294845711926749,-0.6175728280187531,0.7222828373471071,-0.7135948770783092,0.6883591525542724,0.4654667018667956,0.7545836387250695,-0.26256234864225125,0.7306754283129139,0.8549994274917525,-0.8029747431856894,0.8980285096871252,-0.1176309016943228,0.772827212499862,0.0015396637311461208,1.0,0.9543155538732382,0.9080052100627193,-0.6286869924374915,-0.2230366375690759,-0.12571837036735195,-0.197102501790096,0.033147729256278236,-0.039019733864834434,0.057856973731895085,-0.058361907156783126,-0.0645715359280987,0.012075581558410821,-0.5847280193195425],[-0.003081631978011285,0.2667804528085626,0.6722995817059164,-0.6374435441027602,0.7329961891976753,-0.697199917407915,0.7450192361856167,0.4409187580400579,0.7842252545744581,-0.29143733304581754,0.7545264203922345,0.8527574029838525,-0.7648022499662573,0.8707884682679062,-0.1291957189819088,0.7228581645897648,0.033312520307694424,0.9543155538732382,1.0,0.940932873708031,-0.6004450192237597,-0.22644640422263468,-0.09559862360488942,-0.18691681068939597,0.031498153123543426,-0.062238128143765926,0.0336291121791646,-0.023346602288723352,-0.04527797471006273,0.048308776561764875,-0.547153040560409],[0.006363434523502558,0.28417448544154317,0.676397368130107,-0.6160745454064465,0.6975623200762704,-0.6319268235240664,0.7380328115829556,0.37560473178335047,0.7691646535971732,-0.2646427995761057,0.7015321772034538,0.7963272516813783,-0.6674719735210397,0.7941158590168661,-0.13287384090896373,0.6122698555789399,0.03089182532493982,0.9080052100627193,0.940932873708031,1.0,-0.5606531515497487,-0.20987925787632988,-0.05792054187682928,-0.18118820201633984,0.043846989818581136,-0.0930752534167106,0.04673138990211062,0.0027158294885521713,0.0062228004284199554,0.07843192801566787,-0.4545707267250656],[0.0546720276569547,-0.11206050303151067,-0.32721931718519004,0.23206716780655584,-0.32576070725905576,0.3129042160726141,-0.4190046214534636,-0.21328561089034423,-0.3743526902049924,0.23364539146029906,-0.35338852022487244,-0.4215771077982637,0.39770328880643824,-0.4487227853043467,0.1719765083194583,-0.35654887619457565,0.2420465829729501,-0.6286869924374915,-0.6004450192237597,-0.5606531515497487,1.0,0.05935745632680611,0.14971570994794378,0.17005066900618251,0.0013509223298104522,0.12209682608840905,-0.1582334319563767,0.05631338416958266,0.05938525530802768,-0.06760713996841494,0.26259180333409754],[0.2425003454209875,-0.0435448051745826,-0.3480719043429145,0.3357951421321843,-0.3905553374747205,0.3011282852094513,-0.338418010142817,-0.0423180056913961,-0.42198362347225826,-0.16635441855300745,-0.3722877843205808,-0.3880075778818805,0.2233350985635395,-0.24045079161196992,-0.04251329114925541,-0.1503912017383243,-0.1408834757132344,-0.2230366375690759,-0.22644640422263468,-0.20987925787632988,0.05935745632680611,1.0,-0.4915165068487317,0.3664012938788266,0.19879186087951087,-0.04039779799813546,0.037698300620011824,0.048728961158307736,-0.12421025579782889,0.08694154730780468,0.18360114278243383],[0.06191078844713242,-0.05568522309454584,0.10978334025739765,-0.10168253103512599,0.07245696592720566,-0.04957275729793098,0.08562809379357948,-0.19832103645378138,0.20089505355418527,0.3536698745103665,0.17243649350657253,0.11991787253893085,0.12480015096996191,-0.0778950137046864,0.11904599452674054,-0.20948294656352967,0.16975969256400986,-0.12571837036735195,-0.09559862360488942,-0.05792054187682928,0.14971570994794378,-0.4915165068487317,1.0,-0.6134468713727934,-0.13524689168754328,0.001205983538624303,0.1396381180125809,0.01601633205591176,0.3762354530005452,0.22496298360563496,0.1061489419068305],[-0.052336972295555506,0.0943891888631758,-0.09118529774144489,0.10393152071906417,-0.10431851768467852,0.17488153605886717,-0.12364531866775805,0.1640019235676363,-0.25283888590494646,-0.32626094256188504,-0.27059657612934407,-0.2727231985470627,0.08433261481307001,-0.16803146915526693,-0.07248998647285194,-0.014870877058270173,-0.06951914435724571,-0.197102501790096,-0.18691681068939597,-0.18118820201633984,0.17005066900618251,0.3664012938788266,-0.6134468713727934,1.0,0.20555061240409342,0.005555134541074436,-0.2617162776460679,0.042837328513808115,-0.34620653733569773,-0.18302543570082533,0.0987412369640268],[-0.16872791275617904,0.0761329008760937,0.004506840074018094,0.08769525024708694,0.0051481431757168464,0.016402480970636287,-0.06606260735348173,0.2562839214708963,-0.02300986352738762,-0.30566746167478376,-0.05521255760958656,-0.03611774909514328,-0.06398689615089916,0.013408752210874984,-0.04028434116911356,0.04935750167467896,-0.057162707585664406,0.033147729256278236,0.031498153123543426,0.043846989818581136,0.0013509223298104522,0.19879186087951087,-0.13524689168754328,0.20555061240409342,1.0,-0.008876166283788645,0.08970295608216788,0.02175269401321418,-0.22259319435047414,-0.021892870684218132,-0.04926304608381129],[0.03422384071024588,-4.3366447595242484e-05,-0.07449917823603203,-0.0034330974022567426,0.029982794572505616,-0.1022876397086222,-0.12409374360020445,-0.01778053997011176,-0.03948666856441891,0.03292196954539542,0.038376972809255,0.02673926064071297,-0.12490630339798699,0.06907266143057308,0.01923037583985011,0.1626681000294187,0.018579328779992313,-0.039019733864834434,-0.062238128143765926,-0.0930752534167106,0.12209682608840905,-0.04039779799813546,0.001205983538624303,0.005555134541074436,-0.008876166283788645,1.0,-0.08609207245720177,-0.09094365451778125,-0.17758970482276318,-0.02608258101044306,-0.11048682129500427],[-0.08015537516740186,-0.19717797816761146,-0.10796480987733327,0.13522383281188124,-0.10872832320409029,-0.011844901447120249,-0.11094731811376349,-0.15792780240713733,0.04552138141327899,0.29325424239553544,-0.011200028248449657,0.014741469748355192,0.026155189696097217,0.03654435472147385,0.0038934254876982007,-0.07343224503835075,-0.018234003072623864,0.057856973731895085,0.0336291121791646,0.04673138990211062,-0.1582334319563767,0.037698300620011824,0.1396381180125809,-0.2617162776460679,0.08970295608216788,-0.08609207245720177,1.0,0.04227893622137579,0.1897654062330542,0.11541300710596683,0.028993157505946165],[0.0056947611144727945,-0.0482427097680955,0.05340034734849865,-0.006762917819482421,-0.03201629044032925,0.12734440444686865,0.053724310356477754,-0.015148607383798599,0.011934785330130543,0.01751725552042749,-0.14164243509323532,-0.04566863864618433,0.14151331028962366,-0.09822806130720747,0.02962024227485123,-0.14897012971939905,0.04269886456230123,-0.058361907156783126,-0.023346602288723352,0.0027158294885521713,0.05631338416958266,0.048728961158307736,0.01601633205591176,0.042837328513808115,0.02175269401321418,-0.09094365451778125,0.04227893622137579,1.0,0.14130537595807455,-0.004531561834306878,0.028084251969569336],[0.04776846519710266,-0.1352432886125526,0.10488222915795282,-0.0948638885330264,0.002407775443123276,0.05335539392188264,0.10163330923778294,-0.22426111827259418,0.1545337197354661,0.3823955125131211,0.0543245669191876,0.05333373006629888,0.2197072521656195,-0.0869221238240027,0.0646487692390909,-0.2342262049432511,0.13446624051929848,-0.0645715359280987,-0.04527797471006273,0.0062228004284199554,0.05938525530802768,-0.12421025579782889,0.3762354530005452,-0.34620653733569773,-0.22259319435047414,-0.17758970482276318,0.1897654062330542,0.14130537595807455,1.0,0.12984971984096005,0.10844183334574208],[-0.03244473826374118,0.018830136874302048,0.15190122201809045,0.024285377595784995,0.09033199934504305,-0.0856535462215851,0.13555104103490304,-0.0705804722126513,0.13197050325809564,0.06763824844332866,0.1256157435633611,0.1080111948840187,0.03350945188878915,-0.005741632248737184,-0.07581419979661447,-0.10910160025834865,0.07243031946231669,0.012075581558410821,0.048308776561764875,0.07843192801566787,-0.06760713996841494,0.08694154730780468,0.22496298360563496,-0.18302543570082533,-0.021892870684218132,-0.02608258101044306,0.11541300710596683,-0.004531561834306878,0.12984971984096005,1.0,0.06935034565911778],[0.044921015606160276,-0.17559571415070888,-0.4140652083107102,0.47347489940607695,-0.557681994014988,0.6966875060670571,-0.3610550812177925,-0.4353210159337436,-0.4714169559249283,0.11941393139431287,-0.5525023937721794,-0.6290537687396351,0.6896368975884982,-0.6780600242851847,-0.06188734852264803,-0.7448551993802949,-0.03326981485064767,-0.5847280193195425,-0.547153040560409,-0.4545707267250656,0.26259180333409754,0.18360114278243383,0.1061489419068305,0.0987412369640268,-0.04926304608381129,-0.11048682129500427,0.028993157505946165,0.028084251969569336,0.10844183334574208,0.06935034565911778,1.0]],\"type\":\"heatmap\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.375]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Correlation Matrix for the original dataframe\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Correlation Matrix for the undersampled dataframe\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(255,255,204)\"],[0.125,\"rgb(255,237,160)\"],[0.25,\"rgb(254,217,118)\"],[0.375,\"rgb(254,178,76)\"],[0.5,\"rgb(253,141,60)\"],[0.625,\"rgb(252,78,42)\"],[0.75,\"rgb(227,26,28)\"],[0.875,\"rgb(189,0,38)\"],[1.0,\"rgb(128,0,38)\"]]},\"height\":800,\"width\":700},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('aae7656a-95cb-44a7-9cb7-fb9224f97455');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Heatmap 1\n",
        " ini dibangun di atas himpunan data asli. Himpunan data asli adalah himpunan data yang tidak seimbang dengan rasio 99,83:0,17 dari Non-fraudulant adalah untuk transaksi Fraudulant masing-masing. Oleh karena itu, ini bukan indikator yang baik tentang fitur apa yang mempengaruhi transaksi untuk menjadi penipu. Hal yang sama dapat dilihat melalui heapmap serta sebagian besar fitur tidak menunjukkan korelasi sama sekali.\n",
        "*   Heatmap 2 \n",
        "Untuk mendapatkan pandangan yang lebih baik tentang fitur apa yang memengaruhi transaksi untuk menjadi penipu, akan lebih baik untuk memplot heatmap di atas himpunan data yang dirusak secara acak di mana distribusi kelas (penipuan vs non-penipuan) sama. Seperti dapat dilihat melalui gambar heatmap ini menunjukkan banyak korelasi antara berbagai fitur. Oleh karena itu, grafik ini terbukti berguna dalam mempelajari fitur-fiturnya.\n",
        "\n"
      ],
      "metadata": {
        "id": "ptH7bnZJl_O9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tujuan utama saya adalah untuk menemukan fitur-fitur yang mempengaruhi transaksi menjadi penipu. Untuk mencapai ini, saya akan fokus pada kolom terakhir plot di mana korelasi antara berbagai fitur dan Kelas dihitung. Berikut ini adalah analisis saya\n",
        "\n",
        "\n",
        "*   Korelasi Positif: Fitur V2, V4, V11 & V19 menunjukkan korelasi positif dengan kelas. Semakin tinggi nilai fitur-fitur ini, semakin tinggi kemungkinan transaksi menjadi penipu.\n",
        "*   Korelasi Negatif: Fitur V10, V12, V14 & V17 menunjukkan korelasi negatif dengan kelas. Semakin rendah nilai fitur-fitur ini, semakin tinggi kemungkinan transaksi menjadi penipu\n",
        "\n"
      ],
      "metadata": {
        "id": "AIrKMYinmk65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Histogram"
      ],
      "metadata": {
        "id": "Jm0Ku_qmnYBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Di bawah ini saya telah memplot histogram fitur-fitur yang tercantum di atas. Baris pertama histogram menunjukkan distribusi fitur yang berkorelasi positif dengan Kelas: V2, V4, V11 & V19, sedangkan baris kedua menunjukkan distribusi fitur yang berkorelasi negatif dengan Kelas: V10, V12, V14 & V17."
      ],
      "metadata": {
        "id": "xJR-cdX1n6X4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows = 2\n",
        "cols = 4\n",
        "fig = make_subplots(rows=rows,cols=cols,vertical_spacing=0.15,\n",
        "                    subplot_titles=['V2 Distribution', 'V4 Distribution', 'V11 Distribution', 'V19 Distribution',\n",
        "                                                 'V10 Distribution', 'V12 Distribution', 'V14 Distribution', 'V17 Distribution'])\n",
        "features = ['V2','V4','V11','V19','V10','V12','V14','V17']\n",
        "for r in range(1,rows+1):\n",
        "    for c in range(1, cols+1):\n",
        "        fig.add_trace(go.Histogram(name=features[r+c-2],x=df.loc[df.Class==1,features[r+c-2]]),r,c)\n",
        "        fig.update_xaxes(mirror=True,linewidth=2,linecolor='black',row=r,col=c)\n",
        "        fig.update_yaxes(mirror=True,linewidth=2,linecolor='black',row=r,col=c)\n",
        "fig.update_layout(template='seaborn',title='Distribusi Fitur untuk Fraud')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "6ma-ZbMfoE5k",
        "outputId": "ea09287e-8dd9-481a-b0b5-1a4a964a458e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"7a175bf5-1926-4291-90aa-5b4b9cd91892\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7a175bf5-1926-4291-90aa-5b4b9cd91892\")) {                    Plotly.newPlot(                        \"7a175bf5-1926-4291-90aa-5b4b9cd91892\",                        [{\"name\":\"V2\",\"x\":[1.95199201064158,-3.15730712090228,1.759247460267,1.35836702839758,3.0197404207034,4.13783683497998,4.13246389713003,3.71288929524103,3.80907594667829,2.30089443776603,2.42643280600508,2.00148526626613,3.26158454822833,3.40279371307631,4.09391182702914,4.91785071056565,4.31352332575143,2.66067027657541,2.48195386638743,3.6396539992044,3.44264397684973,1.69569365346656,5.8563932148043,5.79364414692454,0.258555160773118,5.97355569173344,3.91479678866992,4.14198623236944,7.09891625215749,4.19963266902077,2.69386747884008,3.04446910225824,3.10093489093256,7.01671438495857,5.22544230971559,8.28742055534983,8.20479650456012,8.63621438967976,2.90208643306647,0.898474023721059,0.942289402014327,1.11145278248281,9.06761342731767,6.96770866359565,3.85415032971366,6.50318451651946,4.48826730168204,7.47232389650112,7.42136996239257,7.87515679273047,8.32658106147414,8.7759971528627,9.22369194937548,9.66990017304097,10.1148157246654,10.5586001882538,1.33897371069007,10.3939171427504,10.5417508026636,10.8196653713117,1.13014648418496,11.5863805198184,11.8179219897853,12.0958932259299,12.3739891389716,12.6521968313004,12.9305051249875,13.2089042844176,13.4873857909274,13.7659421584186,14.0445667815106,14.3232538097233,14.6019980426299,0.965681439446855,15.3658043803315,-0.0713403777285035,15.5981926625554,15.8769229879536,16.1557014298057,16.4345245512223,16.7133892350242,2.82916799881581,2.60857946990866,3.54975512877325,0.34404807190464,0.885657038258755,1.72873464521162,0.0202179180614602,1.5548897630737,0.416413936043849,1.69987344643198,2.59145816263611,3.13178963278262,1.49126972926361,2.70853541135777,3.36830621710984,4.04560138120513,4.14086717613266,4.51835470349753,4.38289736244467,5.64943864783758,5.77651621042963,-5.19836019923329,-1.64354066791439,1.17950120574809,2.84479469928473,-0.0147931576652609,0.520539361927579,4.10487145129475,3.36734230912012,3.65809481979987,4.51904694695796,5.08369023030901,4.14594361146639,4.57174320411303,4.75051466030858,4.96089229123138,5.38101952251685,6.24165891255794,6.14765332384605,6.61328394324752,5.9183066586857,6.30238478416897,6.26158585106885,6.33288209288301,6.57461542943546,6.72050777097643,6.99038924197379,6.34428045616839,8.07523975163174,8.40142101040258,7.37804241221284,8.58497179585822,1.30021877705413,8.71325017095966,2.978121790406,1.0734990949761,6.15577293013926,9.28684735978866,9.84315322329519,3.35345148012501,2.09815186657166,3.37511020399082,0.963031254092613,1.64804777413239,0.811069300236989,2.42650326490524,0.716241580332591,3.66339525318756,0.355412643473604,2.12231379246165,0.047938380305255,2.30849245367643,1.78649494921925,2.13243062687771,1.05954227713479,0.557090903443645,1.39000150924187,1.44352346510311,2.24411874456383,-1.46426898705405,0.524525772902587,1.39436766175691,1.69422928947167,6.86619841481805,7.09219680097303,7.36554648639464,7.63974510878724,7.91463349246877,-1.63244121283891,0.407227280182074,1.38735982061524,0.417447287721689,1.2176203228402,1.34452078912347,1.26397355628777,1.57357807373238,-0.0008912294816884,0.577609830544052,1.46871292315117,2.39704134824746,2.94820920837905,-3.93073139597263,1.95609915073809,2.72047248689249,2.79103028235041,2.40082554709233,1.81235458422751,2.46267526851135,2.22537994112476,4.54367201286394,5.12575923008793,3.38613996883911,2.01523346310003,1.27139528958141,1.55276821126964,2.22514650025341,3.26466481012305,-3.34843873033788,-6.97642000754641,1.28663756547088,-4.81446073955621,-0.364223121381638,0.581573270980264,0.68382137690334,1.50515204317029,3.1298519330804,2.60772002929222,1.22131743135767,2.50671895922695,-0.285760408166142,-0.0855947885921835,2.94149944882418,2.52282067569291,0.872988038728802,0.962830680816555,-3.4204679837707,-0.571085006532232,1.52483716405302,-0.668973794096954,0.78144226309285,1.39934474808556,0.403326526860602,-0.0454102784513458,-1.30465465035444,12.785970638298,-0.548931183157109,1.13424300279892,1.13723897606434,1.63677796226183,1.13313858781029,-0.457654560738072,1.18975728641634,0.185734554774403,0.194120636801706,-0.257575207100777,1.33566696241079,1.80869795041448,2.36575487772312,0.985632693552081,0.435519332206195,2.34694943137396,3.41891065333381,3.56875123426923,3.48062317879011,3.56342789803106,1.29119504187036,1.15643107873873,1.09486151295003,1.07967115744319,0.608590312773943,1.29185826269199,2.26827061391536,1.43530513012275,2.77308160372497,1.88647569827836,1.03612940153875,1.79064923163963,1.97552752738073,2.42837911824053,3.46288948991687,1.82762056700016,1.26441977404559,-0.802528699267131,2.09615030972986,3.42199090467553,3.92110415204576,3.26657425418237,3.25907610397605,2.92854110729003,2.60912703784891,0.94520635153406,-1.15597800832635,-0.45806896998712,2.63288131193679,0.951966571156228,3.73823496480673,1.55496360697718,2.88180518239049,2.36518252886777,1.63005630331209,3.63344238024837,3.44895257232738,3.25389242362715,4.4011941515981,5.66724730913206,5.43726336227612,5.8907352377921,7.10298492227346,7.1515323543223,5.36741605145469,6.72746568826853,7.25193622855414,7.35214833905529,7.50878980635543,6.1391827154247,6.48309458751086,7.1919501426236,8.21302215295327,7.76395304621262,8.21517673687939,16.497471901867,10.4325276778611,0.0248807914815549,-0.365518405631879,11.6148005425867,12.5721178535385,3.54138524292281,5.42646054559111,4.10787318567637,12.864988563015,12.3525186682391,14.7063346696674,15.53613332478,5.15109356872598,16.6978316913154,-1.09337687781209,19.1672390103062,1.1453810871791,21.4672029942752,1.49695912243222,4.0664132778545,4.06404334190313,3.74030556080113,22.0577289904909,4.35901910783724,4.56964856472544,2.87112058054735,5.22219270751471,5.2133398229232,5.67813391258695,2.50022390414582,2.80929887414381,3.34685000184439,0.650677737498259,2.23275183861699,2.10772866087808,-1.67492805871463,1.08868850191044,1.33351901279168,5.31338185985134,5.52929920087665,2.2756363708417,-7.15904171709445,0.415616496914758,4.43991138307409,1.3422122564916,1.07309853428207,2.99449857558056,1.92765003845063,1.33765782444144,2.76253994253031,2.66427399774238,2.93522576984167,-1.64676405421121,0.0492431315858544,2.48710339519253,1.8564996040552,3.05725030538059,2.28498795250353,2.618584398377,3.22594669094366,-0.51942947320952,-1.23755547027318,1.13347191665669,1.86137334473124,-2.48482353043406,3.14191813880044,1.53170785726036,3.22201046223725,2.09801863238761,3.23806951076392,0.938943680000523,-0.124051888133202,1.7654516187093,1.18363142021427,1.94810044909488,1.74636046414013,-3.95232008590575,-1.24493887246577,1.1001181155631,-0.751792062726136,-0.228062380877632,3.2529263650346,-2.72266032465254,-2.37033515007664,0.76676154669164,1.974141135114,1.86341353532436,0.0992494427033949,1.66171286952217,-0.922135693038651,1.37376948070694,2.07443887131076,3.31249456257958,0.364541282922338,3.67657741239774,2.94382338959853,1.65851450876035,2.84902401493181,1.90580604250552,4.25118050159519,2.79541433019956,2.62973923034009,-0.408409922870926,4.36280068444382,2.72680028914035,0.727831411106392,2.71585507956703,3.68287614423407,3.8467996764866,3.15208420536211,-0.0254646126717458,1.42110000741665,2.37982185248504,0.74533277919767,2.18791662800118,-2.71426804459821,1.06959286384179,1.65909255408015,2.55133767783118,3.32956068110382,3.83594330652809,3.19993870654465,3.29943622098785,3.74859690056241,4.19597576169878,4.64182734988813,1.31042652386526,-0.843910597775511,3.16472117285823,1.40345824321907,3.69877241384725,2.21907469290599,-3.48813018118561,-3.93591892431521,-7.44901515872674,3.04150237620527,4.67255275192187,4.82706041999945,5.26231210944906,2.61710490740972,1.36307703789779,1.32562957435462,3.10670266443901,4.60150558710842,4.86453518123444,0.141547455482355,1.1762702245705,2.50103820829712,4.14718554774299,-7.19697963053735,3.13294449795257,1.51260401518904,1.59682357624614,3.30938527728796,4.70005527392636,0.705607819703042,5.00235242592827,2.71988211593934,3.97788074139497,0.623013013517624,-0.360628009949399,-8.40215367768915,2.36159360978361,-1.13189035724166,-0.757459362256544,2.79318461104641,1.12565266367046,1.28938093711056,1.1263660623459,0.58586417180689,0.158475887304227],\"type\":\"histogram\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"V4\",\"x\":[3.9979055875468,2.2886436183814,2.33024305053917,2.67978696694832,4.73279513041887,6.6757321631344,6.34855667313983,6.07826550560828,6.04744510216478,4.007682804682,4.41666124290876,3.81919458538265,2.35709625199132,2.62536815276644,7.38024451788662,5.70150043141163,6.79679668055103,4.52249960508858,4.4559228120932,2.73066814884895,2.80533625940251,4.32819855298178,6.37974188053221,6.39582974649419,4.85389435139681,9.00714687170235,6.09414095882864,6.66627300324451,8.60755678650129,7.42694037455047,5.4676845487781,5.92819080241929,3.26463274045175,10.3432280604117,6.68995065770063,8.59434189301081,10.330099825448,10.3133493732845,2.507298518227,3.17025757451452,3.02404970580847,1.73159516277684,10.2966027898053,8.61789514115238,9.64831072711484,11.2703523334822,10.1072738734101,11.165525840514,11.927511869244,11.9061699078901,11.8853128922128,11.8648680803607,11.8447765860728,11.8249902296814,11.8054692105913,11.7861803616399,3.1236723071222,6.18596883540498,6.0172946473619,6.04661174671427,2.67568785863118,6.03851541556808,6.0862356342864,6.11554110191771,6.14482097803751,6.17407791004356,6.20331419234722,6.23253182330679,6.26173255148578,6.2909179135006,6.32008926518927,6.34924780743689,6.37839460769688,1.92186300234526,6.37089534679314,3.36177713733967,6.41844174657532,6.44759140152748,6.47673117996833,6.50586178736296,6.53498386355181,4.70769143992869,4.36008935234848,5.80936957402456,1.72168007534123,2.86129223993172,3.81354418795523,2.57204626116115,3.24161746276725,2.52086280678918,3.64394526899047,1.28624391005241,5.42094070941518,0.817253270463702,1.36186594394607,5.62311973109633,5.48719863078843,5.50567203744754,5.54745334718879,4.45522984017686,5.25284201867297,5.90271545151069,4.42066620155728,1.15825311047012,1.99882440095464,4.77770088131929,6.94512997633611,8.00535147326105,4.02839095079544,3.85970067435928,5.34024166876747,6.21476727765717,7.54603279503791,8.34439167363678,6.57705643811276,7.09885431317009,8.1748251681484,7.96392808742307,8.19961393161759,6.70277957100753,7.51992923163014,8.80736917876038,8.92511547634157,7.18360208606589,7.69077191542072,8.7862568391843,8.69861009281133,8.694896899191,5.58100899740718,5.66482005292134,8.25233430637468,9.19493491430021,9.50559351508723,2.58984264330545,9.24945923683651,3.86912437879902,1.38439373061694,4.1807791786876,7.81867331002574,6.15578864849515,3.61611930403552,6.45658840962748,6.13637764344382,4.9559633578155,4.89460056642244,0.935264670223385,0.27601659835291,0.217804800631468,3.88095965427288,-1.2555927126284,1.20184879823143,1.49395843665091,2.06410058377601,1.21433549160762,2.11699770636107,0.905586233912649,0.756424293386678,1.66142517591961,2.03698508634993,1.49253586483501,1.9213560843992,1.20919597418592,1.04932705568948,2.42543608490852,4.19421096699453,4.24306897383907,4.27332307326376,4.30340291762786,4.33334117975523,0.847752885502341,3.16182144737059,4.22868619369076,0.901644194576026,2.08707599095328,3.19529149873811,2.23799063903423,-0.572676430720841,0.338337780759695,5.15940136394611,5.17470627250374,5.17781925521834,5.18530347959595,1.71466918264498,2.79698655025108,6.34833355148109,6.99121396498416,3.46221746352071,4.12754860722303,2.3244800653478,2.17853822878821,5.50800333404763,5.52739306209755,4.36762905773351,3.81202413104427,0.790371244425149,2.99211739124618,4.34222824814605,3.40359359659281,3.17505971028128,3.41675415987856,2.41967479633278,1.20422986423394,3.79494903930385,4.31924127992395,1.50188726081003,2.28686855813503,3.41557336328899,3.06415614684784,2.06757505760281,4.8861341982102,5.33704802681048,1.40116573166082,3.25884522291112,4.08304665188122,2.75536885087579,2.74331806279958,6.60684578567387,-0.0145876823031251,3.28929147538496,-0.589439741635524,0.605760683474701,3.86437703955242,2.75655816357726,-1.31327481447103,0.0537401062585881,3.32033688288942,0.894081819978967,2.01222598912655,3.24229293383089,4.02857099852445,2.81340096831714,2.23077826688105,2.89138777331251,3.76115529034876,3.92074784640417,1.15267090326627,1.69388472852407,2.21308539346999,0.0897905975142065,0.317131047127407,-0.471119606930407,3.98335888025187,4.03598694267746,4.16471993013258,4.31123366835313,4.28434595524384,2.05820222243243,2.07627840454674,2.01255429562949,1.28783908383189,-0.267565092666965,2.13577170090141,1.87133052690782,1.99311717679272,4.44645597412376,-0.475242891532036,3.12824327369048,3.85343274655953,2.81919063998449,4.87129854095106,4.9321986662268,5.34830323951426,3.19364784504611,0.389760264731692,3.06945315960973,5.27089100906596,5.14826254938013,3.92452561357555,3.68473739367705,3.89115992835328,3.63194695349796,2.64006508673377,2.78675032975706,2.73722917151503,3.44611314661501,3.83399771227534,1.36744244056479,0.669327345741316,2.43418142416554,1.11160176466249,2.37836729179698,0.183208447320966,3.02105161812575,2.26645647990886,4.45357956949695,8.24614693395311,10.3072263079132,10.2590359766218,8.01082339822486,7.03111476501099,9.06447791765316,8.42583167857118,8.20414440620562,10.6485054461688,7.46577999198461,7.74055544506762,6.55419115286706,9.09955188204157,7.11609059812684,6.71185525207739,6.20736889019759,8.90415677106517,8.04607504591293,3.78754815533943,4.82088596439253,10.4638662754002,11.1908946558522,5.95566359407,6.67906180701896,1.71031444791959,11.3451198184298,11.1227714331133,12.1146718424589,7.04337354768731,4.53447860064768,9.5849686202149,1.06478463530602,11.1254347149714,2.09180337375362,11.7374361361796,1.83672705849852,5.89860229319899,4.68000806392241,7.44096403590735,11.8450129100508,5.36402677044258,4.44107935434428,6.89095207502484,8.11772427554261,8.43198635177602,8.41629539413803,1.18945163355882,5.83556642595055,6.83580203854396,3.98782809057201,3.38670841159996,1.41130357398271,5.6175556662941,1.00873271714408,1.83500588341825,6.02897499089959,6.08132107951892,1.22694819658893,1.30957974749918,1.53684419661661,7.78868440738042,-0.151513299728476,4.17326819444992,3.98651893184362,-0.0739425941379643,3.24535764512838,5.20140306725894,0.394707094952515,2.41901198641213,0.473353567439937,2.86546277005979,5.32454683526606,4.10009796977678,5.54397248278589,3.8311119987993,3.55245370976796,3.59316052421617,0.774741045624737,4.83349012798216,-0.283072525739314,2.44808047483365,3.67056244781436,5.5218205893507,3.58461483133399,6.03734512826846,6.5145732431847,5.7208466769739,3.07984368774547,0.382608915041756,0.9874099790721,2.17990251484867,1.30580476704534,1.7722054455123,5.15352461752314,4.54477220840185,2.20471352581391,-0.203459370656895,2.20188352154659,4.63241097983647,2.50200470213773,2.33504453116197,0.116771978233793,5.39079309979716,5.46368064632147,3.40195536781235,2.55505843390024,3.37300132781874,2.80535094114905,5.44805969239449,5.03698507739508,2.40003149118237,7.23205827524957,3.53337387196109,2.05206440242466,6.00941477810058,4.50891315092218,7.28365703710757,3.24751301512342,0.694992040498764,6.24946176104187,5.30453432323767,5.34275900861121,5.92484984705884,6.31066097414859,4.01673095104413,3.12145858452036,5.53125220648323,2.65053018469314,2.94294608011161,3.81839172249665,3.89355597724996,0.119476214172018,1.44979237466742,4.61740996943795,2.58803264715889,1.63696695878653,3.6017196361428,1.84411148322924,6.50233023566696,7.78363417666419,7.76324179132026,7.74321514676806,7.72350199432307,2.62028192286183,0.75975906867787,2.24659736005894,2.66010705652321,5.62048638535855,0.236995179253694,3.24681566349703,0.163310074791927,3.72843914957409,5.9675870384467,7.1435001202707,7.3340585164719,7.31648729995658,5.84296995871769,4.17351574396431,4.23315121365749,3.10990342442989,5.71608803673092,7.65239936205533,-0.457662244561315,2.88213779866317,5.37416005823382,6.49374059630435,5.104798647287,5.80389261500645,1.75379247237301,2.51298558446866,6.39457369583463,7.67188445074794,0.514779310643757,7.75691471173633,3.04443718621919,1.65776584508859,1.67888930740175,2.48610285639632,6.9509829448522,1.9707587789256,1.08696263677666,-0.755458092963448,2.40073141993213,1.74929253346589,1.4118498419441,0.46830838758824,1.81709247345531,0.408669992998441],\"type\":\"histogram\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"V11\",\"x\":[3.20203320709635,-0.414575448285725,2.03291215755072,4.89584422347523,2.10134386504854,5.66439470857116,6.75462544809695,4.56072010550223,6.43905335158373,5.5887239146762,4.67572941865677,3.57205481558784,5.45074606689486,4.36671348631445,6.35507773663404,7.38805512292025,7.62008905836908,6.66243683071252,6.45418752494833,6.35361231915591,6.31620967716699,4.80232276125089,7.10298858788516,7.07166913682445,4.69039566550924,12.0189131816199,4.65408842254301,10.8530116481991,11.6197234753825,4.57011280759332,5.27550585077254,5.14940878300581,3.18718689736493,11.6692047358121,10.446846814514,11.228470279576,11.2779207278067,11.1524905985837,3.33850216040272,1.07272839973578,0.154921008931302,0.500376369958899,11.0270590938161,9.36907905765884,9.32879925655782,10.5452629545898,8.80568196718575,10.2777688628065,10.1875873241664,10.0637897462894,9.93981974172569,9.81570317447819,9.69146098207319,9.56711029521397,9.44266526535108,9.31813768535999,1.124059382453,7.39441941053863,6.32936467621872,6.21088301172371,1.83449419801385,5.96620250720685,5.8492930661792,5.73081553744459,5.61234710799626,5.49388683652872,5.3754339072439,5.25698760960799,5.1385473219039,5.02011249777419,4.90168265513877,4.78325736701241,4.6648362538527,2.35161910622909,4.41994345577668,0.987277021963291,4.30309581759563,4.18467368942509,4.06625507293473,3.94783971729026,3.8294273949908,3.79256535985687,2.11151686706104,5.47939151009669,3.02816223099618,0.675287853392807,2.36843367282003,1.97582106179607,2.75617194535395,1.1205051770709,2.80200512615164,3.90739912775712,4.72997415443333,0.0243696057661544,3.77974953895486,3.83978771072745,3.77960220775921,3.53820204012168,3.36784560815482,2.95434436554049,3.6573495649865,3.67670318691664,3.26606601582438,0.159743522312315,2.80433477984687,1.84409317018026,5.73008435556377,5.73576265915634,9.09528815249629,3.82376208408163,3.96979981229186,7.2529532268294,7.38185937432083,7.67453383416429,8.26529460055417,6.87757089846463,6.45582813287588,6.64520072606617,7.04773274001302,7.60555947435276,6.89518136811315,6.85495311388866,6.78605830197451,7.12716532148781,5.80470785195987,5.97513066688423,5.58936163192341,5.3306013514672,5.1483517210937,6.03766622940467,5.61099879659254,4.82823533219729,5.29923634963938,3.49080495043995,4.39243558567834,3.47109784646449,4.35477463025116,3.18605794805635,4.81815244707108,4.67734929657245,3.58682418337431,4.38921350258246,4.09721607443527,6.27866584548672,6.28337707847689,2.77896789639267,3.65788166668826,3.36736102310858,3.52572598717089,-0.473852105914046,3.53221960237349,-0.984171728067149,3.43824825990431,2.96259879138962,2.88704787664695,1.48028602025778,2.28193937592012,0.141178993422237,2.81431415481622,2.40165068027699,-1.06453419450651,-0.668358831257417,2.5555891530874,1.96223597455109,2.94398521977131,2.82667122820047,2.70785640511515,2.5891035399443,2.47040101557896,1.17235508293037,0.90311745288141,3.20091235546057,-0.876737591678351,2.82114488798301,0.747478135782509,1.17447506014201,2.37853722491518,0.0045179679664243,6.25006758982915,6.02903256317613,5.76318940883843,5.70520550718269,-0.153131026660117,2.33832327000211,5.26658587269696,4.77414774007074,3.26492215161104,4.31571103012142,2.25514748870463,1.83721490161197,5.2241240042156,5.72525459149638,1.84750351109611,3.55473755027372,0.614977120327696,3.1284396921776,3.76230638231684,2.88609147657536,3.06424584128211,2.61176184321338,3.5617949640183,0.144562690111297,5.04075120270381,4.83896418696128,1.91445404493049,2.79039639060721,1.39818511854919,1.11335409263987,0.915947028928619,3.54601225001006,4.98601380361468,-0.921051995675577,3.97722223959189,1.53319383793753,1.92856763203456,2.14005681553663,5.26786160380362,-0.245676823310174,1.27720226474415,0.881268050432366,1.61826162043188,2.6215881261205,2.56070020158284,-0.651414013964987,-1.35655775612738,4.40680552357904,-1.03941706835478,2.19166507997652,4.66325458481107,1.60198538284757,1.55375586796783,3.51034756034463,-1.27393508028395,4.44719176626515,4.37690666362302,0.82637484441332,2.57283021584331,3.1020899271543,2.60516857519668,-0.39560772252726,0.567551954604602,3.04839203447565,3.77557843937585,3.70431215185119,3.21126387844398,3.25959475409854,1.0804386160969,0.763204840843787,2.60593702345612,0.706999574201444,1.50062918076179,1.35275258963919,3.35763973653551,0.273983570211148,2.39416766551329,2.50978140392157,1.29341829662131,1.90428359307622,0.301368829965399,4.3437434980468,7.18296700883659,7.19030608944843,5.41604190908794,1.27462907751277,1.8806015528528,6.30904400603177,6.34897930341209,4.52299197543382,4.35148149710451,4.22130410784879,3.36918605153883,-0.529805728295342,1.03303201224459,0.504116141204789,4.25656448730292,0.301977229683697,0.382172176843061,2.20944075185923,4.921657447038,2.05681205985716,3.50456779253823,3.71921153916465,2.42595071598052,2.71273940377591,9.41303953977606,8.62125508140256,8.78878366710272,8.87947566765026,8.68830799242781,8.46024444901677,7.15408284221914,8.03070840755191,8.38914233451929,6.35722736343626,7.61081978841573,6.98988561330738,7.58874088021049,6.05731930477932,7.42580096307482,7.09318207259894,5.93465734341534,4.41999660154863,5.90239975502551,0.7653541419638,0.637766685379952,5.57362527301538,5.70211147983179,2.02467408050134,2.54083553206878,2.17523030559549,5.56925817499418,4.41705461009659,4.971248707036,4.73958247105186,5.20081516878268,3.22323270290842,1.36858453419511,3.7859770496129,4.87197985976052,3.40932261990014,4.28702087961434,7.02127774818005,7.86446740028511,6.82579316213884,3.48195180343701,7.34365210856032,7.00213577397937,5.35088988417692,7.18872396524447,7.15062516950116,7.05106508958574,3.69471123994721,4.69879549591235,4.69653339192897,-0.427567391481657,4.54630106888309,3.51964234486905,0.606910821999133,3.58604242366444,2.45371037821171,4.43173633655471,4.3150759158968,4.17609762346479,-1.39432826167269,1.42841254547618,4.22041859352387,1.3415717221686,-0.408402781057003,1.84607851719332,1.28674925677162,3.61264534637429,2.14393063330902,1.96148093151336,2.96924007367485,-1.54230486820434,-1.12757349175133,3.6195974073081,2.99348883356357,4.51335526006987,3.36955824955852,3.27754628526759,3.24943114650197,-0.375466188651408,-0.0001211803349648,-0.482409384022894,2.22296005779154,1.73812401383737,4.77672033006624,3.21163365301808,1.51389817939856,1.05148630261883,3.39415208597649,2.07411645462861,-0.491112318271443,3.28282460993431,2.86702850008408,2.09307500991474,2.4507521592725,0.983646778914785,4.18216236800046,4.49792897288062,0.253931337415353,4.22915426403483,2.68057817990216,2.9456208658257,2.94293916487767,1.20030360709416,0.195839103876469,2.37587561688329,3.72393253444097,0.997448763245357,2.73157578227581,-1.70222840135659,3.2740753098509,3.94231582587852,2.71069667870109,4.21321289394162,4.4045784815908,3.9168025570096,2.94119009271712,2.22079491381924,3.87116530391397,3.05365441815753,-1.59425779202416,2.11390001406861,3.53614548208968,1.99136063471588,3.69317394224412,1.2038344844503,2.15579608547647,1.92718574923744,4.7365938426554,2.85877650156878,3.34180192747217,3.59279683214404,0.613867739096179,1.90399926160786,-0.448793725596362,-0.688453906925825,1.43932206570096,3.64225693939881,3.73703768128326,3.35972193954249,4.56919375212135,4.60417047790948,4.48003526995735,4.3557700196603,4.23139330449617,0.470864719590572,0.0110374511201705,1.86359573670074,3.64647783754223,4.43631907416962,2.21400028680889,2.94437484242405,0.71387764641859,2.52894302060173,4.90581986504193,5.78365443891613,5.71631869503674,5.59112619350265,2.75783745850663,1.70189470812283,1.45123754814542,3.58639450927204,3.8278680907164,4.1064045585523,-0.800150416391868,-1.51420473629918,3.48060170327307,4.46946731169238,1.1682159434835,0.757063214391669,2.17297610055437,1.96612345703981,3.61873721262172,4.54849458373201,-0.191190536963042,4.47590467269415,2.28802174654208,2.98962640655731,1.77950450310136,1.05410721205494,-1.47514531556892,0.874051625366684,1.03201558219625,1.33831754595819,1.24195817554592,2.1157951772133,2.8584658156696,1.79496896856641,1.93351953683592,0.491140241656789],\"type\":\"histogram\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"name\":\"V19\",\"x\":[0.416955705037907,0.283344830149495,-1.33444106667307,0.308333945758691,-2.72185312222835,-1.93466573889727,-1.32735663549015,-2.37059945059811,-1.80801215867357,2.2501232487881,1.55419726345897,1.11826355175812,0.351948943356815,-0.265421595374812,-0.0897244112241547,-2.07145048844325,-1.31449509665307,2.17738568653903,2.26298478762517,0.357987030484253,0.364810482193887,1.74050729036196,-1.38218756352589,-1.38555780172735,1.66339401354543,-0.410480977392724,-2.00547660274646,3.16699890688552,-0.501750653452579,-0.287188855297045,0.991486122257293,1.50492485905709,-0.662462068430895,1.2702262705049,3.12692935212663,-0.574675143795817,1.19726633504633,1.16202614780693,1.95922405409272,-1.53270721248432,-0.865104609842214,-2.54852159198286,1.12678437819631,2.38280793552097,1.60687003263877,0.579200358016368,2.06937744931751,0.604625910708604,0.753149847889189,0.719787682108791,0.686227163597458,0.652498045264831,0.618624412799665,0.58462597267458,0.550519004149565,0.516317073274611,-1.56381522671193,1.26834277321029,1.43226792970939,1.39031436050276,-1.30699464468423,1.32116655982617,1.27209136353211,1.23014255193802,1.18820420779718,1.1462752482696,1.10435473489394,1.06244185030067,1.02053587929144,0.978636193358608,0.936742237936608,0.894853521838799,0.852969608454831,-0.385884175181753,0.783577593799492,-1.15585017273094,0.734573493016404,0.69268841200477,0.650807370688892,0.608930080519071,0.567056279787444,-2.67995024218857,-3.28615008214787,-1.95429995537505,3.0016850593747,0.484758940230455,-0.90268980289448,1.66926055335833,-0.686196723569762,-0.655269928208246,-0.124137989024621,0.17774563450317,0.432054206519352,0.38676063692414,0.132330776389272,2.41438956859515,2.8921696850147,2.46384303909831,2.52578492424474,3.62333181402755,1.64541389333247,2.62662452479163,3.02526099185501,1.4060448737262,-0.888087464222472,-2.88977035831304,-0.688720555143152,0.0929734778841175,2.9951111673215,-0.871581688476025,1.12659865645629,0.787578807808201,3.66952343976659,2.99255446334225,3.85637474254372,1.95189049542104,4.03823050489431,3.45394255518458,3.20430921695579,3.80913643570604,1.85246698871594,3.11847976563045,2.87235363605874,3.65678707068496,2.10273540686125,3.33103902941017,3.62971365041526,3.51761050964655,5.2283417900513,1.16906441801605,1.24351749943488,3.18355894967976,3.10173536885404,1.46108031890323,3.25653448060821,2.04269768780688,1.29616504982889,0.718555009324824,3.32675827497024,1.1266403652792,0.936939858866071,-1.06302761603247,-1.43960797610281,2.6304759946371,2.59017338411194,1.08340676372199,0.874542948076265,2.10905264474381,1.14787783834912,0.574335960915453,-0.289935891439032,-0.298920455435975,1.16012029433585,-0.23930965408033,1.28596139472532,0.272698476205832,-0.511210088142662,-2.19176427800358,-0.208809536741974,-0.0958074336903356,1.40357376229763,-0.73174984602915,-0.0017219235416342,0.139687230416985,0.645904895509124,0.596364320528384,0.554027499068527,0.511761951503497,0.469554313978012,0.476859902488945,-0.666806394320072,0.0346554556282822,-0.0644929660672327,0.572791028207014,-0.603726269220942,2.11863332532912,0.860211793588662,0.0725498490088206,2.18142273556017,2.64398422133793,2.46519487038601,2.35202964025176,-1.23138550165184,0.93023918577297,1.50425021091709,2.83699299496563,0.0802807729992116,-0.440434552920779,1.71549441975915,-0.450550113544917,2.51343040062446,-2.02888535240153,-3.60265725092653,-0.231198386269899,-1.09619645414336,2.15221455770756,2.31416486951171,-0.531558760456647,0.595629103995644,0.254771833248553,0.22842274838649,0.105878827218844,2.59857755637223,0.606452965011177,1.54523326964355,0.79514422023384,-0.133819199948815,2.03059193793375,-1.10076358353881,2.68112678165858,1.43529381015392,1.16443546519237,1.76361087438004,0.831623853010765,-1.56869755794851,-1.57707047840184,1.33293006548133,1.22602219788409,1.1764455977519,1.19012126352217,-0.09472379272847,0.288846910516582,2.69080834203374,0.68705620239513,-1.55456174696529,0.0515761185277783,-0.728989760343786,-0.443999191918561,0.291250739005026,-0.136117269757132,2.30361261010114,2.78338340771804,0.329826631850516,1.19160626766329,1.23304434947994,0.407187527410462,0.397308037124058,0.933262164554872,1.58958220191211,-1.08122326117298,2.50202738858443,2.52496746940249,1.88404425730219,1.73797600497073,2.19728771323892,2.14350179519978,-1.10727585500251,-1.09471647432252,-0.880812102847679,-1.53933883157799,-0.896071786353489,-1.22925431837217,-0.894893657235367,0.26084733041578,2.43127449162965,-0.0095336065683719,0.223718288348024,1.73238175785046,-0.927124072666602,0.98258385892977,1.00766725992114,0.844059610296466,1.38560952778492,-1.14037564250718,0.779950535234061,0.876018768156628,0.897402406121681,3.18415235636348,2.33675362049059,2.35591891159776,2.79433340410919,0.913175997078955,2.22616065557659,-0.94351353548825,2.99317350708135,-1.15062735713932,-0.581355690647057,0.60039728842723,0.174840185624481,-2.24107485298106,-1.1962847755939,0.407805060819919,0.37371480785248,0.626059293435215,2.27422550991903,0.15601503277122,2.58609321670737,2.50082720798487,3.51795494036344,4.00892074227194,1.9823563171714,4.1300314273319,3.81304079276336,0.623796611777714,1.57369789640089,4.85125513655685,2.21175583268581,1.17118873250237,2.27108150670047,1.94169681013401,2.55087034384644,-0.567939572890149,1.51769533116994,-1.91256263382671,-2.10358290329291,0.169740705598221,2.16209864550609,1.56212955232854,0.148592393859995,2.59445276115475,1.66102935873752,2.43582348553379,1.42263161326029,-0.129188144339879,-1.37551765637273,-1.24328515722898,-1.65176618071699,-1.25446534452587,0.252273565031692,-0.248828402209821,1.01162645030639,-0.507536514254236,3.83298514230067,0.0653171492484702,-0.901040817847599,3.37971333584943,1.48227743472618,0.510570181831806,1.95874993153475,1.5604792800844,1.52573244095261,0.0038960221310578,-0.585321852047277,1.80401333906519,-1.6840216339214,3.52773827223549,0.795448867520342,0.752760921550722,1.71709526842855,0.520496923051347,0.936966154656013,0.886746966076448,1.27132193138436,0.0575510393537501,1.31912362938259,2.79789150183086,-0.917407954929339,-2.33518537609962,-3.68190355226504,-0.716811424575637,0.0982420128901166,-0.376135682527478,0.267914551538718,-0.183180903717309,1.08428646665042,1.79092414652793,-1.35984389291856,2.35115138243805,-1.79673863123125,2.36229077589933,0.170143879416802,0.524007524087668,-0.00202115788658,-2.3007976756963,-0.391047742407487,-0.559479810847182,-0.559132202274595,-1.87401526330162,2.06569197047395,0.994829500437418,0.952141057235768,-2.2213838533863,1.97974707098703,0.189130835579419,1.50157346167502,-0.167199797868911,0.152892032043683,-0.663370800920003,1.06015422605258,3.56973257751778,-0.17381402447058,0.477521452443793,-0.193132205838334,-1.90979861946686,0.596696430089622,0.71833237368083,1.02892683645358,0.506039978517755,1.81901276401306,1.93037970885184,0.32519494288717,1.98738627690236,-1.49715223294239,-1.17779250651196,-1.55653021213315,0.606570797159568,1.60929290421203,3.49006859270908,1.14847293881065,-1.56373996709776,-1.95006033191067,0.242162496030838,2.32892697361116,-0.736110693106424,1.70168502365985,-1.80233249695937,-1.46691055321726,-1.25758897993879,1.93548375407006,2.8686028948655,0.971906321717639,-1.80557671393198,-0.13769358207354,0.685510860299876,2.3534526931986,-1.61692658827377,1.49032876283779,0.982728632705372,-1.92330893857582,0.0284845308917937,1.35674828969143,2.99524475453849,0.235226841085862,-0.215409738450978,1.14778361222539,1.11403305037529,1.08013289303778,1.04610451099676,-1.48943421708841,-0.45793403989618,0.0135877061935761,-0.300930778531616,-1.08520791024384,0.38526260953691,0.0833797227600835,0.731998749113651,0.136722438174659,-0.819371096333784,1.09382579750391,0.832574035012694,0.797641375455208,-0.820354414754465,-1.59744021309102,-1.53016232603362,3.0573817418767,-2.09738547120766,0.502453451135321,-0.0513220971157383,-1.76235002438458,-1.16441437126035,0.707199945685905,0.421144082740547,1.24714263088632,-0.526280794204029,0.626240855695279,-1.01863859540215,0.78808629554402,-0.221267207742386,0.647708880496559,3.53100289778427,0.434072536887008,-0.30860899195249,2.54831265500006,1.30794073758635,0.527619755594392,0.87334427153726,0.423099369076423,0.42234244481934,0.391167040935071,0.737657217477667,0.266272320267649,-0.0354803664667244,0.593508846946918],\"type\":\"histogram\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"name\":\"V4\",\"x\":[3.9979055875468,2.2886436183814,2.33024305053917,2.67978696694832,4.73279513041887,6.6757321631344,6.34855667313983,6.07826550560828,6.04744510216478,4.007682804682,4.41666124290876,3.81919458538265,2.35709625199132,2.62536815276644,7.38024451788662,5.70150043141163,6.79679668055103,4.52249960508858,4.4559228120932,2.73066814884895,2.80533625940251,4.32819855298178,6.37974188053221,6.39582974649419,4.85389435139681,9.00714687170235,6.09414095882864,6.66627300324451,8.60755678650129,7.42694037455047,5.4676845487781,5.92819080241929,3.26463274045175,10.3432280604117,6.68995065770063,8.59434189301081,10.330099825448,10.3133493732845,2.507298518227,3.17025757451452,3.02404970580847,1.73159516277684,10.2966027898053,8.61789514115238,9.64831072711484,11.2703523334822,10.1072738734101,11.165525840514,11.927511869244,11.9061699078901,11.8853128922128,11.8648680803607,11.8447765860728,11.8249902296814,11.8054692105913,11.7861803616399,3.1236723071222,6.18596883540498,6.0172946473619,6.04661174671427,2.67568785863118,6.03851541556808,6.0862356342864,6.11554110191771,6.14482097803751,6.17407791004356,6.20331419234722,6.23253182330679,6.26173255148578,6.2909179135006,6.32008926518927,6.34924780743689,6.37839460769688,1.92186300234526,6.37089534679314,3.36177713733967,6.41844174657532,6.44759140152748,6.47673117996833,6.50586178736296,6.53498386355181,4.70769143992869,4.36008935234848,5.80936957402456,1.72168007534123,2.86129223993172,3.81354418795523,2.57204626116115,3.24161746276725,2.52086280678918,3.64394526899047,1.28624391005241,5.42094070941518,0.817253270463702,1.36186594394607,5.62311973109633,5.48719863078843,5.50567203744754,5.54745334718879,4.45522984017686,5.25284201867297,5.90271545151069,4.42066620155728,1.15825311047012,1.99882440095464,4.77770088131929,6.94512997633611,8.00535147326105,4.02839095079544,3.85970067435928,5.34024166876747,6.21476727765717,7.54603279503791,8.34439167363678,6.57705643811276,7.09885431317009,8.1748251681484,7.96392808742307,8.19961393161759,6.70277957100753,7.51992923163014,8.80736917876038,8.92511547634157,7.18360208606589,7.69077191542072,8.7862568391843,8.69861009281133,8.694896899191,5.58100899740718,5.66482005292134,8.25233430637468,9.19493491430021,9.50559351508723,2.58984264330545,9.24945923683651,3.86912437879902,1.38439373061694,4.1807791786876,7.81867331002574,6.15578864849515,3.61611930403552,6.45658840962748,6.13637764344382,4.9559633578155,4.89460056642244,0.935264670223385,0.27601659835291,0.217804800631468,3.88095965427288,-1.2555927126284,1.20184879823143,1.49395843665091,2.06410058377601,1.21433549160762,2.11699770636107,0.905586233912649,0.756424293386678,1.66142517591961,2.03698508634993,1.49253586483501,1.9213560843992,1.20919597418592,1.04932705568948,2.42543608490852,4.19421096699453,4.24306897383907,4.27332307326376,4.30340291762786,4.33334117975523,0.847752885502341,3.16182144737059,4.22868619369076,0.901644194576026,2.08707599095328,3.19529149873811,2.23799063903423,-0.572676430720841,0.338337780759695,5.15940136394611,5.17470627250374,5.17781925521834,5.18530347959595,1.71466918264498,2.79698655025108,6.34833355148109,6.99121396498416,3.46221746352071,4.12754860722303,2.3244800653478,2.17853822878821,5.50800333404763,5.52739306209755,4.36762905773351,3.81202413104427,0.790371244425149,2.99211739124618,4.34222824814605,3.40359359659281,3.17505971028128,3.41675415987856,2.41967479633278,1.20422986423394,3.79494903930385,4.31924127992395,1.50188726081003,2.28686855813503,3.41557336328899,3.06415614684784,2.06757505760281,4.8861341982102,5.33704802681048,1.40116573166082,3.25884522291112,4.08304665188122,2.75536885087579,2.74331806279958,6.60684578567387,-0.0145876823031251,3.28929147538496,-0.589439741635524,0.605760683474701,3.86437703955242,2.75655816357726,-1.31327481447103,0.0537401062585881,3.32033688288942,0.894081819978967,2.01222598912655,3.24229293383089,4.02857099852445,2.81340096831714,2.23077826688105,2.89138777331251,3.76115529034876,3.92074784640417,1.15267090326627,1.69388472852407,2.21308539346999,0.0897905975142065,0.317131047127407,-0.471119606930407,3.98335888025187,4.03598694267746,4.16471993013258,4.31123366835313,4.28434595524384,2.05820222243243,2.07627840454674,2.01255429562949,1.28783908383189,-0.267565092666965,2.13577170090141,1.87133052690782,1.99311717679272,4.44645597412376,-0.475242891532036,3.12824327369048,3.85343274655953,2.81919063998449,4.87129854095106,4.9321986662268,5.34830323951426,3.19364784504611,0.389760264731692,3.06945315960973,5.27089100906596,5.14826254938013,3.92452561357555,3.68473739367705,3.89115992835328,3.63194695349796,2.64006508673377,2.78675032975706,2.73722917151503,3.44611314661501,3.83399771227534,1.36744244056479,0.669327345741316,2.43418142416554,1.11160176466249,2.37836729179698,0.183208447320966,3.02105161812575,2.26645647990886,4.45357956949695,8.24614693395311,10.3072263079132,10.2590359766218,8.01082339822486,7.03111476501099,9.06447791765316,8.42583167857118,8.20414440620562,10.6485054461688,7.46577999198461,7.74055544506762,6.55419115286706,9.09955188204157,7.11609059812684,6.71185525207739,6.20736889019759,8.90415677106517,8.04607504591293,3.78754815533943,4.82088596439253,10.4638662754002,11.1908946558522,5.95566359407,6.67906180701896,1.71031444791959,11.3451198184298,11.1227714331133,12.1146718424589,7.04337354768731,4.53447860064768,9.5849686202149,1.06478463530602,11.1254347149714,2.09180337375362,11.7374361361796,1.83672705849852,5.89860229319899,4.68000806392241,7.44096403590735,11.8450129100508,5.36402677044258,4.44107935434428,6.89095207502484,8.11772427554261,8.43198635177602,8.41629539413803,1.18945163355882,5.83556642595055,6.83580203854396,3.98782809057201,3.38670841159996,1.41130357398271,5.6175556662941,1.00873271714408,1.83500588341825,6.02897499089959,6.08132107951892,1.22694819658893,1.30957974749918,1.53684419661661,7.78868440738042,-0.151513299728476,4.17326819444992,3.98651893184362,-0.0739425941379643,3.24535764512838,5.20140306725894,0.394707094952515,2.41901198641213,0.473353567439937,2.86546277005979,5.32454683526606,4.10009796977678,5.54397248278589,3.8311119987993,3.55245370976796,3.59316052421617,0.774741045624737,4.83349012798216,-0.283072525739314,2.44808047483365,3.67056244781436,5.5218205893507,3.58461483133399,6.03734512826846,6.5145732431847,5.7208466769739,3.07984368774547,0.382608915041756,0.9874099790721,2.17990251484867,1.30580476704534,1.7722054455123,5.15352461752314,4.54477220840185,2.20471352581391,-0.203459370656895,2.20188352154659,4.63241097983647,2.50200470213773,2.33504453116197,0.116771978233793,5.39079309979716,5.46368064632147,3.40195536781235,2.55505843390024,3.37300132781874,2.80535094114905,5.44805969239449,5.03698507739508,2.40003149118237,7.23205827524957,3.53337387196109,2.05206440242466,6.00941477810058,4.50891315092218,7.28365703710757,3.24751301512342,0.694992040498764,6.24946176104187,5.30453432323767,5.34275900861121,5.92484984705884,6.31066097414859,4.01673095104413,3.12145858452036,5.53125220648323,2.65053018469314,2.94294608011161,3.81839172249665,3.89355597724996,0.119476214172018,1.44979237466742,4.61740996943795,2.58803264715889,1.63696695878653,3.6017196361428,1.84411148322924,6.50233023566696,7.78363417666419,7.76324179132026,7.74321514676806,7.72350199432307,2.62028192286183,0.75975906867787,2.24659736005894,2.66010705652321,5.62048638535855,0.236995179253694,3.24681566349703,0.163310074791927,3.72843914957409,5.9675870384467,7.1435001202707,7.3340585164719,7.31648729995658,5.84296995871769,4.17351574396431,4.23315121365749,3.10990342442989,5.71608803673092,7.65239936205533,-0.457662244561315,2.88213779866317,5.37416005823382,6.49374059630435,5.104798647287,5.80389261500645,1.75379247237301,2.51298558446866,6.39457369583463,7.67188445074794,0.514779310643757,7.75691471173633,3.04443718621919,1.65776584508859,1.67888930740175,2.48610285639632,6.9509829448522,1.9707587789256,1.08696263677666,-0.755458092963448,2.40073141993213,1.74929253346589,1.4118498419441,0.46830838758824,1.81709247345531,0.408669992998441],\"type\":\"histogram\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"name\":\"V11\",\"x\":[3.20203320709635,-0.414575448285725,2.03291215755072,4.89584422347523,2.10134386504854,5.66439470857116,6.75462544809695,4.56072010550223,6.43905335158373,5.5887239146762,4.67572941865677,3.57205481558784,5.45074606689486,4.36671348631445,6.35507773663404,7.38805512292025,7.62008905836908,6.66243683071252,6.45418752494833,6.35361231915591,6.31620967716699,4.80232276125089,7.10298858788516,7.07166913682445,4.69039566550924,12.0189131816199,4.65408842254301,10.8530116481991,11.6197234753825,4.57011280759332,5.27550585077254,5.14940878300581,3.18718689736493,11.6692047358121,10.446846814514,11.228470279576,11.2779207278067,11.1524905985837,3.33850216040272,1.07272839973578,0.154921008931302,0.500376369958899,11.0270590938161,9.36907905765884,9.32879925655782,10.5452629545898,8.80568196718575,10.2777688628065,10.1875873241664,10.0637897462894,9.93981974172569,9.81570317447819,9.69146098207319,9.56711029521397,9.44266526535108,9.31813768535999,1.124059382453,7.39441941053863,6.32936467621872,6.21088301172371,1.83449419801385,5.96620250720685,5.8492930661792,5.73081553744459,5.61234710799626,5.49388683652872,5.3754339072439,5.25698760960799,5.1385473219039,5.02011249777419,4.90168265513877,4.78325736701241,4.6648362538527,2.35161910622909,4.41994345577668,0.987277021963291,4.30309581759563,4.18467368942509,4.06625507293473,3.94783971729026,3.8294273949908,3.79256535985687,2.11151686706104,5.47939151009669,3.02816223099618,0.675287853392807,2.36843367282003,1.97582106179607,2.75617194535395,1.1205051770709,2.80200512615164,3.90739912775712,4.72997415443333,0.0243696057661544,3.77974953895486,3.83978771072745,3.77960220775921,3.53820204012168,3.36784560815482,2.95434436554049,3.6573495649865,3.67670318691664,3.26606601582438,0.159743522312315,2.80433477984687,1.84409317018026,5.73008435556377,5.73576265915634,9.09528815249629,3.82376208408163,3.96979981229186,7.2529532268294,7.38185937432083,7.67453383416429,8.26529460055417,6.87757089846463,6.45582813287588,6.64520072606617,7.04773274001302,7.60555947435276,6.89518136811315,6.85495311388866,6.78605830197451,7.12716532148781,5.80470785195987,5.97513066688423,5.58936163192341,5.3306013514672,5.1483517210937,6.03766622940467,5.61099879659254,4.82823533219729,5.29923634963938,3.49080495043995,4.39243558567834,3.47109784646449,4.35477463025116,3.18605794805635,4.81815244707108,4.67734929657245,3.58682418337431,4.38921350258246,4.09721607443527,6.27866584548672,6.28337707847689,2.77896789639267,3.65788166668826,3.36736102310858,3.52572598717089,-0.473852105914046,3.53221960237349,-0.984171728067149,3.43824825990431,2.96259879138962,2.88704787664695,1.48028602025778,2.28193937592012,0.141178993422237,2.81431415481622,2.40165068027699,-1.06453419450651,-0.668358831257417,2.5555891530874,1.96223597455109,2.94398521977131,2.82667122820047,2.70785640511515,2.5891035399443,2.47040101557896,1.17235508293037,0.90311745288141,3.20091235546057,-0.876737591678351,2.82114488798301,0.747478135782509,1.17447506014201,2.37853722491518,0.0045179679664243,6.25006758982915,6.02903256317613,5.76318940883843,5.70520550718269,-0.153131026660117,2.33832327000211,5.26658587269696,4.77414774007074,3.26492215161104,4.31571103012142,2.25514748870463,1.83721490161197,5.2241240042156,5.72525459149638,1.84750351109611,3.55473755027372,0.614977120327696,3.1284396921776,3.76230638231684,2.88609147657536,3.06424584128211,2.61176184321338,3.5617949640183,0.144562690111297,5.04075120270381,4.83896418696128,1.91445404493049,2.79039639060721,1.39818511854919,1.11335409263987,0.915947028928619,3.54601225001006,4.98601380361468,-0.921051995675577,3.97722223959189,1.53319383793753,1.92856763203456,2.14005681553663,5.26786160380362,-0.245676823310174,1.27720226474415,0.881268050432366,1.61826162043188,2.6215881261205,2.56070020158284,-0.651414013964987,-1.35655775612738,4.40680552357904,-1.03941706835478,2.19166507997652,4.66325458481107,1.60198538284757,1.55375586796783,3.51034756034463,-1.27393508028395,4.44719176626515,4.37690666362302,0.82637484441332,2.57283021584331,3.1020899271543,2.60516857519668,-0.39560772252726,0.567551954604602,3.04839203447565,3.77557843937585,3.70431215185119,3.21126387844398,3.25959475409854,1.0804386160969,0.763204840843787,2.60593702345612,0.706999574201444,1.50062918076179,1.35275258963919,3.35763973653551,0.273983570211148,2.39416766551329,2.50978140392157,1.29341829662131,1.90428359307622,0.301368829965399,4.3437434980468,7.18296700883659,7.19030608944843,5.41604190908794,1.27462907751277,1.8806015528528,6.30904400603177,6.34897930341209,4.52299197543382,4.35148149710451,4.22130410784879,3.36918605153883,-0.529805728295342,1.03303201224459,0.504116141204789,4.25656448730292,0.301977229683697,0.382172176843061,2.20944075185923,4.921657447038,2.05681205985716,3.50456779253823,3.71921153916465,2.42595071598052,2.71273940377591,9.41303953977606,8.62125508140256,8.78878366710272,8.87947566765026,8.68830799242781,8.46024444901677,7.15408284221914,8.03070840755191,8.38914233451929,6.35722736343626,7.61081978841573,6.98988561330738,7.58874088021049,6.05731930477932,7.42580096307482,7.09318207259894,5.93465734341534,4.41999660154863,5.90239975502551,0.7653541419638,0.637766685379952,5.57362527301538,5.70211147983179,2.02467408050134,2.54083553206878,2.17523030559549,5.56925817499418,4.41705461009659,4.971248707036,4.73958247105186,5.20081516878268,3.22323270290842,1.36858453419511,3.7859770496129,4.87197985976052,3.40932261990014,4.28702087961434,7.02127774818005,7.86446740028511,6.82579316213884,3.48195180343701,7.34365210856032,7.00213577397937,5.35088988417692,7.18872396524447,7.15062516950116,7.05106508958574,3.69471123994721,4.69879549591235,4.69653339192897,-0.427567391481657,4.54630106888309,3.51964234486905,0.606910821999133,3.58604242366444,2.45371037821171,4.43173633655471,4.3150759158968,4.17609762346479,-1.39432826167269,1.42841254547618,4.22041859352387,1.3415717221686,-0.408402781057003,1.84607851719332,1.28674925677162,3.61264534637429,2.14393063330902,1.96148093151336,2.96924007367485,-1.54230486820434,-1.12757349175133,3.6195974073081,2.99348883356357,4.51335526006987,3.36955824955852,3.27754628526759,3.24943114650197,-0.375466188651408,-0.0001211803349648,-0.482409384022894,2.22296005779154,1.73812401383737,4.77672033006624,3.21163365301808,1.51389817939856,1.05148630261883,3.39415208597649,2.07411645462861,-0.491112318271443,3.28282460993431,2.86702850008408,2.09307500991474,2.4507521592725,0.983646778914785,4.18216236800046,4.49792897288062,0.253931337415353,4.22915426403483,2.68057817990216,2.9456208658257,2.94293916487767,1.20030360709416,0.195839103876469,2.37587561688329,3.72393253444097,0.997448763245357,2.73157578227581,-1.70222840135659,3.2740753098509,3.94231582587852,2.71069667870109,4.21321289394162,4.4045784815908,3.9168025570096,2.94119009271712,2.22079491381924,3.87116530391397,3.05365441815753,-1.59425779202416,2.11390001406861,3.53614548208968,1.99136063471588,3.69317394224412,1.2038344844503,2.15579608547647,1.92718574923744,4.7365938426554,2.85877650156878,3.34180192747217,3.59279683214404,0.613867739096179,1.90399926160786,-0.448793725596362,-0.688453906925825,1.43932206570096,3.64225693939881,3.73703768128326,3.35972193954249,4.56919375212135,4.60417047790948,4.48003526995735,4.3557700196603,4.23139330449617,0.470864719590572,0.0110374511201705,1.86359573670074,3.64647783754223,4.43631907416962,2.21400028680889,2.94437484242405,0.71387764641859,2.52894302060173,4.90581986504193,5.78365443891613,5.71631869503674,5.59112619350265,2.75783745850663,1.70189470812283,1.45123754814542,3.58639450927204,3.8278680907164,4.1064045585523,-0.800150416391868,-1.51420473629918,3.48060170327307,4.46946731169238,1.1682159434835,0.757063214391669,2.17297610055437,1.96612345703981,3.61873721262172,4.54849458373201,-0.191190536963042,4.47590467269415,2.28802174654208,2.98962640655731,1.77950450310136,1.05410721205494,-1.47514531556892,0.874051625366684,1.03201558219625,1.33831754595819,1.24195817554592,2.1157951772133,2.8584658156696,1.79496896856641,1.93351953683592,0.491140241656789],\"type\":\"histogram\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"},{\"name\":\"V19\",\"x\":[0.416955705037907,0.283344830149495,-1.33444106667307,0.308333945758691,-2.72185312222835,-1.93466573889727,-1.32735663549015,-2.37059945059811,-1.80801215867357,2.2501232487881,1.55419726345897,1.11826355175812,0.351948943356815,-0.265421595374812,-0.0897244112241547,-2.07145048844325,-1.31449509665307,2.17738568653903,2.26298478762517,0.357987030484253,0.364810482193887,1.74050729036196,-1.38218756352589,-1.38555780172735,1.66339401354543,-0.410480977392724,-2.00547660274646,3.16699890688552,-0.501750653452579,-0.287188855297045,0.991486122257293,1.50492485905709,-0.662462068430895,1.2702262705049,3.12692935212663,-0.574675143795817,1.19726633504633,1.16202614780693,1.95922405409272,-1.53270721248432,-0.865104609842214,-2.54852159198286,1.12678437819631,2.38280793552097,1.60687003263877,0.579200358016368,2.06937744931751,0.604625910708604,0.753149847889189,0.719787682108791,0.686227163597458,0.652498045264831,0.618624412799665,0.58462597267458,0.550519004149565,0.516317073274611,-1.56381522671193,1.26834277321029,1.43226792970939,1.39031436050276,-1.30699464468423,1.32116655982617,1.27209136353211,1.23014255193802,1.18820420779718,1.1462752482696,1.10435473489394,1.06244185030067,1.02053587929144,0.978636193358608,0.936742237936608,0.894853521838799,0.852969608454831,-0.385884175181753,0.783577593799492,-1.15585017273094,0.734573493016404,0.69268841200477,0.650807370688892,0.608930080519071,0.567056279787444,-2.67995024218857,-3.28615008214787,-1.95429995537505,3.0016850593747,0.484758940230455,-0.90268980289448,1.66926055335833,-0.686196723569762,-0.655269928208246,-0.124137989024621,0.17774563450317,0.432054206519352,0.38676063692414,0.132330776389272,2.41438956859515,2.8921696850147,2.46384303909831,2.52578492424474,3.62333181402755,1.64541389333247,2.62662452479163,3.02526099185501,1.4060448737262,-0.888087464222472,-2.88977035831304,-0.688720555143152,0.0929734778841175,2.9951111673215,-0.871581688476025,1.12659865645629,0.787578807808201,3.66952343976659,2.99255446334225,3.85637474254372,1.95189049542104,4.03823050489431,3.45394255518458,3.20430921695579,3.80913643570604,1.85246698871594,3.11847976563045,2.87235363605874,3.65678707068496,2.10273540686125,3.33103902941017,3.62971365041526,3.51761050964655,5.2283417900513,1.16906441801605,1.24351749943488,3.18355894967976,3.10173536885404,1.46108031890323,3.25653448060821,2.04269768780688,1.29616504982889,0.718555009324824,3.32675827497024,1.1266403652792,0.936939858866071,-1.06302761603247,-1.43960797610281,2.6304759946371,2.59017338411194,1.08340676372199,0.874542948076265,2.10905264474381,1.14787783834912,0.574335960915453,-0.289935891439032,-0.298920455435975,1.16012029433585,-0.23930965408033,1.28596139472532,0.272698476205832,-0.511210088142662,-2.19176427800358,-0.208809536741974,-0.0958074336903356,1.40357376229763,-0.73174984602915,-0.0017219235416342,0.139687230416985,0.645904895509124,0.596364320528384,0.554027499068527,0.511761951503497,0.469554313978012,0.476859902488945,-0.666806394320072,0.0346554556282822,-0.0644929660672327,0.572791028207014,-0.603726269220942,2.11863332532912,0.860211793588662,0.0725498490088206,2.18142273556017,2.64398422133793,2.46519487038601,2.35202964025176,-1.23138550165184,0.93023918577297,1.50425021091709,2.83699299496563,0.0802807729992116,-0.440434552920779,1.71549441975915,-0.450550113544917,2.51343040062446,-2.02888535240153,-3.60265725092653,-0.231198386269899,-1.09619645414336,2.15221455770756,2.31416486951171,-0.531558760456647,0.595629103995644,0.254771833248553,0.22842274838649,0.105878827218844,2.59857755637223,0.606452965011177,1.54523326964355,0.79514422023384,-0.133819199948815,2.03059193793375,-1.10076358353881,2.68112678165858,1.43529381015392,1.16443546519237,1.76361087438004,0.831623853010765,-1.56869755794851,-1.57707047840184,1.33293006548133,1.22602219788409,1.1764455977519,1.19012126352217,-0.09472379272847,0.288846910516582,2.69080834203374,0.68705620239513,-1.55456174696529,0.0515761185277783,-0.728989760343786,-0.443999191918561,0.291250739005026,-0.136117269757132,2.30361261010114,2.78338340771804,0.329826631850516,1.19160626766329,1.23304434947994,0.407187527410462,0.397308037124058,0.933262164554872,1.58958220191211,-1.08122326117298,2.50202738858443,2.52496746940249,1.88404425730219,1.73797600497073,2.19728771323892,2.14350179519978,-1.10727585500251,-1.09471647432252,-0.880812102847679,-1.53933883157799,-0.896071786353489,-1.22925431837217,-0.894893657235367,0.26084733041578,2.43127449162965,-0.0095336065683719,0.223718288348024,1.73238175785046,-0.927124072666602,0.98258385892977,1.00766725992114,0.844059610296466,1.38560952778492,-1.14037564250718,0.779950535234061,0.876018768156628,0.897402406121681,3.18415235636348,2.33675362049059,2.35591891159776,2.79433340410919,0.913175997078955,2.22616065557659,-0.94351353548825,2.99317350708135,-1.15062735713932,-0.581355690647057,0.60039728842723,0.174840185624481,-2.24107485298106,-1.1962847755939,0.407805060819919,0.37371480785248,0.626059293435215,2.27422550991903,0.15601503277122,2.58609321670737,2.50082720798487,3.51795494036344,4.00892074227194,1.9823563171714,4.1300314273319,3.81304079276336,0.623796611777714,1.57369789640089,4.85125513655685,2.21175583268581,1.17118873250237,2.27108150670047,1.94169681013401,2.55087034384644,-0.567939572890149,1.51769533116994,-1.91256263382671,-2.10358290329291,0.169740705598221,2.16209864550609,1.56212955232854,0.148592393859995,2.59445276115475,1.66102935873752,2.43582348553379,1.42263161326029,-0.129188144339879,-1.37551765637273,-1.24328515722898,-1.65176618071699,-1.25446534452587,0.252273565031692,-0.248828402209821,1.01162645030639,-0.507536514254236,3.83298514230067,0.0653171492484702,-0.901040817847599,3.37971333584943,1.48227743472618,0.510570181831806,1.95874993153475,1.5604792800844,1.52573244095261,0.0038960221310578,-0.585321852047277,1.80401333906519,-1.6840216339214,3.52773827223549,0.795448867520342,0.752760921550722,1.71709526842855,0.520496923051347,0.936966154656013,0.886746966076448,1.27132193138436,0.0575510393537501,1.31912362938259,2.79789150183086,-0.917407954929339,-2.33518537609962,-3.68190355226504,-0.716811424575637,0.0982420128901166,-0.376135682527478,0.267914551538718,-0.183180903717309,1.08428646665042,1.79092414652793,-1.35984389291856,2.35115138243805,-1.79673863123125,2.36229077589933,0.170143879416802,0.524007524087668,-0.00202115788658,-2.3007976756963,-0.391047742407487,-0.559479810847182,-0.559132202274595,-1.87401526330162,2.06569197047395,0.994829500437418,0.952141057235768,-2.2213838533863,1.97974707098703,0.189130835579419,1.50157346167502,-0.167199797868911,0.152892032043683,-0.663370800920003,1.06015422605258,3.56973257751778,-0.17381402447058,0.477521452443793,-0.193132205838334,-1.90979861946686,0.596696430089622,0.71833237368083,1.02892683645358,0.506039978517755,1.81901276401306,1.93037970885184,0.32519494288717,1.98738627690236,-1.49715223294239,-1.17779250651196,-1.55653021213315,0.606570797159568,1.60929290421203,3.49006859270908,1.14847293881065,-1.56373996709776,-1.95006033191067,0.242162496030838,2.32892697361116,-0.736110693106424,1.70168502365985,-1.80233249695937,-1.46691055321726,-1.25758897993879,1.93548375407006,2.8686028948655,0.971906321717639,-1.80557671393198,-0.13769358207354,0.685510860299876,2.3534526931986,-1.61692658827377,1.49032876283779,0.982728632705372,-1.92330893857582,0.0284845308917937,1.35674828969143,2.99524475453849,0.235226841085862,-0.215409738450978,1.14778361222539,1.11403305037529,1.08013289303778,1.04610451099676,-1.48943421708841,-0.45793403989618,0.0135877061935761,-0.300930778531616,-1.08520791024384,0.38526260953691,0.0833797227600835,0.731998749113651,0.136722438174659,-0.819371096333784,1.09382579750391,0.832574035012694,0.797641375455208,-0.820354414754465,-1.59744021309102,-1.53016232603362,3.0573817418767,-2.09738547120766,0.502453451135321,-0.0513220971157383,-1.76235002438458,-1.16441437126035,0.707199945685905,0.421144082740547,1.24714263088632,-0.526280794204029,0.626240855695279,-1.01863859540215,0.78808629554402,-0.221267207742386,0.647708880496559,3.53100289778427,0.434072536887008,-0.30860899195249,2.54831265500006,1.30794073758635,0.527619755594392,0.87334427153726,0.423099369076423,0.42234244481934,0.391167040935071,0.737657217477667,0.266272320267649,-0.0354803664667244,0.593508846946918],\"type\":\"histogram\",\"xaxis\":\"x7\",\"yaxis\":\"y7\"},{\"name\":\"V10\",\"x\":[-2.77227214465915,-0.838586564582682,-1.52541162656194,-4.80163740602813,-2.44746925511151,-6.18789062970647,-6.04546779778801,-5.13445447110633,-4.95949291161496,-4.62498495406596,-5.00924850212751,-3.95581234352737,-6.23456133227108,-6.19988176274188,-3.94423849794435,-7.45484065078351,-6.81081309938215,-5.52627805985834,-5.3903302556601,-6.7167200227127,-6.99990663386522,-5.57602263642415,-7.19160424618226,-7.29780335001461,-1.9877731876087,-12.8409338181318,-5.15309460989926,-11.4204509744097,-13.1934150665232,-4.13784019622865,-4.59495176285009,-4.13889121357616,1.01511287978593,-11.853866972601,-11.5619497720699,-13.1366983691039,-11.7971810675777,-11.7121866242875,1.07741752106048,-0.592472935320844,-0.554223900525873,-0.164562674892883,-11.6271935556579,-11.7868116556041,-11.2014000859835,-13.6705451263516,-12.9389293107706,-14.166794659606,-13.3482776536659,-13.2616517082667,-13.175198078736,-13.0888909176936,-13.0027093010697,-12.9166361091709,-12.8306571996417,-12.7447607871859,-0.859862301810301,-9.66878891236125,-9.22282550730978,-9.15336803834587,-0.369908966047961,-9.04039624894471,-8.9286556608751,-8.85919405880884,-8.78972336330438,-8.72024451506225,-8.6507583293562,-8.58126551626339,-8.51176669710133,-8.44226241787632,-8.37275316035861,-8.303239351259,-8.233721369876,-3.46568908576121,-8.12096173759343,-3.65142656863483,-8.00915938639777,-7.93964241937325,-7.87012194292549,-7.80059820772759,-7.7310714411342,-1.88484243991678,-2.33593332652232,-4.59238980599474,-2.89525166830126,3.24508640095346,-2.73415555507211,-3.58281002008802,-2.13317644293659,0.644549730341658,-2.83487115980611,-3.71744992918956,-7.06074618169306,-0.121653217684609,-3.55198400939375,-6.0677981503786,-6.31970750896333,-6.54624181523522,-6.60046062150676,-7.52436833681058,-7.8335555711125,-7.50211219093686,-0.794993881662565,-1.96530880945923,-1.95980925751416,-2.04216786301424,-3.97652513857503,-3.05121035544102,-13.6913151328525,-5.29061006200618,-4.46628416302479,-11.2981564915382,-11.1412776902967,-11.435623996076,-12.981619145004,-11.6344144245911,-11.5198609264142,-11.589748311433,-12.2653238444006,-13.3866834395246,-13.2151722995049,-12.8881582878915,-12.8056831898117,-13.6081431627279,-12.8357376825339,-13.0740681657723,-12.6959474039839,-12.7806339362021,-14.6764702497464,-15.1241628144947,-14.2266980575287,-13.0094028057641,-14.1101844415457,-3.22678710680364,-14.5571590528859,-4.75830407509117,-4.15583783449678,-6.40337055173194,-16.6496281595399,-18.2711681738888,-5.69992228265959,-4.07758540918968,-4.56525209408734,-7.14219911358407,-7.78135276287243,-2.96199570179906,-4.98092843827312,-1.25028553742691,-5.72681709632961,-1.48124586053984,-2.97526724837752,-0.792937990748917,-2.75579692797163,-3.84391103993778,-3.36401057980002,-0.55054534794377,-0.585778431385528,-0.433393925731893,-3.50579032571994,-3.94238290411726,0.225933803313285,-0.552902906422504,-2.49561924548174,-2.89261176082088,-6.24624318477127,-6.13490688724113,-6.06578236274727,-5.99659592015915,-5.92735916911943,-0.150129182778684,-0.283731283967387,-3.09650359868717,-0.0450882478448673,-3.09509360697848,-2.9966693020716,-2.70501138232752,-5.45960189444545,1.01029102209398,-7.14513662527302,-8.12216107491307,-8.33286306292127,-8.40315026242229,-0.0492328559624844,-3.24510859732028,-7.74848004950582,-7.86450647898838,-5.97492543825504,-3.55583492739064,-4.88114292689057,-5.71150474047788,-9.33212806886128,-6.77833138248069,-2.8084555425423,-3.07669858515182,-0.867899742347565,-3.39355348115172,-4.17062288702767,-3.28820356526528,-4.35068531246963,-4.00174208524931,-3.23678401592309,-3.42605225253339,-3.25263359468289,-3.55038539904852,-2.30110989675506,0.169572797878818,-4.15369240632128,-3.83477508791878,-2.12697274994354,-4.83482799462627,-3.9905513318108,-0.0913533730643921,-5.11725920989043,-3.16213595485783,-0.157696445821874,-0.194120466505581,-3.62477471396623,-0.371671945168217,-4.32053577559936,0.264544748886681,-2.85611682977408,-2.65971794652165,-3.95100289197434,-1.7690597207318,0.517567879914365,-5.05250236713858,0.54318725600578,-1.87964382107016,-4.7117686842189,-2.89499040084744,-4.05629261571005,-5.03202838566819,0.324238886093679,-4.99341703829647,-4.68423332514029,0.334532824069685,-3.9433368210052,-3.53865023182429,-2.9989262562074,-1.03963769713185,0.166830707878014,-5.51550707258062,-6.44720227383046,-6.28780335064533,-6.56125741097377,-6.8254901042394,-2.15530254380865,-2.10066651278309,-1.92527812380296,-2.544410418956,-1.02533539256113,-2.15251889070952,-4.62691916410905,-2.23120932812687,-6.26070551479114,-3.8337413849476,0.269561809170344,-1.88617599041763,-2.9328952580311,-5.63894131284807,-8.0991193981365,-8.33770697381781,-8.74597261185534,-0.71347376073502,-3.99521073403213,-8.40966487562735,-8.53775768653457,-6.2133552491157,-6.35388725151755,-5.99567612703198,-5.822449155685,-2.06990438955593,-0.133950251206468,1.987861862693,-3.93629417027159,0.541699242973355,0.369936028027435,-4.15635447965382,-4.72309174576035,-3.37617706712688,-2.8290982053899,-3.71748137540216,-4.09564897273592,-5.56794705115052,-13.540168238225,-12.0111608836062,-11.2350479111446,-11.1821254546586,-12.9654812039222,-13.3207888671784,-11.0923923688428,-15.2399619587112,-14.9246547735487,-13.2025771482197,-15.5637913387301,-12.4389449056023,-14.5331616869738,-12.618162687238,-16.7460441053944,-15.3460988468775,-15.1237521803455,-22.1870885620007,-17.1415136412892,0.912806096143303,-0.357616193093852,-16.3035376590131,-16.2556117491401,-2.85032390160027,-5.66586179854092,-6.62569249371823,-16.6011969664137,-15.2318333653018,-18.9132433348732,-20.9491915543611,-0.870997150804889,-19.836148851696,1.78592177154007,-23.2282548357516,-4.4318096317282,-24.4031849699728,-4.36310219273296,-6.68368922880726,-8.99381088354112,-6.80713525144464,-24.5882624372475,-7.17534972178322,-7.57563437993936,-5.11072764247853,-7.33437708370839,-6.86850850672582,-6.86416435989436,-4.51390660472333,-4.54693575081085,-4.45800770078481,1.07295520625891,-5.20833459337633,-5.62467713431414,1.7837390603636,-3.51413330486723,-4.54261203828437,0.453505060416619,0.566679814004086,-4.82077941422469,-1.53160798206082,-2.77674714436829,-4.89115620289902,-3.15812700566592,0.0422275201898101,-2.27673307339047,-3.21618771830464,-4.5652600954372,-1.4706452575308,-2.29773425918487,-5.48742458295368,-0.0844995591396119,1.71353755281029,-2.9716952359177,-3.90674573293228,-3.8517216648754,-3.22455914814995,-5.56914249554635,-5.83645272742826,-1.4294901237515,0.0856615347524881,-2.24811517395215,-2.31474716368481,-3.73965947930309,-3.89824038104731,-2.64940583024547,-2.27152578398956,-3.07403431268054,-4.07025686324581,-3.52012767367189,-0.989431189994817,-3.8410981507899,-5.17993471366321,-4.50131480977758,-6.56465926230671,4.03143505114991,-4.25071651144568,-5.41603688884657,0.217630453611954,-6.42823083022309,-1.34755671450971,-5.11297108805175,-5.16533081830893,-0.159325098707444,-0.0451253297662453,-0.423783865294484,-4.93742665954554,-3.07555830950402,-3.75405392305562,0.955004466801798,-2.73279196653765,-5.6536376856402,-4.61450773315675,-4.40092985049667,-6.54098852025393,-7.04922935969585,-4.06309810827338,-0.628463195272087,-4.85148719411703,-4.91934829935247,-0.887241636246378,-1.44537495699985,-6.28542447506796,-3.20243612238872,-3.41920738405664,-1.87333085278999,-4.81640080035747,-5.17565967956169,-3.89016924226376,-2.63744174460075,-3.23543895742654,-3.26300672553831,0.398155064675901,-4.48548270396242,-2.79633153858609,-0.373927299894818,-3.50892466189359,-4.75993137385013,-3.99178463209724,-4.86874726825181,-3.47341070390428,-2.49756054724841,-2.4112720149303,-2.32511344137919,-2.23906626105695,1.28016674259048,-1.47497416110315,-2.12045759469323,-3.35647371355361,-4.23098383571181,-3.44381902213252,-4.44148408070017,-1.13445381068391,-4.02912871953916,-4.70757080611204,-5.57641879575659,-5.25809597551632,-5.17281182346005,-3.92650993997042,0.228849430580481,0.259411077154011,-5.9548382969224,-6.64615382952148,-5.5334430286147,-1.61361833850235,1.08151398923906,-3.06472953093127,-3.96322447209244,-3.27256917385192,-2.22307032799021,-1.67234597814111,-2.16206139007752,-5.33475387061743,-6.12071508667922,-1.00080505203989,-5.94563397292191,-4.5335154033258,-7.50955747436829,-5.52913123107677,-0.39438126178315,2.68866993252224,-2.5166280017922,1.33441406239882,0.24931080342673,-4.39084192218279,-5.58779378195338,-3.23215317539514,-3.46389087904573,-5.24598383776964,-0.888721675865145],\"type\":\"histogram\",\"xaxis\":\"x8\",\"yaxis\":\"y8\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(234,234,242)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"rgb(234,234,242)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(231,231,240)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(183,183,191)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"rgb(67,103,167)\"},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"colorscale\":{\"sequential\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"sequentialminus\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]]},\"colorway\":[\"rgb(76,114,176)\",\"rgb(221,132,82)\",\"rgb(85,168,104)\",\"rgb(196,78,82)\",\"rgb(129,114,179)\",\"rgb(147,120,96)\",\"rgb(218,139,195)\",\"rgb(140,140,140)\",\"rgb(204,185,116)\",\"rgb(100,181,205)\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"rgb(234,234,242)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"rgb(234,234,242)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"bgcolor\":\"rgb(234,234,242)\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"fillcolor\":\"rgb(67,103,167)\",\"line\":{\"width\":0},\"opacity\":0.5},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"bgcolor\":\"rgb(234,234,242)\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"}},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.2125],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.575,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.2625,0.475],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.575,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.525,0.7375],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.575,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.7875,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.575,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.0,0.2125],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,0.425],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.2625,0.475],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.0,0.425],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"xaxis7\":{\"anchor\":\"y7\",\"domain\":[0.525,0.7375],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis7\":{\"anchor\":\"x7\",\"domain\":[0.0,0.425],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"xaxis8\":{\"anchor\":\"y8\",\"domain\":[0.7875,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis8\":{\"anchor\":\"x8\",\"domain\":[0.0,0.425],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V2 Distribution\",\"x\":0.10625,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V4 Distribution\",\"x\":0.36875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V11 Distribution\",\"x\":0.6312500000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V19 Distribution\",\"x\":0.89375,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V10 Distribution\",\"x\":0.10625,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.425,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V12 Distribution\",\"x\":0.36875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.425,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V14 Distribution\",\"x\":0.6312500000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.425,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V17 Distribution\",\"x\":0.89375,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.425,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Distribusi Fitur untuk Fraud\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7a175bf5-1926-4291-90aa-5b4b9cd91892');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Box Plot"
      ],
      "metadata": {
        "id": "WalIkNk9op5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boxplot adalah cara standar untuk menampilkan distribusi data berdasarkan ringkasan lima angka (\"minimum\", kuartil pertama (Q1), median, kuartil ketiga (Q3), dan \"maksimum\"). Ini dapat memberi tahu Anda tentang outlier Anda dan apa nilai-nilai mereka. Ini juga dapat memberi tahu Anda apakah data Anda simetris, seberapa ketat data Anda dikelompokkan, dan apakah dan bagaimana data Anda miring.\n",
        "\n",
        "Anda perlu memiliki informasi tentang variabilitas atau penyebaran data. Boxplot adalah grafik yang memberi Anda indikasi yang baik tentang bagaimana nilai-nilai dalam data tersebar. Meskipun lot kotak mungkin tampak primitif dibandingkan dengan histogram atau plot kepadatan, mereka memiliki keuntungan mengambil lebih sedikit ruang, yang berguna ketika membandingkan distribusi antara banyak kelompok atau himpunan data.\n",
        "\n",
        "Di bawah ini saya telah memplot boxplot untuk semua fitur yang menunjukkan korelasi positif dan negatif dengan Class. Representasi boxplot untuk setiap fitur ditampilkan secara terpisah untuk masing-masing kelas(0 &1)."
      ],
      "metadata": {
        "id": "lecxOCFrotjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Box-Plots for Positive Correlation\n",
        "rows=1\n",
        "cols=4\n",
        "features = ['V2','V4','V11','V19']\n",
        "fig = make_subplots(rows=rows,cols=cols,subplot_titles=['V2 vs Class','V4 vs Class','V11 vs Class','V19 vs Class'])\n",
        "for r in range(1,rows+1):\n",
        "    for c in range(1,cols+1):\n",
        "        fig.add_trace(go.Box(name=features[r+c-2],x=df_rs['Class'],y=df_rs[features[r+c-2]]),r,c)\n",
        "        fig.update_xaxes(mirror=True,linewidth=2,linecolor='black',row=r,col=c)\n",
        "        fig.update_yaxes(mirror=True,linewidth=2,linecolor='black',row=r,col=c)\n",
        "fig.update_layout(width=700,template='seaborn',title='Boxplots for Positive Correlations')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "VmodgdTUrs7K",
        "outputId": "ee11d296-7668-4bb4-c23e-0b6a729b609f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"87b6626b-c847-47a9-ae17-8b0f5378ec35\" class=\"plotly-graph-div\" style=\"height:525px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"87b6626b-c847-47a9-ae17-8b0f5378ec35\")) {                    Plotly.newPlot(                        \"87b6626b-c847-47a9-ae17-8b0f5378ec35\",                        [{\"name\":\"V2\",\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y\":[0.845049887711819,0.289451215514098,1.11240286511215,-0.304729028381382,2.20260681912487,0.244146827746643,-0.291998470715872,0.107844134081402,1.25755819863272,-0.520790176541268,1.04530218627027,0.0480480404344114,0.810832483494633,-0.982365774608878,1.00810734415515,-0.73496076417937,-0.218979181883603,-1.18013212573691,0.251615559948883,-0.158335153132416,-0.780597577080009,-0.976606515094946,0.628001926863028,0.285336872881923,0.142539767632473,-0.0973665560827295,0.173167880225157,-1.04592907853102,0.305727574143632,-0.201067188363743,-0.600069481773746,-0.139181786113265,3.87276690346742,0.0932350387312718,-3.05154330777863,1.08040739172587,-0.164416845514618,0.306456586499518,-6.23455827632605,-0.16656777640275,-3.30959883981807,0.208210191167264,-1.5307248973014,0.0535093979504338,-1.37320232381817,0.0767488195849404,0.946692600188286,-1.59395351391978,7.17938467908911,-1.69799083883406,-0.213970797999707,-1.99475863327522,0.212323245442363,-0.523847557088687,-0.473087274542781,0.419921026881072,-0.281539572919166,0.757838767607048,1.02741320318584,-0.109287298837858,-0.484431343170466,-0.834103103106904,0.626404913442672,-0.31307923022107,1.26562134412589,-1.59307762599303,-1.32952305598059,0.171539673653981,-0.453440471186524,2.18110055117648,-0.0574641145125285,-0.588805841337802,2.30886052896075,0.230973857400454,1.41265322884918,1.32157092478166,1.37978749908678,0.155522126568606,3.35746996910571,1.2441005466941,-0.399043431192449,0.273845246172641,-0.787810737570159,-0.385510957258575,-0.281894720950206,0.537213555140211,0.832951572074477,1.03988044344268,-0.129807055624538,-0.0591476158884826,-0.460365190029883,-1.42468105118869,-0.289979529183619,1.31095611184636,-3.67098623611817,-0.55514004820599,-0.123955045299557,-1.99889297049104,-0.383553031278584,0.999475786477637,1.03230983402302,-0.159278387841857,-5.1576266728117,1.69537560610727,1.29286455678085,0.748125626786121,1.39806493177594,-1.88749019335918,-4.00234863713444,-1.28634680497618,0.444956541339119,-0.0002199379866521,0.235831492983495,-1.28970559118716,-1.12049427305432,-4.29066065611674,0.699042522079849,1.05325984810943,2.83025614271582,-0.688860664295587,-0.54589502614551,-0.215371352917759,1.43338202186554,1.3066853960225,0.151283263052917,0.371330451416721,-0.505182011222985,0.150507107990991,0.469781383166897,0.0272539538173025,-0.892398723169813,2.32670771180798,-1.32096899109068,0.179386142350764,-0.233325147374722,0.258373304438679,0.26884286870288,0.0902190662347362,0.255391679696322,-4.21478939184768,-1.2700711897775,-6.7013222332589,-0.537869920416053,-2.84349152162381,1.00686984904641,0.0083540761103252,2.78395686154948,2.26707383348303,0.358499901896443,1.05035517991459,-1.08472451816846,-0.806304161542783,0.916362308314718,1.28009100996168,-0.421787435898091,0.0009986193010034,-1.21279582219431,-1.74911712571452,-1.66789863346922,0.861138884740616,-0.0048183249710915,0.283203969247135,1.79111599543344,1.18949919426491,0.979674031666892,3.67058689267286,-0.694284408026982,-1.50569014245939,-0.179061836319441,-1.66019364851153,-3.12550226522242,-0.681052918571311,0.415116139703453,-2.58816304678763,-1.10883709769699,0.735569495815441,-0.357409779042041,-1.57136153914171,-1.72679404135114,0.422960621106459,0.883701843651683,0.828786964261286,-1.56459977992726,-0.958016110501147,-0.117492525101854,0.173597595219352,1.11500018104507,1.33101254993869,-0.230346675695229,0.205222381564503,-0.846843192888548,-1.22068857289616,-0.233371611900075,-1.74989892910373,-0.476584586017255,0.848043189368033,-2.05529168391975,0.0348915794197302,0.111321696197022,-0.195197182739533,0.941771896773746,-0.430952630904701,0.998563364236628,0.358475808646652,3.14939829224608,-0.682919350829677,-1.40583011624512,-2.69037585851636,0.0295556488881886,-0.463998665104347,-0.533432811067365,1.23235464582969,0.217979827812106,1.25083141074522,1.31808097325688,-1.04968639016844,0.828537257247369,0.303986651793274,-1.10422887749768,-0.655433010406284,0.0338961928217827,-0.636479577658582,0.921722229657323,-0.0318081334341202,-0.561826132660578,-2.05707130098489,0.526279939710425,-3.50565984896473,-4.31317092955023,0.962176922889664,0.921867399813143,-0.774068708287915,0.487481844664075,-5.33442998147911,1.14059752452552,-1.45449377681068,0.94757774201131,-0.303914759646803,0.354062029907008,0.719532741000052,0.981350798114768,1.4260828037032,0.0843365854216652,-0.749387618633821,1.67672720960281,3.05488759085627,1.85372304382719,1.55967295311106,0.338045533680299,-0.765221444360345,0.473077816013397,-0.698047121216126,-0.98774050751679,0.281164665585179,1.07291224802079,1.60315906206145,-0.813457298247516,-0.265364437829375,0.96827529656638,-1.24084822904664,-1.86290531957446,-1.79570512634645,2.20518259563365,0.840075838712625,-1.12375788632213,0.197091720857992,1.38654219607514,-0.706390828065863,0.0704838327773704,-0.492785433058984,-0.0314503325085741,0.629052237930811,1.65237181947361,1.44144444032476,1.41812326990055,0.677114305122622,0.935834472072616,0.23340138735185,-2.14896072870566,1.49150485678254,0.292014404166136,1.65792569555354,0.331587071151496,-0.0126860478765513,0.706040566454597,3.21685095685852,4.61962540185116,1.34218461186089,-0.294175529798448,0.105478395503115,2.29617824944046,-0.954271665893699,0.27762350334459,-2.55560703060359,-0.0468326402133002,-0.0347019512918347,0.111936624310367,0.0331593862938891,1.21779669222041,2.29529837373035,0.202655018299461,0.660328667461514,1.31160861434817,0.937172263850164,1.35727537982145,0.180593456349989,-1.14603485267853,0.518165919501172,-0.781541353019939,1.15036649632921,0.03880076809591,0.0678458879936522,0.253286878578568,-1.40879078001667,2.06149683253478,0.008049314347863,-4.11565268800608,0.496866745812988,-8.99558579115041,-3.87204999289945,-0.824774245853075,0.579378038186027,-0.528414955072736,0.308331869234123,-0.450339257219067,0.0394816685456661,2.13979633024363,-0.482972627114514,0.949853367593469,0.774136596604257,1.05809575573284,-0.124003535547818,1.93422194325501,0.705487317437279,0.226921423088963,0.212967697592384,-0.464878068728155,1.37061913057378,-0.602947670204498,0.705635828898778,-0.230241097471607,1.25017055153989,-0.738638333849812,-0.534910066384916,5.14640414195253,-0.0276665288919688,0.790364203485281,0.343285018814307,1.88560990761428,1.52725912782321,1.13203317880889,-12.5418756802282,-0.476209616975543,-0.389576048901283,0.112872146022207,-0.33059130105668,1.58264621381955,4.30785106414498,0.802948208890463,0.0179905405851439,1.44386362337134,-0.996003222456892,-1.44333524573434,-0.0724984095644677,-2.01845494977419,0.388395462420792,0.925160398991203,0.787339779797896,0.694968432937459,1.00216067189044,-0.0459664763878103,2.60563953892384,0.975817142225953,0.166505112451768,0.128643410183662,-0.135345677869838,0.0391128382244271,0.631078709640344,-0.368349552742064,0.0262741413560445,-2.48544020647002,-0.0866689198139185,1.67943041502349,5.36793836452304,1.44214763100119,0.77053291770848,0.306266129846816,-0.558610531829825,-0.773026660692042,1.98701971073461,0.415883486545098,-0.0610776520819693,1.91892866977249,-0.398389249656593,1.0588232909094,-7.87581549630857,-0.631090569453572,-1.0315153973939,-0.344926540017081,1.22611416219327,-0.989990430039284,1.31177044498585,-0.619572335561426,1.34242048894166,0.889239179821693,-1.0812152436375,-0.363111792377686,0.0005834550621947,-1.56992280547199,1.37423051610531,-0.849333024382971,-0.305366818007106,0.156250377975621,4.59599121984537,-0.917071782183458,1.86862165461269,0.0563010574533621,-0.414220787564603,-0.756339951383187,-0.859713051109423,-1.22860132924012,0.974614721309015,-0.215061049108612,0.837789165859423,0.329961113432019,0.519209158290435,-0.394850670845737,1.30057497478002,1.4392082315988,0.440426273961192,-1.13643105685537,0.0648341309608802,-1.51891544155035,0.541718926792891,1.31869830053118,0.223633557199262,1.27281173569643,0.710994662992385,1.63726583518657,-0.240443123238698,1.07931282095759,1.34300590189136,-0.185498578335175,-1.08541931071127,1.78704444936253,-1.26989404251081,0.569737327437784,-0.95890291632381,3.07652979869269,0.662172230757403,1.16080666483672,1.09709502471832,-2.46014329197146,0.225062315334088,2.61814229418264,-0.10637621775832,0.0885459547376937,-1.26367974061369,-0.868940826219834,-0.662946046501578,1.15913542828521,0.303128919944435,1.02212527966067,0.496830209146534,0.444739038660954,-1.31068418858126,-1.02303120797375,-0.525726564017027,-1.01639324593184,-0.131770527205656,-0.166191208218461,0.171750612060459,0.0349071043493868,1.95199201064158,-3.15730712090228,1.759247460267,1.35836702839758,3.0197404207034,4.13783683497998,4.13246389713003,3.71288929524103,3.80907594667829,2.30089443776603,2.42643280600508,2.00148526626613,3.26158454822833,3.40279371307631,4.09391182702914,4.91785071056565,4.31352332575143,2.66067027657541,2.48195386638743,3.6396539992044,3.44264397684973,1.69569365346656,5.8563932148043,5.79364414692454,0.258555160773118,5.97355569173344,3.91479678866992,4.14198623236944,7.09891625215749,4.19963266902077,2.69386747884008,3.04446910225824,3.10093489093256,7.01671438495857,5.22544230971559,8.28742055534983,8.20479650456012,8.63621438967976,2.90208643306647,0.898474023721059,0.942289402014327,1.11145278248281,9.06761342731767,6.96770866359565,3.85415032971366,6.50318451651946,4.48826730168204,7.47232389650112,7.42136996239257,7.87515679273047,8.32658106147414,8.7759971528627,9.22369194937548,9.66990017304097,10.1148157246654,10.5586001882538,1.33897371069007,10.3939171427504,10.5417508026636,10.8196653713117,1.13014648418496,11.5863805198184,11.8179219897853,12.0958932259299,12.3739891389716,12.6521968313004,12.9305051249875,13.2089042844176,13.4873857909274,13.7659421584186,14.0445667815106,14.3232538097233,14.6019980426299,0.965681439446855,15.3658043803315,-0.0713403777285035,15.5981926625554,15.8769229879536,16.1557014298057,16.4345245512223,16.7133892350242,2.82916799881581,2.60857946990866,3.54975512877325,0.34404807190464,0.885657038258755,1.72873464521162,0.0202179180614602,1.5548897630737,0.416413936043849,1.69987344643198,2.59145816263611,3.13178963278262,1.49126972926361,2.70853541135777,3.36830621710984,4.04560138120513,4.14086717613266,4.51835470349753,4.38289736244467,5.64943864783758,5.77651621042963,-5.19836019923329,-1.64354066791439,1.17950120574809,2.84479469928473,-0.0147931576652609,0.520539361927579,4.10487145129475,3.36734230912012,3.65809481979987,4.51904694695796,5.08369023030901,4.14594361146639,4.57174320411303,4.75051466030858,4.96089229123138,5.38101952251685,6.24165891255794,6.14765332384605,6.61328394324752,5.9183066586857,6.30238478416897,6.26158585106885,6.33288209288301,6.57461542943546,6.72050777097643,6.99038924197379,6.34428045616839,8.07523975163174,8.40142101040258,7.37804241221284,8.58497179585822,1.30021877705413,8.71325017095966,2.978121790406,1.0734990949761,6.15577293013926,9.28684735978866,9.84315322329519,3.35345148012501,2.09815186657166,3.37511020399082,0.963031254092613,1.64804777413239,0.811069300236989,2.42650326490524,0.716241580332591,3.66339525318756,0.355412643473604,2.12231379246165,0.047938380305255,2.30849245367643,1.78649494921925,2.13243062687771,1.05954227713479,0.557090903443645,1.39000150924187,1.44352346510311,2.24411874456383,-1.46426898705405,0.524525772902587,1.39436766175691,1.69422928947167,6.86619841481805,7.09219680097303,7.36554648639464,7.63974510878724,7.91463349246877,-1.63244121283891,0.407227280182074,1.38735982061524,0.417447287721689,1.2176203228402,1.34452078912347,1.26397355628777,1.57357807373238,-0.0008912294816884,0.577609830544052,1.46871292315117,2.39704134824746,2.94820920837905,-3.93073139597263,1.95609915073809,2.72047248689249,2.79103028235041,2.40082554709233,1.81235458422751,2.46267526851135,2.22537994112476,4.54367201286394,5.12575923008793,3.38613996883911,2.01523346310003,1.27139528958141,1.55276821126964,2.22514650025341,3.26466481012305,-3.34843873033788,-6.97642000754641,1.28663756547088,-4.81446073955621,-0.364223121381638,0.581573270980264,0.68382137690334,1.50515204317029,3.1298519330804,2.60772002929222,1.22131743135767,2.50671895922695,-0.285760408166142,-0.0855947885921835,2.94149944882418,2.52282067569291,0.872988038728802,0.962830680816555,-3.4204679837707,-0.571085006532232,1.52483716405302,-0.668973794096954,0.78144226309285,1.39934474808556,0.403326526860602,-0.0454102784513458,-1.30465465035444,12.785970638298,-0.548931183157109,1.13424300279892,1.13723897606434,1.63677796226183,1.13313858781029,-0.457654560738072,1.18975728641634,0.185734554774403,0.194120636801706,-0.257575207100777,1.33566696241079,1.80869795041448,2.36575487772312,0.985632693552081,0.435519332206195,2.34694943137396,3.41891065333381,3.56875123426923,3.48062317879011,3.56342789803106,1.29119504187036,1.15643107873873,1.09486151295003,1.07967115744319,0.608590312773943,1.29185826269199,2.26827061391536,1.43530513012275,2.77308160372497,1.88647569827836,1.03612940153875,1.79064923163963,1.97552752738073,2.42837911824053,3.46288948991687,1.82762056700016,1.26441977404559,-0.802528699267131,2.09615030972986,3.42199090467553,3.92110415204576,3.26657425418237,3.25907610397605,2.92854110729003,2.60912703784891,0.94520635153406,-1.15597800832635,-0.45806896998712,2.63288131193679,0.951966571156228,3.73823496480673,1.55496360697718,2.88180518239049,2.36518252886777,1.63005630331209,3.63344238024837,3.44895257232738,3.25389242362715,4.4011941515981,5.66724730913206,5.43726336227612,5.8907352377921,7.10298492227346,7.1515323543223,5.36741605145469,6.72746568826853,7.25193622855414,7.35214833905529,7.50878980635543,6.1391827154247,6.48309458751086,7.1919501426236,8.21302215295327,7.76395304621262,8.21517673687939,16.497471901867,10.4325276778611,0.0248807914815549,-0.365518405631879,11.6148005425867,12.5721178535385,3.54138524292281,5.42646054559111,4.10787318567637,12.864988563015,12.3525186682391,14.7063346696674,15.53613332478,5.15109356872598,16.6978316913154,-1.09337687781209,19.1672390103062,1.1453810871791,21.4672029942752,1.49695912243222,4.0664132778545,4.06404334190313,3.74030556080113,22.0577289904909,4.35901910783724,4.56964856472544,2.87112058054735,5.22219270751471,5.2133398229232,5.67813391258695,2.50022390414582,2.80929887414381,3.34685000184439,0.650677737498259,2.23275183861699,2.10772866087808,-1.67492805871463,1.08868850191044,1.33351901279168,5.31338185985134,5.52929920087665,2.2756363708417,-7.15904171709445,0.415616496914758,4.43991138307409,1.3422122564916,1.07309853428207,2.99449857558056,1.92765003845063,1.33765782444144,2.76253994253031,2.66427399774238,2.93522576984167,-1.64676405421121,0.0492431315858544,2.48710339519253,1.8564996040552,3.05725030538059,2.28498795250353,2.618584398377,3.22594669094366,-0.51942947320952,-1.23755547027318,1.13347191665669,1.86137334473124,-2.48482353043406,3.14191813880044,1.53170785726036,3.22201046223725,2.09801863238761,3.23806951076392,0.938943680000523,-0.124051888133202,1.7654516187093,1.18363142021427,1.94810044909488,1.74636046414013,-3.95232008590575,-1.24493887246577,1.1001181155631,-0.751792062726136,-0.228062380877632,3.2529263650346,-2.72266032465254,-2.37033515007664,0.76676154669164,1.974141135114,1.86341353532436,0.0992494427033949,1.66171286952217,-0.922135693038651,1.37376948070694,2.07443887131076,3.31249456257958,0.364541282922338,3.67657741239774,2.94382338959853,1.65851450876035,2.84902401493181,1.90580604250552,4.25118050159519,2.79541433019956,2.62973923034009,-0.408409922870926,4.36280068444382,2.72680028914035,0.727831411106392,2.71585507956703,3.68287614423407,3.8467996764866,3.15208420536211,-0.0254646126717458,1.42110000741665,2.37982185248504,0.74533277919767,2.18791662800118,-2.71426804459821,1.06959286384179,1.65909255408015,2.55133767783118,3.32956068110382,3.83594330652809,3.19993870654465,3.29943622098785,3.74859690056241,4.19597576169878,4.64182734988813,1.31042652386526,-0.843910597775511,3.16472117285823,1.40345824321907,3.69877241384725,2.21907469290599,-3.48813018118561,-3.93591892431521,-7.44901515872674,3.04150237620527,4.67255275192187,4.82706041999945,5.26231210944906,2.61710490740972,1.36307703789779,1.32562957435462,3.10670266443901,4.60150558710842,4.86453518123444,0.141547455482355,1.1762702245705,2.50103820829712,4.14718554774299,-7.19697963053735,3.13294449795257,1.51260401518904,1.59682357624614,3.30938527728796,4.70005527392636,0.705607819703042,5.00235242592827,2.71988211593934,3.97788074139497,0.623013013517624,-0.360628009949399,-8.40215367768915,2.36159360978361,-1.13189035724166,-0.757459362256544,2.79318461104641,1.12565266367046,1.28938093711056,1.1263660623459,0.58586417180689,0.158475887304227],\"type\":\"box\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"V4\",\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y\":[-0.798504315204253,0.746449665317911,-0.136235475448822,0.191727277807162,0.584093781378617,-0.0681375838378675,0.335419433465819,2.41534482266622,-0.164192349602247,0.236876074053261,-0.0533703364340655,1.20766252727512,-0.731286560474856,0.54064860218644,-0.351904423915644,0.0515866436454466,1.66830859756217,-1.96492819882367,1.19735822247995,-0.57565054188082,-0.233356793062171,1.42851599927715,-2.37049780969797,0.25502106655852,0.474669725362096,0.186138115887096,1.25847496178332,-1.40486048748799,-2.52985870819215,-3.53552251882757,-1.65259626385957,-1.50094983670214,3.19951255532546,3.72632061374787,-1.0368810152607,0.849933271188772,1.38457464721582,3.69474410321719,0.694127194012609,0.651406608714116,-1.25512694375117,1.47669085191398,-1.71824470678907,1.32596463027957,-1.63132730657343,0.407813943063858,2.17260988911288,-0.945789336579987,-1.59271563725465,-1.64135236707311,0.420770488936868,-1.21672110739872,0.438014560298126,0.395065777980737,0.248656608742151,0.676065424681186,-0.189345695681116,0.973702297539776,-0.85528648812858,1.48034225177119,-1.72359967911149,1.30496346487487,2.82797270628491,0.227426492639971,1.47298796375446,0.057384112363554,-1.29039617025733,0.337452438550014,-0.0220791195771848,-0.0204070100537494,0.48222150042866,0.14233415008569,0.456605878192993,0.925021108571445,4.42081962970288,0.765782641332019,-1.39329679516582,0.462922934388626,-0.122168645245817,-0.249935816663408,-1.13443111652448,4.67311643754974,-0.741780650963173,-0.639014438487363,-0.0024564160364634,1.84538395578035,-1.27459340360503,1.28241408289597,0.296300859568388,-0.550580804397756,-0.759128855469788,-1.26536145238004,-1.75747005280049,0.745443489839114,-0.241709232263113,0.389862264807318,-0.615477345157338,-1.2954083830544,0.251409023114943,-0.628230121827106,-0.933524682022156,0.27010532621105,-1.35726558231106,4.38019082865812,0.132866953226044,-0.682698106657862,1.98233397235501,0.852340177395539,-0.919401377421124,0.03998664455446,-2.14598331152068,0.0149975412225583,-0.071988497482486,1.60487714509677,-0.451448160428822,0.279438593249671,2.95640505089983,-1.17815493148199,-1.47554527567794,0.916005884265678,1.09048311377199,0.142346131357513,1.21494804937545,-0.743312514587284,1.32090720674092,-0.66360630805709,-1.2577675478974,0.0904753989410154,-0.0190775754974485,0.171837353163653,-1.15242009463644,-1.55413201861256,-0.636319426747612,0.544015966062044,0.628399639710172,-1.27149685228776,2.84220065033541,0.337718579631917,1.12171892558769,-0.422254187290919,-1.9308154402289,1.77851521490575,0.16191524574454,3.09056708537878,1.37699282776051,-0.965620761200104,-0.633723997519105,-0.361050972440982,3.60422740361203,-1.18019741588039,-1.50801880648803,0.195393909551816,-0.624437004129766,-0.954728164548934,0.282269538614058,0.411419978767992,-0.465615510880619,-3.01979320387118,-2.5973902443622,-1.51633852668717,0.894610685668396,-0.185899700279648,-1.30753437785447,1.05306586144291,-0.143964509994539,-1.15947630679263,-2.12680333301768,-1.6591200460075,-0.0633415802183448,0.485501251703601,0.868625091574408,-1.14529728279699,-1.82362941897726,-2.43983700484558,-1.06888109408847,-0.740349125300555,1.49386239732992,-1.82674602372956,0.0973769270331218,3.62025434258217,0.0648092716233501,-3.3569555495654,-2.02521924499319,-3.10228611877606,0.191252511730869,1.46338928243094,0.318305343032743,-0.0830254056248082,-0.440323357894607,0.997466839724068,0.238105125887956,-0.626314004125342,0.273922778128199,-0.442704106414814,0.0957264890669429,-0.59371691218928,-2.49180030864647,-0.208565190271253,1.32860046438535,1.17311695889486,0.24850506890855,-1.02811233873233,1.25198240214152,-1.28347936126384,-1.37864995621115,-2.82937577576752,-0.349027305076278,1.75548935743247,0.178598825872951,1.36850172967619,1.45018316255688,-0.616888655394277,-0.68538442775889,1.01559461174526,-0.707853104065719,-1.37850539234096,0.867551387723401,0.931818331474151,1.58144460129228,-1.40662614768072,1.25632616930286,0.207662948332556,-2.41678014083045,-0.0741541187514567,-2.52662428356729,-1.3100422688434,-0.399464340760696,-0.292200724514892,-0.633174542361312,0.138610721658763,4.26335224568218,0.630396549455607,3.24225730419773,-1.10642358160324,1.06516634743305,-1.5632452868734,0.786227416978078,-2.40985321137651,0.989607194883577,1.06734854257619,-0.301119780198347,3.46678153611518,-0.54367083901172,0.343576797478756,-1.54209747801595,-0.318242604916557,-0.513456104024545,0.242855054158322,0.470206033058659,0.0715076135230553,3.79513516445918,-0.384981692188206,0.260535452495916,0.701694623685261,0.0140779617706722,1.36918490202526,-0.42479338150147,-3.30223245423973,-1.56515573291598,-2.61395759234326,-3.24185792654573,-1.79091878160914,2.66299464735042,-0.342451171588286,-2.41993034741738,-0.238739637315787,3.35650471379127,0.316438106690345,0.0297760703615864,-1.74387628435124,0.346946657167236,0.323650776250657,-0.755787413764678,-0.0198503576883476,0.963916401753598,-1.13015128717054,-1.28053113750852,0.623223861748701,-0.174344611833149,3.08244799818149,-0.221644652619726,-0.730285614233765,-0.606941211034209,1.22840424828092,1.22759457733651,-0.628840070910376,-1.665327329464,1.12279851610311,0.16439771738824,1.25497319261753,1.56835457942036,-0.586482893303896,-0.20579639419043,1.82790109875439,0.212599373180838,0.250056931473439,-1.70583067680722,1.27099631651355,0.676618958572918,4.32230282042595,-1.06289945773745,-1.30974175394665,2.44369168605395,3.29285235300135,0.485533173743636,0.688721933730814,-0.952234399777368,-0.755601284846128,-0.328788336356241,-0.575655758870685,0.195110692279388,1.14470392684321,1.11899203651514,0.719541322054712,4.00006898502703,1.57893720281673,0.22064787676428,3.85188344712363,7.40494406837597,-1.17667264326796,-0.85897109655106,-0.688907142308678,-2.28021290709241,0.50189363646994,1.22311255913375,0.518929805165827,0.862714724095424,-0.629277715316845,-0.745177908084876,-0.808008933583532,1.89486576816646,0.556868573368284,4.2369149910416,-0.488626060727631,-1.37637197065488,-0.10004512595663,0.962776177831044,0.700205205381994,0.391313344030043,1.21964719031253,1.25267522303641,-0.281334816338225,-0.395635283428566,-0.63855615859857,-0.263438231978821,0.531564820349085,-1.5340656126507,2.83475282790965,0.971888468881552,-1.36487681503068,-0.361291889923088,2.37529796926222,1.10025944192562,1.46995381219021,0.434977455289287,0.632936440218303,1.0049581804781,-0.176893848568078,-0.451291970578649,0.489534430333306,1.76645808318664,-0.43997856075067,0.959792597254141,0.220229251067397,-1.25621363389616,0.610017984822279,-1.94275864212069,0.0337816456038616,-0.573737183368458,-0.655767164257239,0.76784953253011,-3.13898185609735,0.0007128179754471,0.765472499738311,0.183059904203185,2.16542242270865,0.304623361140279,0.191909386060231,-0.478253611099284,0.4079913068747,-0.540859301941742,0.0900062920779799,-0.660639536997733,0.227302098549909,0.049709438555301,-0.951362732880347,0.468244578442542,-2.45481742235189,-1.33620806532479,-2.59634406021693,-3.0282027814584,0.403058415865765,1.16547064865544,0.0999716853106187,-0.446216484168631,2.05382224319992,0.390089953260439,1.75438682261125,0.216215475620072,0.509793832223154,-1.9138196429058,0.083132706642457,-2.69543214319593,2.76147944239884,-0.585161164126688,-1.30021225195673,0.264832676738767,0.222367476952151,-0.49784083056679,-0.758488806971549,-2.35026632878194,0.143467614471691,0.504231491605852,-0.151419082495208,-0.820500592195307,-0.668105795915775,-1.93234404329693,-1.5681857453435,-1.96948487075172,-0.85428467896587,-2.58359228217893,0.205275105385101,1.27894939548875,0.51335265475604,0.718727057175493,0.981565914237307,-0.705189863893333,2.07732059224122,-0.268277095004917,-0.664262817267804,-1.5862714105834,0.236928193680994,-1.6191236868259,3.47926036996924,-0.602762174894745,1.39855396421174,-0.46687908463297,-0.873252326422078,1.78484888816876,0.0726446737274564,1.03217522115551,3.44787220900225,0.54825767639633,-0.627731613882115,-0.427513051289771,-0.982184054524118,0.497429313259259,-0.869183035436894,-0.484643115473765,-0.58030735754441,0.292746977553298,-0.132774690956799,0.0754904341846861,-0.851047825088916,-0.280201488444917,0.534130179499113,-1.51968230381586,-1.25805000462086,-0.520182065405444,1.48628736286442,-0.724924886083733,0.500214529871299,-1.16979626613533,-0.0333882528866637,-2.9235710123117,-1.52479326621762,0.347226540437022,0.817695695704217,1.12602493445725,0.74424314339597,0.158971884065514,0.334071255083074,0.210555130075364,3.9979055875468,2.2886436183814,2.33024305053917,2.67978696694832,4.73279513041887,6.6757321631344,6.34855667313983,6.07826550560828,6.04744510216478,4.007682804682,4.41666124290876,3.81919458538265,2.35709625199132,2.62536815276644,7.38024451788662,5.70150043141163,6.79679668055103,4.52249960508858,4.4559228120932,2.73066814884895,2.80533625940251,4.32819855298178,6.37974188053221,6.39582974649419,4.85389435139681,9.00714687170235,6.09414095882864,6.66627300324451,8.60755678650129,7.42694037455047,5.4676845487781,5.92819080241929,3.26463274045175,10.3432280604117,6.68995065770063,8.59434189301081,10.330099825448,10.3133493732845,2.507298518227,3.17025757451452,3.02404970580847,1.73159516277684,10.2966027898053,8.61789514115238,9.64831072711484,11.2703523334822,10.1072738734101,11.165525840514,11.927511869244,11.9061699078901,11.8853128922128,11.8648680803607,11.8447765860728,11.8249902296814,11.8054692105913,11.7861803616399,3.1236723071222,6.18596883540498,6.0172946473619,6.04661174671427,2.67568785863118,6.03851541556808,6.0862356342864,6.11554110191771,6.14482097803751,6.17407791004356,6.20331419234722,6.23253182330679,6.26173255148578,6.2909179135006,6.32008926518927,6.34924780743689,6.37839460769688,1.92186300234526,6.37089534679314,3.36177713733967,6.41844174657532,6.44759140152748,6.47673117996833,6.50586178736296,6.53498386355181,4.70769143992869,4.36008935234848,5.80936957402456,1.72168007534123,2.86129223993172,3.81354418795523,2.57204626116115,3.24161746276725,2.52086280678918,3.64394526899047,1.28624391005241,5.42094070941518,0.817253270463702,1.36186594394607,5.62311973109633,5.48719863078843,5.50567203744754,5.54745334718879,4.45522984017686,5.25284201867297,5.90271545151069,4.42066620155728,1.15825311047012,1.99882440095464,4.77770088131929,6.94512997633611,8.00535147326105,4.02839095079544,3.85970067435928,5.34024166876747,6.21476727765717,7.54603279503791,8.34439167363678,6.57705643811276,7.09885431317009,8.1748251681484,7.96392808742307,8.19961393161759,6.70277957100753,7.51992923163014,8.80736917876038,8.92511547634157,7.18360208606589,7.69077191542072,8.7862568391843,8.69861009281133,8.694896899191,5.58100899740718,5.66482005292134,8.25233430637468,9.19493491430021,9.50559351508723,2.58984264330545,9.24945923683651,3.86912437879902,1.38439373061694,4.1807791786876,7.81867331002574,6.15578864849515,3.61611930403552,6.45658840962748,6.13637764344382,4.9559633578155,4.89460056642244,0.935264670223385,0.27601659835291,0.217804800631468,3.88095965427288,-1.2555927126284,1.20184879823143,1.49395843665091,2.06410058377601,1.21433549160762,2.11699770636107,0.905586233912649,0.756424293386678,1.66142517591961,2.03698508634993,1.49253586483501,1.9213560843992,1.20919597418592,1.04932705568948,2.42543608490852,4.19421096699453,4.24306897383907,4.27332307326376,4.30340291762786,4.33334117975523,0.847752885502341,3.16182144737059,4.22868619369076,0.901644194576026,2.08707599095328,3.19529149873811,2.23799063903423,-0.572676430720841,0.338337780759695,5.15940136394611,5.17470627250374,5.17781925521834,5.18530347959595,1.71466918264498,2.79698655025108,6.34833355148109,6.99121396498416,3.46221746352071,4.12754860722303,2.3244800653478,2.17853822878821,5.50800333404763,5.52739306209755,4.36762905773351,3.81202413104427,0.790371244425149,2.99211739124618,4.34222824814605,3.40359359659281,3.17505971028128,3.41675415987856,2.41967479633278,1.20422986423394,3.79494903930385,4.31924127992395,1.50188726081003,2.28686855813503,3.41557336328899,3.06415614684784,2.06757505760281,4.8861341982102,5.33704802681048,1.40116573166082,3.25884522291112,4.08304665188122,2.75536885087579,2.74331806279958,6.60684578567387,-0.0145876823031251,3.28929147538496,-0.589439741635524,0.605760683474701,3.86437703955242,2.75655816357726,-1.31327481447103,0.0537401062585881,3.32033688288942,0.894081819978967,2.01222598912655,3.24229293383089,4.02857099852445,2.81340096831714,2.23077826688105,2.89138777331251,3.76115529034876,3.92074784640417,1.15267090326627,1.69388472852407,2.21308539346999,0.0897905975142065,0.317131047127407,-0.471119606930407,3.98335888025187,4.03598694267746,4.16471993013258,4.31123366835313,4.28434595524384,2.05820222243243,2.07627840454674,2.01255429562949,1.28783908383189,-0.267565092666965,2.13577170090141,1.87133052690782,1.99311717679272,4.44645597412376,-0.475242891532036,3.12824327369048,3.85343274655953,2.81919063998449,4.87129854095106,4.9321986662268,5.34830323951426,3.19364784504611,0.389760264731692,3.06945315960973,5.27089100906596,5.14826254938013,3.92452561357555,3.68473739367705,3.89115992835328,3.63194695349796,2.64006508673377,2.78675032975706,2.73722917151503,3.44611314661501,3.83399771227534,1.36744244056479,0.669327345741316,2.43418142416554,1.11160176466249,2.37836729179698,0.183208447320966,3.02105161812575,2.26645647990886,4.45357956949695,8.24614693395311,10.3072263079132,10.2590359766218,8.01082339822486,7.03111476501099,9.06447791765316,8.42583167857118,8.20414440620562,10.6485054461688,7.46577999198461,7.74055544506762,6.55419115286706,9.09955188204157,7.11609059812684,6.71185525207739,6.20736889019759,8.90415677106517,8.04607504591293,3.78754815533943,4.82088596439253,10.4638662754002,11.1908946558522,5.95566359407,6.67906180701896,1.71031444791959,11.3451198184298,11.1227714331133,12.1146718424589,7.04337354768731,4.53447860064768,9.5849686202149,1.06478463530602,11.1254347149714,2.09180337375362,11.7374361361796,1.83672705849852,5.89860229319899,4.68000806392241,7.44096403590735,11.8450129100508,5.36402677044258,4.44107935434428,6.89095207502484,8.11772427554261,8.43198635177602,8.41629539413803,1.18945163355882,5.83556642595055,6.83580203854396,3.98782809057201,3.38670841159996,1.41130357398271,5.6175556662941,1.00873271714408,1.83500588341825,6.02897499089959,6.08132107951892,1.22694819658893,1.30957974749918,1.53684419661661,7.78868440738042,-0.151513299728476,4.17326819444992,3.98651893184362,-0.0739425941379643,3.24535764512838,5.20140306725894,0.394707094952515,2.41901198641213,0.473353567439937,2.86546277005979,5.32454683526606,4.10009796977678,5.54397248278589,3.8311119987993,3.55245370976796,3.59316052421617,0.774741045624737,4.83349012798216,-0.283072525739314,2.44808047483365,3.67056244781436,5.5218205893507,3.58461483133399,6.03734512826846,6.5145732431847,5.7208466769739,3.07984368774547,0.382608915041756,0.9874099790721,2.17990251484867,1.30580476704534,1.7722054455123,5.15352461752314,4.54477220840185,2.20471352581391,-0.203459370656895,2.20188352154659,4.63241097983647,2.50200470213773,2.33504453116197,0.116771978233793,5.39079309979716,5.46368064632147,3.40195536781235,2.55505843390024,3.37300132781874,2.80535094114905,5.44805969239449,5.03698507739508,2.40003149118237,7.23205827524957,3.53337387196109,2.05206440242466,6.00941477810058,4.50891315092218,7.28365703710757,3.24751301512342,0.694992040498764,6.24946176104187,5.30453432323767,5.34275900861121,5.92484984705884,6.31066097414859,4.01673095104413,3.12145858452036,5.53125220648323,2.65053018469314,2.94294608011161,3.81839172249665,3.89355597724996,0.119476214172018,1.44979237466742,4.61740996943795,2.58803264715889,1.63696695878653,3.6017196361428,1.84411148322924,6.50233023566696,7.78363417666419,7.76324179132026,7.74321514676806,7.72350199432307,2.62028192286183,0.75975906867787,2.24659736005894,2.66010705652321,5.62048638535855,0.236995179253694,3.24681566349703,0.163310074791927,3.72843914957409,5.9675870384467,7.1435001202707,7.3340585164719,7.31648729995658,5.84296995871769,4.17351574396431,4.23315121365749,3.10990342442989,5.71608803673092,7.65239936205533,-0.457662244561315,2.88213779866317,5.37416005823382,6.49374059630435,5.104798647287,5.80389261500645,1.75379247237301,2.51298558446866,6.39457369583463,7.67188445074794,0.514779310643757,7.75691471173633,3.04443718621919,1.65776584508859,1.67888930740175,2.48610285639632,6.9509829448522,1.9707587789256,1.08696263677666,-0.755458092963448,2.40073141993213,1.74929253346589,1.4118498419441,0.46830838758824,1.81709247345531,0.408669992998441],\"type\":\"box\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"V11\",\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y\":[0.504579086049177,0.388966130830033,-0.978478624052058,1.84612084586317,0.533205436249431,0.926583632311737,-0.541091325310213,0.487884891710484,0.935562677894048,-1.16877902718797,-0.844208360039966,-0.278244217398965,0.172611926156316,-1.37378474024248,1.08710981015992,0.516382892799812,0.942664972283113,-0.634513704437543,-0.173838752949858,-0.0856189348143482,0.321733714132618,1.21882074487274,-0.643902277347136,-0.689680499389149,1.5378110752664,0.563058626434135,-0.268609357130232,1.39380203210307,-2.2116867743703,-1.39027688405241,0.274893875201137,0.55422586302907,1.96022235460685,-0.0233202574590879,-1.35267992051846,0.951187092297051,-0.0702952371671307,-1.79454367172849,0.022651772642376,0.683623010408824,-0.840966449985159,-0.188582978563335,-1.39734599335765,0.758821905114858,-1.42382876368974,1.73055947527395,0.640704654656777,0.534381457695334,-0.291861183030441,0.694481143844459,-0.45526262097222,-0.79604181219342,-0.485733983819266,-1.84950901685822,-1.76461092987039,0.336957066219557,-0.288392233682203,1.56339487813708,0.577918271617381,-0.401958980078942,1.03985049177819,0.805370377644208,1.20025966772766,-1.04011887204234,2.89392310118071,1.75490885496213,-0.484120637320938,1.43008595883739,-0.436550443950052,-0.276640492134051,-0.799763192819392,0.0741514209665695,-1.28260265543163,1.05916731785909,-0.80242471148409,0.871758265942236,1.11327309038148,-0.705192935675908,-1.08545991808436,-0.935766168537404,-1.54478960187093,1.44029349406384,0.0866232055931826,0.0229362502168991,1.06053185647527,-0.582343641673757,0.428326565314028,0.0833440659597867,0.333876251105507,-0.0284941695140753,1.0804910446871,0.930545182055951,-1.48134404743203,0.893671350959719,-1.15982439033409,0.557963345136853,-0.562765770361888,-2.22997353080615,-1.68473170613296,1.14379311066972,-1.5662247021163,0.726049892058882,-0.388161528828055,-1.28665612534353,0.432216719734024,0.86149662439488,-1.70029628603509,1.13762261571622,-0.276238489032417,-1.38854025619787,-0.204057642223532,0.113972172509604,-0.508921790350981,-0.801226834749029,0.683787205191732,-1.07918966663504,-0.861373488474209,0.0427224326121339,0.459033640220746,0.118590303875241,0.373465690301319,0.020589032928147,-0.988863268899718,-0.845586284341876,-0.839567177901607,0.495243707097597,-1.54897217104915,-0.159721464624235,-1.14145567948264,-0.632606317204491,-0.628070055637182,-0.355773326464421,-0.216733139759314,-0.988586738058276,0.729579389962081,-0.240346942604364,-0.414433794754597,1.30572658993841,-1.52545247016586,-0.424181274370669,-0.150203671738358,1.27418599240195,1.82159470737535,-2.27528060324321,-0.9411470000784,1.59039368731094,-1.21301109672964,0.640931840654039,-1.48652043812375,-0.504343881894505,-1.03851987778669,0.455556524745668,1.07789436624594,-0.149307697173257,0.373720016262333,-0.619410053363752,0.359942450091996,0.629848494776516,-0.242311586137507,0.008066727733995,-0.493873833670897,1.33180035155625,0.536060799324063,-1.21110540794647,1.29433554529939,-0.958918700280753,0.630490112260051,-1.79286566406153,0.0431880746091364,1.51397534855303,1.2581377261926,0.736807279045356,0.0160176060961017,-0.322778374920564,0.260114367805838,-0.144922855429239,-1.47024045104948,0.0888807345663853,-1.16071627166663,-1.93468856960434,0.814156490035141,-0.63333779784194,0.843574928113372,0.0999617135866182,-0.973338890624502,-0.765817709736697,0.291566042647954,-0.443063942563802,0.875259878330869,-1.07974295530802,-1.94442496676893,-0.0815807782578976,-0.400389140358934,-1.01538024820699,-1.11203680583312,0.139078991253087,-0.61243517801306,-0.961203360774208,1.16741241206306,0.902206699249015,-0.811168778839411,0.214372230551019,2.11912949976798,-0.36323229688964,-0.181578343820628,-0.406548315299127,0.166834462341473,-1.63430704832657,1.76681172282559,0.0717657420429196,-2.53440610602288,-0.580848040427974,0.444536439289916,0.939936941604546,0.859863979094823,1.35146097524734,-1.09276758637827,1.12129648728196,-0.594163347666949,0.283522400450053,1.60634195106108,-1.02323623608635,-1.55068829859634,1.30811504195532,1.41404514387676,0.901475835740009,0.874240319731224,-1.5114505953703,0.868111099639819,0.396011577752972,1.24588777021084,-2.3730307147362,-0.805890976822929,1.08419693197783,-0.464819865805848,-1.1497096793284,-0.607646544107593,0.725004455149095,-0.972053736500534,-2.06832624023241,0.907651474236417,0.0250734888133422,-0.697767936644854,1.08736336187348,-0.410918986709039,0.947504969015652,-0.934663927167526,-1.35590173494855,-0.397483006857178,0.777829320085692,-1.57053404378298,0.385408895569179,-1.232225560334,-0.249858669853365,-0.0126605938186682,1.32842594930375,1.22193355370044,-0.513120903876049,0.938176893265011,-0.293303651141342,0.163239601009771,-0.453652374106572,2.09473973493956,0.194061009470335,-1.20354208016034,-0.211574858892686,-2.27281252487797,-1.06859887624194,0.439886363904673,-1.19752339354543,-0.371656440153634,-0.505472692182557,-0.929650107283515,0.496104396718463,0.926742560879389,-1.21406119943506,-0.0951528200197317,-0.262872741122919,-0.379098175209659,-0.407563114754369,-1.48070564092609,0.749172942351747,-0.73472612819897,0.200333829004198,-0.819364543770756,-1.29881177712684,0.675734538694722,-0.323561549180519,-1.08801821860886,1.08415387351508,0.789728974463101,1.36399994023388,-1.08019219994516,-1.3298270662982,0.154759947018345,0.391785703684402,-1.37697419781615,-1.03823523557065,0.592136263331013,0.0344709672592151,-0.914515507885582,1.29797394331013,0.338003038268539,-0.407845211563861,-0.628468900230548,0.944194792030483,-1.65243297804171,-1.01627709093853,0.0619994540580587,-2.069490573279,0.561752002809957,-0.981142888593441,-0.515725038137758,-1.11732787943692,-1.53131904644161,0.616815497439985,-0.672623136148956,-1.36144530056221,-1.34420230633534,0.072141835833465,1.26342589632468,-2.27734538756591,0.615564021976907,-0.870496608429436,-2.0481635257614,1.6120891984837,-1.37170826044248,-0.483679530623485,0.738670653192305,0.271025933948307,0.0316103722424561,-0.365388834333865,0.672725548785863,-0.807286380854941,0.632298010375298,1.39513154644514,-0.510330736447199,0.0752632563555709,-1.88982651062076,0.506833953655501,-2.37812514193425,-0.550169883456547,-0.891435714890451,-1.19767445098926,0.0317699009704347,1.88972974144176,-0.0554439266710254,-0.839291912073635,-1.21509458088514,-0.0601880617603286,-0.854431466917493,0.20886972467867,0.387390878094698,0.792223617290591,-0.580540336879805,-0.483837375632956,-1.09735757481877,-1.83139072004322,0.387635647055296,-0.555794411529266,-0.545884823006631,1.45585216432332,-2.27572503853042,0.03666066784636,-0.115632837622709,-2.02443707224882,0.570061568254373,-0.49484840203961,-1.31978063626234,0.86152863902094,-0.685902512114828,-0.394981860465351,-0.36313551338693,0.489838266175561,0.773241186312033,-0.609777354399257,0.534569008475675,-0.195196021955935,0.885314383167611,-0.560664490661123,1.00927197965158,-1.40562702960955,-1.02014900319833,-1.09947616588724,-0.503500697248446,0.968271869968845,1.88554096276719,-0.738395410446329,1.74753172957429,-1.78962229274422,-0.565098663309821,-0.821862307712133,-0.870013019737915,-0.150733299081503,-0.205509335777926,0.614924084666754,0.939697772498609,-1.47676113586972,0.457402591421875,1.71828774114694,0.555379152797645,0.0840415623726238,1.33342711955404,1.99820902542593,-0.846933368507922,-0.288930063992251,-0.4443505464024,-1.72843037409986,-1.58190634234074,0.0763181228377049,-0.923226821625099,-1.14546829425224,1.90586013670673,-0.0210694137912108,0.518923669108494,-1.05437207321431,0.499806431381422,-1.21035166707624,0.0581585411977325,1.18118010274054,-1.79961965290597,0.151529828000805,1.15322653872905,1.47410811378808,0.495614176015894,1.49128801921631,-0.892281756297508,-1.0432785657984,-0.675379708798188,-0.867875921532954,0.744920005468959,0.785274712165791,0.359195101043384,0.146282429340961,-1.39230272558633,1.0632239769358,-1.20881348098704,-0.796658229144483,0.501257463649653,1.42592950061683,-0.729665751497567,0.0817461372679467,0.257529353671017,-1.75165067552607,-0.360097839540111,0.237942393216676,1.24404142714263,-0.411759842420838,-1.39577122854217,-1.15355518105467,0.319560218140115,1.27261105637341,1.29738073815959,-1.32540542154051,0.288845712813837,0.374892251118293,-1.06658555267138,-0.25798478703341,1.11626605177594,1.1913550436186,0.599842359362915,-0.883588035540767,-0.327561950741929,1.20085526340245,0.365937926154999,-0.384045661837632,-0.147795614827735,-1.58578337987477,-1.75864212965243,0.250018019314968,1.18066434209635,-0.703203642202038,-0.655355392964771,3.20203320709635,-0.414575448285725,2.03291215755072,4.89584422347523,2.10134386504854,5.66439470857116,6.75462544809695,4.56072010550223,6.43905335158373,5.5887239146762,4.67572941865677,3.57205481558784,5.45074606689486,4.36671348631445,6.35507773663404,7.38805512292025,7.62008905836908,6.66243683071252,6.45418752494833,6.35361231915591,6.31620967716699,4.80232276125089,7.10298858788516,7.07166913682445,4.69039566550924,12.0189131816199,4.65408842254301,10.8530116481991,11.6197234753825,4.57011280759332,5.27550585077254,5.14940878300581,3.18718689736493,11.6692047358121,10.446846814514,11.228470279576,11.2779207278067,11.1524905985837,3.33850216040272,1.07272839973578,0.154921008931302,0.500376369958899,11.0270590938161,9.36907905765884,9.32879925655782,10.5452629545898,8.80568196718575,10.2777688628065,10.1875873241664,10.0637897462894,9.93981974172569,9.81570317447819,9.69146098207319,9.56711029521397,9.44266526535108,9.31813768535999,1.124059382453,7.39441941053863,6.32936467621872,6.21088301172371,1.83449419801385,5.96620250720685,5.8492930661792,5.73081553744459,5.61234710799626,5.49388683652872,5.3754339072439,5.25698760960799,5.1385473219039,5.02011249777419,4.90168265513877,4.78325736701241,4.6648362538527,2.35161910622909,4.41994345577668,0.987277021963291,4.30309581759563,4.18467368942509,4.06625507293473,3.94783971729026,3.8294273949908,3.79256535985687,2.11151686706104,5.47939151009669,3.02816223099618,0.675287853392807,2.36843367282003,1.97582106179607,2.75617194535395,1.1205051770709,2.80200512615164,3.90739912775712,4.72997415443333,0.0243696057661544,3.77974953895486,3.83978771072745,3.77960220775921,3.53820204012168,3.36784560815482,2.95434436554049,3.6573495649865,3.67670318691664,3.26606601582438,0.159743522312315,2.80433477984687,1.84409317018026,5.73008435556377,5.73576265915634,9.09528815249629,3.82376208408163,3.96979981229186,7.2529532268294,7.38185937432083,7.67453383416429,8.26529460055417,6.87757089846463,6.45582813287588,6.64520072606617,7.04773274001302,7.60555947435276,6.89518136811315,6.85495311388866,6.78605830197451,7.12716532148781,5.80470785195987,5.97513066688423,5.58936163192341,5.3306013514672,5.1483517210937,6.03766622940467,5.61099879659254,4.82823533219729,5.29923634963938,3.49080495043995,4.39243558567834,3.47109784646449,4.35477463025116,3.18605794805635,4.81815244707108,4.67734929657245,3.58682418337431,4.38921350258246,4.09721607443527,6.27866584548672,6.28337707847689,2.77896789639267,3.65788166668826,3.36736102310858,3.52572598717089,-0.473852105914046,3.53221960237349,-0.984171728067149,3.43824825990431,2.96259879138962,2.88704787664695,1.48028602025778,2.28193937592012,0.141178993422237,2.81431415481622,2.40165068027699,-1.06453419450651,-0.668358831257417,2.5555891530874,1.96223597455109,2.94398521977131,2.82667122820047,2.70785640511515,2.5891035399443,2.47040101557896,1.17235508293037,0.90311745288141,3.20091235546057,-0.876737591678351,2.82114488798301,0.747478135782509,1.17447506014201,2.37853722491518,0.0045179679664243,6.25006758982915,6.02903256317613,5.76318940883843,5.70520550718269,-0.153131026660117,2.33832327000211,5.26658587269696,4.77414774007074,3.26492215161104,4.31571103012142,2.25514748870463,1.83721490161197,5.2241240042156,5.72525459149638,1.84750351109611,3.55473755027372,0.614977120327696,3.1284396921776,3.76230638231684,2.88609147657536,3.06424584128211,2.61176184321338,3.5617949640183,0.144562690111297,5.04075120270381,4.83896418696128,1.91445404493049,2.79039639060721,1.39818511854919,1.11335409263987,0.915947028928619,3.54601225001006,4.98601380361468,-0.921051995675577,3.97722223959189,1.53319383793753,1.92856763203456,2.14005681553663,5.26786160380362,-0.245676823310174,1.27720226474415,0.881268050432366,1.61826162043188,2.6215881261205,2.56070020158284,-0.651414013964987,-1.35655775612738,4.40680552357904,-1.03941706835478,2.19166507997652,4.66325458481107,1.60198538284757,1.55375586796783,3.51034756034463,-1.27393508028395,4.44719176626515,4.37690666362302,0.82637484441332,2.57283021584331,3.1020899271543,2.60516857519668,-0.39560772252726,0.567551954604602,3.04839203447565,3.77557843937585,3.70431215185119,3.21126387844398,3.25959475409854,1.0804386160969,0.763204840843787,2.60593702345612,0.706999574201444,1.50062918076179,1.35275258963919,3.35763973653551,0.273983570211148,2.39416766551329,2.50978140392157,1.29341829662131,1.90428359307622,0.301368829965399,4.3437434980468,7.18296700883659,7.19030608944843,5.41604190908794,1.27462907751277,1.8806015528528,6.30904400603177,6.34897930341209,4.52299197543382,4.35148149710451,4.22130410784879,3.36918605153883,-0.529805728295342,1.03303201224459,0.504116141204789,4.25656448730292,0.301977229683697,0.382172176843061,2.20944075185923,4.921657447038,2.05681205985716,3.50456779253823,3.71921153916465,2.42595071598052,2.71273940377591,9.41303953977606,8.62125508140256,8.78878366710272,8.87947566765026,8.68830799242781,8.46024444901677,7.15408284221914,8.03070840755191,8.38914233451929,6.35722736343626,7.61081978841573,6.98988561330738,7.58874088021049,6.05731930477932,7.42580096307482,7.09318207259894,5.93465734341534,4.41999660154863,5.90239975502551,0.7653541419638,0.637766685379952,5.57362527301538,5.70211147983179,2.02467408050134,2.54083553206878,2.17523030559549,5.56925817499418,4.41705461009659,4.971248707036,4.73958247105186,5.20081516878268,3.22323270290842,1.36858453419511,3.7859770496129,4.87197985976052,3.40932261990014,4.28702087961434,7.02127774818005,7.86446740028511,6.82579316213884,3.48195180343701,7.34365210856032,7.00213577397937,5.35088988417692,7.18872396524447,7.15062516950116,7.05106508958574,3.69471123994721,4.69879549591235,4.69653339192897,-0.427567391481657,4.54630106888309,3.51964234486905,0.606910821999133,3.58604242366444,2.45371037821171,4.43173633655471,4.3150759158968,4.17609762346479,-1.39432826167269,1.42841254547618,4.22041859352387,1.3415717221686,-0.408402781057003,1.84607851719332,1.28674925677162,3.61264534637429,2.14393063330902,1.96148093151336,2.96924007367485,-1.54230486820434,-1.12757349175133,3.6195974073081,2.99348883356357,4.51335526006987,3.36955824955852,3.27754628526759,3.24943114650197,-0.375466188651408,-0.0001211803349648,-0.482409384022894,2.22296005779154,1.73812401383737,4.77672033006624,3.21163365301808,1.51389817939856,1.05148630261883,3.39415208597649,2.07411645462861,-0.491112318271443,3.28282460993431,2.86702850008408,2.09307500991474,2.4507521592725,0.983646778914785,4.18216236800046,4.49792897288062,0.253931337415353,4.22915426403483,2.68057817990216,2.9456208658257,2.94293916487767,1.20030360709416,0.195839103876469,2.37587561688329,3.72393253444097,0.997448763245357,2.73157578227581,-1.70222840135659,3.2740753098509,3.94231582587852,2.71069667870109,4.21321289394162,4.4045784815908,3.9168025570096,2.94119009271712,2.22079491381924,3.87116530391397,3.05365441815753,-1.59425779202416,2.11390001406861,3.53614548208968,1.99136063471588,3.69317394224412,1.2038344844503,2.15579608547647,1.92718574923744,4.7365938426554,2.85877650156878,3.34180192747217,3.59279683214404,0.613867739096179,1.90399926160786,-0.448793725596362,-0.688453906925825,1.43932206570096,3.64225693939881,3.73703768128326,3.35972193954249,4.56919375212135,4.60417047790948,4.48003526995735,4.3557700196603,4.23139330449617,0.470864719590572,0.0110374511201705,1.86359573670074,3.64647783754223,4.43631907416962,2.21400028680889,2.94437484242405,0.71387764641859,2.52894302060173,4.90581986504193,5.78365443891613,5.71631869503674,5.59112619350265,2.75783745850663,1.70189470812283,1.45123754814542,3.58639450927204,3.8278680907164,4.1064045585523,-0.800150416391868,-1.51420473629918,3.48060170327307,4.46946731169238,1.1682159434835,0.757063214391669,2.17297610055437,1.96612345703981,3.61873721262172,4.54849458373201,-0.191190536963042,4.47590467269415,2.28802174654208,2.98962640655731,1.77950450310136,1.05410721205494,-1.47514531556892,0.874051625366684,1.03201558219625,1.33831754595819,1.24195817554592,2.1157951772133,2.8584658156696,1.79496896856641,1.93351953683592,0.491140241656789],\"type\":\"box\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"name\":\"V19\",\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y\":[0.349511782992854,-0.32778431333547,0.226161793337683,0.192921125420964,1.22877146134467,0.418806995775525,0.335866637643759,-0.524370634467985,-0.0577226858132946,1.77310995070472,0.116672715748714,-0.712279419115083,0.327993541058147,-0.299768850151738,0.379675601859698,0.457863187019465,0.37156766187458,0.930881050988091,-0.402231086225111,0.96659337795661,0.964963039427907,-0.322280199794356,0.170711297695114,0.362903834795544,-0.150267525294398,0.614114694897377,-0.31574820908163,-0.0230441988990556,0.352083307655312,-0.350168973900931,0.819934798218484,0.654395121981179,0.0038509029056758,-1.34092879667356,-0.36103509407069,0.70354172160314,-0.990759964771578,-1.58688917502273,-0.641286424689703,0.367604312340528,-0.632918596106386,-0.496454429546243,0.043498874840878,0.0246869153100427,0.0002210554927139,0.0222382497595395,-0.108617769163444,-1.66159661667044,-0.502565829104553,-0.004084837156214,-0.361610801487403,1.25705865333083,0.108821578464643,-0.0429245427081534,0.0638789657975271,0.508200849802966,-0.0054572642635306,0.281916840496972,0.230532055841827,-0.410344136092181,0.130588157408813,-0.266592623673325,1.22959148054341,0.305821813311635,-0.912261753152464,-0.941854007244029,0.754747886962965,0.266861672088008,-0.105486635755898,-0.196362158484278,0.436438135892532,0.271246888026843,0.284927210853641,-0.299059506127351,0.848092234029571,0.346109132581053,0.279980430287229,0.246982159164657,-0.310367808426199,0.42317952149943,-0.203221650457926,0.875840587292041,0.46463930783986,0.772788378940356,-0.398141918524562,1.87959491005704,-0.027621481617815,1.0336545121884,0.540232804037194,0.252709358649747,-0.359893890486243,0.089046261768601,0.0184051550372061,0.707708866041003,0.459207009433885,0.0284004850954587,-2.00239224133035,0.308241628690511,0.113829279121811,0.0109678952377757,0.179680826110874,0.53639162819458,-0.853040154211817,1.43065407815553,-0.0986498162543745,0.124444901220986,-0.224502088214394,0.135987224791507,0.599473076401502,-0.126803378393814,-0.579118178760166,-0.0975060084843629,0.25679886388545,0.567968828406203,0.62025129289977,-0.89852593170389,0.320538584229294,0.399986965360007,-0.528876296190779,-0.521042013088986,-0.484970179089656,0.765200955427645,0.758242122771037,-0.31690106838124,0.0561794334448101,-0.751745830846369,-1.84248274081921,0.275178538554211,0.903933062337829,-0.180834792825948,-0.614360484797128,-0.655012006801155,-0.05644860681936,0.0066357645285205,0.278240457580612,0.195115750927066,-1.17757607390592,0.204807638086698,0.0410383700263831,-0.088051343138178,0.536867836275323,-0.654706173460776,0.183802662999659,-2.78020993571903,1.79067942892149,1.25779402282181,-0.377518729031792,0.646484221437335,-1.76093045997,-0.765076875522506,0.0580143798410562,0.647987078816449,-0.0525789968959243,0.194122685496397,0.373469293165448,0.138519580224933,-0.694548479584381,0.347601481445949,-0.342243964133515,-0.855723815076179,0.570831725675175,1.26219684615866,-0.741689715111838,0.911125466003106,0.304217295466808,-0.633208912319302,0.474176526246748,-0.0022344517204263,0.339299552313378,0.159728394653561,-0.296947585712446,1.22272198942141,-0.944721525119375,0.0727856898087844,-0.712832666109556,-1.14587843351541,0.186763978535458,0.275143015206617,0.133698401528651,-1.08382911007205,-0.545967375812028,-0.405097752899952,-0.12826503744967,-0.302583001876998,-0.167345087651144,-0.0170015709590669,0.307099079759801,0.0111865680745225,0.223468382961967,-0.461824497865398,-1.22743060582818,-0.453000964894931,0.100172443322396,0.611864729112891,0.296493719757227,0.988796511037724,-0.70756267572249,0.772523062175835,-0.145370102633086,-0.296591141217628,0.845646144780336,1.19141062881486,0.178227653254092,1.00961971396738,-0.364512115834257,0.305741625079988,0.928513451122424,1.09992781793648,-1.17281932038236,-1.93419248160542,0.338757563616759,-0.320935327980643,0.240459178417129,-0.264213071411622,-0.172518347896682,-0.0333108463180112,2.96042991370102,0.0331787849580174,-0.758791187517623,-1.8401069907249,-2.14918476797647,0.106185581962875,-0.274613596658954,0.476227021879887,-1.00581782833321,1.00436761288466,0.778697659410074,0.475613408533886,0.852728597171164,0.200862890648903,-1.57780826833669,-0.467562968963074,0.0585463587594405,-0.202182335500302,0.284559635708331,-0.180465794800142,-0.228691724871602,0.639826771690595,-0.124629858854995,1.07017897716381,0.167232888588141,1.71999865650842,-0.320681913813639,0.457559367703808,-0.548528338054204,0.100836990380796,0.306634027335595,0.28010905074047,-0.0318358604027582,0.0731309009184477,-1.35491631338366,1.02422745890342,-0.629530725825486,-0.189016258669576,-0.448761802937124,0.0172454194972637,-0.290621991523226,-0.924783632620659,-0.67653382779745,0.924496516038366,0.169018520514791,0.576270069399153,-0.403068725490952,-0.346001196310772,-0.84409015526754,-0.219086082070861,-0.0474828224860932,-0.38682507802766,0.594440791011349,0.462176941825975,0.0009917086744514,-0.149164419939795,-0.0955863552117982,0.235778338440438,1.03195211811288,-0.294409161203842,0.319179201564689,-0.117161144003302,-0.254972038999782,0.550593823070402,-0.348861154206411,0.151419291835257,0.843817374522148,0.198026806841997,2.04401091043221,-0.452568210760557,-0.114427116436399,0.19749784322143,0.103611302920123,0.265562888002784,-0.47841741320365,0.48954040024191,1.09206672836998,-1.80686689745736,0.246066447379909,0.621086372406786,0.122222544321037,-0.678774166332119,0.856230472505996,1.79529071689683,1.11110489291656,-1.33084357235424,-2.09521315264233,0.16665966447594,0.7170195193099,1.41080172247542,0.920606869148026,0.595434600018156,-1.37308786984053,0.4262585762917,0.530641844909215,-0.164955477631965,-0.281368273763803,-0.212575815220689,1.57782435765213,-0.894836219782724,-0.397267882317301,-1.64470031590943,2.13224687532853,0.30864203705393,0.275401369452703,-0.0576336840391119,0.203134397497985,0.119504306388828,0.106220693689556,-0.253877886207892,0.622522866315851,0.446437689074686,0.125106624817809,0.294286179186609,-1.51734524785437,-0.579481101228266,1.42262506353582,-0.445959069054487,0.22610420307278,0.976078045990397,-0.127388225371282,1.21824276184366,0.021206789124805,-0.326511551542897,0.278414948399088,-0.0235558208685598,-0.991639351534969,1.23981132333077,-1.05826022412725,0.201203829391344,-0.0334035270460257,-0.736944407385182,0.452318966722157,0.246702001444461,0.423318716697852,-1.42422462654313,-0.335155549784093,0.233841023239635,0.0393997676400495,-0.162576018936308,0.740928174667756,-0.0356720264060895,0.463422592794763,-0.329512407342219,-1.55354221815084,-0.663315824641065,0.723310696503051,-0.186405939468386,0.468930308950909,0.128381942805112,-0.382552919900771,1.05808150674893,-0.0479362487331059,-0.0070107830512795,0.251663137689787,-0.314518048323965,1.02936081040009,0.6017447458639,0.522268924455889,-1.71820585709003,-0.51479653135618,0.126309836842694,-0.126442789646231,0.136225708011739,-0.633468723058424,-0.0215544843847318,-0.0988097950743659,-0.307482703370799,0.999106533406816,-0.776265533639643,0.780966281360952,-0.62469241799607,0.578822566864051,-0.640408472925331,-0.810210437990403,0.170499256179724,0.25202885736087,0.623859450396863,-0.471202587700769,2.68317658310896,-1.35309606518181,-0.548638709202886,0.448408904692785,0.754137424569512,0.29339596867696,-0.243355580160082,-1.35880107722808,0.754446401393543,-0.0908121526376802,-0.17659506659685,-0.979744406411261,0.585039755276324,-1.20539445789911,0.342730540544535,-1.14708736890429,1.28855608181556,-0.266308611891473,-0.121170423747046,0.137070102131596,-0.204526002849187,-1.29916973043687,0.600861596138829,0.620366909740467,0.278657505184552,0.167492204221975,-0.48604745944139,0.109372171322067,-0.221631592882275,-0.68199544637418,0.0313583708103075,-0.285264650863515,0.394582049127827,0.136449878142354,-0.58914557579314,0.583702282255015,0.457074441088012,0.185848192419215,-0.864516251737659,-1.77271353435025,0.515119150520383,-0.190018832837223,-0.737443992115013,1.03714033764161,0.313410770628401,0.337110863261194,-1.75320074378294,-0.424467884304999,-1.02646372232255,-0.516163722754242,1.39466671885383,0.09013087576981,-0.901615954220908,-0.0422119024087427,-0.409824841488478,0.642252367301293,0.319497919077477,-0.706341888881005,-0.81447909978335,-0.79434621604906,-0.426197086097632,1.01922745291502,-0.280980516203547,0.795957522867239,-0.161443185943379,0.120705985439544,0.120601865467362,0.380856369210029,-0.969709287210852,0.0203563236580399,-0.335400550936674,-0.447615146290045,0.145329720345585,-0.0430180023778004,-0.275929471860688,-0.984464514241052,0.0936809840773824,-0.247707097458164,0.416955705037907,0.283344830149495,-1.33444106667307,0.308333945758691,-2.72185312222835,-1.93466573889727,-1.32735663549015,-2.37059945059811,-1.80801215867357,2.2501232487881,1.55419726345897,1.11826355175812,0.351948943356815,-0.265421595374812,-0.0897244112241547,-2.07145048844325,-1.31449509665307,2.17738568653903,2.26298478762517,0.357987030484253,0.364810482193887,1.74050729036196,-1.38218756352589,-1.38555780172735,1.66339401354543,-0.410480977392724,-2.00547660274646,3.16699890688552,-0.501750653452579,-0.287188855297045,0.991486122257293,1.50492485905709,-0.662462068430895,1.2702262705049,3.12692935212663,-0.574675143795817,1.19726633504633,1.16202614780693,1.95922405409272,-1.53270721248432,-0.865104609842214,-2.54852159198286,1.12678437819631,2.38280793552097,1.60687003263877,0.579200358016368,2.06937744931751,0.604625910708604,0.753149847889189,0.719787682108791,0.686227163597458,0.652498045264831,0.618624412799665,0.58462597267458,0.550519004149565,0.516317073274611,-1.56381522671193,1.26834277321029,1.43226792970939,1.39031436050276,-1.30699464468423,1.32116655982617,1.27209136353211,1.23014255193802,1.18820420779718,1.1462752482696,1.10435473489394,1.06244185030067,1.02053587929144,0.978636193358608,0.936742237936608,0.894853521838799,0.852969608454831,-0.385884175181753,0.783577593799492,-1.15585017273094,0.734573493016404,0.69268841200477,0.650807370688892,0.608930080519071,0.567056279787444,-2.67995024218857,-3.28615008214787,-1.95429995537505,3.0016850593747,0.484758940230455,-0.90268980289448,1.66926055335833,-0.686196723569762,-0.655269928208246,-0.124137989024621,0.17774563450317,0.432054206519352,0.38676063692414,0.132330776389272,2.41438956859515,2.8921696850147,2.46384303909831,2.52578492424474,3.62333181402755,1.64541389333247,2.62662452479163,3.02526099185501,1.4060448737262,-0.888087464222472,-2.88977035831304,-0.688720555143152,0.0929734778841175,2.9951111673215,-0.871581688476025,1.12659865645629,0.787578807808201,3.66952343976659,2.99255446334225,3.85637474254372,1.95189049542104,4.03823050489431,3.45394255518458,3.20430921695579,3.80913643570604,1.85246698871594,3.11847976563045,2.87235363605874,3.65678707068496,2.10273540686125,3.33103902941017,3.62971365041526,3.51761050964655,5.2283417900513,1.16906441801605,1.24351749943488,3.18355894967976,3.10173536885404,1.46108031890323,3.25653448060821,2.04269768780688,1.29616504982889,0.718555009324824,3.32675827497024,1.1266403652792,0.936939858866071,-1.06302761603247,-1.43960797610281,2.6304759946371,2.59017338411194,1.08340676372199,0.874542948076265,2.10905264474381,1.14787783834912,0.574335960915453,-0.289935891439032,-0.298920455435975,1.16012029433585,-0.23930965408033,1.28596139472532,0.272698476205832,-0.511210088142662,-2.19176427800358,-0.208809536741974,-0.0958074336903356,1.40357376229763,-0.73174984602915,-0.0017219235416342,0.139687230416985,0.645904895509124,0.596364320528384,0.554027499068527,0.511761951503497,0.469554313978012,0.476859902488945,-0.666806394320072,0.0346554556282822,-0.0644929660672327,0.572791028207014,-0.603726269220942,2.11863332532912,0.860211793588662,0.0725498490088206,2.18142273556017,2.64398422133793,2.46519487038601,2.35202964025176,-1.23138550165184,0.93023918577297,1.50425021091709,2.83699299496563,0.0802807729992116,-0.440434552920779,1.71549441975915,-0.450550113544917,2.51343040062446,-2.02888535240153,-3.60265725092653,-0.231198386269899,-1.09619645414336,2.15221455770756,2.31416486951171,-0.531558760456647,0.595629103995644,0.254771833248553,0.22842274838649,0.105878827218844,2.59857755637223,0.606452965011177,1.54523326964355,0.79514422023384,-0.133819199948815,2.03059193793375,-1.10076358353881,2.68112678165858,1.43529381015392,1.16443546519237,1.76361087438004,0.831623853010765,-1.56869755794851,-1.57707047840184,1.33293006548133,1.22602219788409,1.1764455977519,1.19012126352217,-0.09472379272847,0.288846910516582,2.69080834203374,0.68705620239513,-1.55456174696529,0.0515761185277783,-0.728989760343786,-0.443999191918561,0.291250739005026,-0.136117269757132,2.30361261010114,2.78338340771804,0.329826631850516,1.19160626766329,1.23304434947994,0.407187527410462,0.397308037124058,0.933262164554872,1.58958220191211,-1.08122326117298,2.50202738858443,2.52496746940249,1.88404425730219,1.73797600497073,2.19728771323892,2.14350179519978,-1.10727585500251,-1.09471647432252,-0.880812102847679,-1.53933883157799,-0.896071786353489,-1.22925431837217,-0.894893657235367,0.26084733041578,2.43127449162965,-0.0095336065683719,0.223718288348024,1.73238175785046,-0.927124072666602,0.98258385892977,1.00766725992114,0.844059610296466,1.38560952778492,-1.14037564250718,0.779950535234061,0.876018768156628,0.897402406121681,3.18415235636348,2.33675362049059,2.35591891159776,2.79433340410919,0.913175997078955,2.22616065557659,-0.94351353548825,2.99317350708135,-1.15062735713932,-0.581355690647057,0.60039728842723,0.174840185624481,-2.24107485298106,-1.1962847755939,0.407805060819919,0.37371480785248,0.626059293435215,2.27422550991903,0.15601503277122,2.58609321670737,2.50082720798487,3.51795494036344,4.00892074227194,1.9823563171714,4.1300314273319,3.81304079276336,0.623796611777714,1.57369789640089,4.85125513655685,2.21175583268581,1.17118873250237,2.27108150670047,1.94169681013401,2.55087034384644,-0.567939572890149,1.51769533116994,-1.91256263382671,-2.10358290329291,0.169740705598221,2.16209864550609,1.56212955232854,0.148592393859995,2.59445276115475,1.66102935873752,2.43582348553379,1.42263161326029,-0.129188144339879,-1.37551765637273,-1.24328515722898,-1.65176618071699,-1.25446534452587,0.252273565031692,-0.248828402209821,1.01162645030639,-0.507536514254236,3.83298514230067,0.0653171492484702,-0.901040817847599,3.37971333584943,1.48227743472618,0.510570181831806,1.95874993153475,1.5604792800844,1.52573244095261,0.0038960221310578,-0.585321852047277,1.80401333906519,-1.6840216339214,3.52773827223549,0.795448867520342,0.752760921550722,1.71709526842855,0.520496923051347,0.936966154656013,0.886746966076448,1.27132193138436,0.0575510393537501,1.31912362938259,2.79789150183086,-0.917407954929339,-2.33518537609962,-3.68190355226504,-0.716811424575637,0.0982420128901166,-0.376135682527478,0.267914551538718,-0.183180903717309,1.08428646665042,1.79092414652793,-1.35984389291856,2.35115138243805,-1.79673863123125,2.36229077589933,0.170143879416802,0.524007524087668,-0.00202115788658,-2.3007976756963,-0.391047742407487,-0.559479810847182,-0.559132202274595,-1.87401526330162,2.06569197047395,0.994829500437418,0.952141057235768,-2.2213838533863,1.97974707098703,0.189130835579419,1.50157346167502,-0.167199797868911,0.152892032043683,-0.663370800920003,1.06015422605258,3.56973257751778,-0.17381402447058,0.477521452443793,-0.193132205838334,-1.90979861946686,0.596696430089622,0.71833237368083,1.02892683645358,0.506039978517755,1.81901276401306,1.93037970885184,0.32519494288717,1.98738627690236,-1.49715223294239,-1.17779250651196,-1.55653021213315,0.606570797159568,1.60929290421203,3.49006859270908,1.14847293881065,-1.56373996709776,-1.95006033191067,0.242162496030838,2.32892697361116,-0.736110693106424,1.70168502365985,-1.80233249695937,-1.46691055321726,-1.25758897993879,1.93548375407006,2.8686028948655,0.971906321717639,-1.80557671393198,-0.13769358207354,0.685510860299876,2.3534526931986,-1.61692658827377,1.49032876283779,0.982728632705372,-1.92330893857582,0.0284845308917937,1.35674828969143,2.99524475453849,0.235226841085862,-0.215409738450978,1.14778361222539,1.11403305037529,1.08013289303778,1.04610451099676,-1.48943421708841,-0.45793403989618,0.0135877061935761,-0.300930778531616,-1.08520791024384,0.38526260953691,0.0833797227600835,0.731998749113651,0.136722438174659,-0.819371096333784,1.09382579750391,0.832574035012694,0.797641375455208,-0.820354414754465,-1.59744021309102,-1.53016232603362,3.0573817418767,-2.09738547120766,0.502453451135321,-0.0513220971157383,-1.76235002438458,-1.16441437126035,0.707199945685905,0.421144082740547,1.24714263088632,-0.526280794204029,0.626240855695279,-1.01863859540215,0.78808629554402,-0.221267207742386,0.647708880496559,3.53100289778427,0.434072536887008,-0.30860899195249,2.54831265500006,1.30794073758635,0.527619755594392,0.87334427153726,0.423099369076423,0.42234244481934,0.391167040935071,0.737657217477667,0.266272320267649,-0.0354803664667244,0.593508846946918],\"type\":\"box\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(234,234,242)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"rgb(234,234,242)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(231,231,240)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(183,183,191)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"rgb(67,103,167)\"},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"colorscale\":{\"sequential\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"sequentialminus\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]]},\"colorway\":[\"rgb(76,114,176)\",\"rgb(221,132,82)\",\"rgb(85,168,104)\",\"rgb(196,78,82)\",\"rgb(129,114,179)\",\"rgb(147,120,96)\",\"rgb(218,139,195)\",\"rgb(140,140,140)\",\"rgb(204,185,116)\",\"rgb(100,181,205)\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"rgb(234,234,242)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"rgb(234,234,242)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"bgcolor\":\"rgb(234,234,242)\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"fillcolor\":\"rgb(67,103,167)\",\"line\":{\"width\":0},\"opacity\":0.5},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"bgcolor\":\"rgb(234,234,242)\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"}},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.2125],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.2625,0.475],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.525,0.7375],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.7875,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V2 vs Class\",\"x\":0.10625,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V4 vs Class\",\"x\":0.36875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V11 vs Class\",\"x\":0.6312500000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V19 vs Class\",\"x\":0.89375,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"width\":700,\"title\":{\"text\":\"Boxplots for Positive Correlations\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('87b6626b-c847-47a9-ae17-8b0f5378ec35');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Box-Plots for Negative Correlation\n",
        "rows=1\n",
        "cols=4\n",
        "features = ['V10','V12','V14','V17']\n",
        "fig = make_subplots(rows=rows,cols=cols,subplot_titles=['V10 vs Class','V12 vs Class','V14 vs Class','V17 vs Class'])\n",
        "for r in range(1,rows+1):\n",
        "    for c in range(1,cols+1):\n",
        "        fig.add_trace(go.Box(name=features[r+c-2],x=df_rs['Class'],y=df_rs[features[r+c-2]]),r,c)\n",
        "        fig.update_xaxes(mirror=True,linewidth=2,linecolor='black',row=r,col=c)\n",
        "        fig.update_yaxes(mirror=True,linewidth=2,linecolor='black',row=r,col=c)\n",
        "fig.update_layout(width=700,template='seaborn',title='Boxplots for Negative Correlations')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "oIYFc8k7r1BV",
        "outputId": "18587f35-fa1b-4cd7-8f01-f48deeaafdab"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"f4b953c6-2c89-41f6-94e0-915bfb9a433b\" class=\"plotly-graph-div\" style=\"height:525px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f4b953c6-2c89-41f6-94e0-915bfb9a433b\")) {                    Plotly.newPlot(                        \"f4b953c6-2c89-41f6-94e0-915bfb9a433b\",                        [{\"name\":\"V10\",\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y\":[-0.255273958239804,-0.0928539979788115,-0.506742534469509,-0.280493243493316,1.59662294123342,-0.240603346477903,-0.0586729488008763,0.894620785734476,-0.242868217662484,1.38350639766463,-0.487015959032126,-0.218095609483542,-0.405060915681314,0.372110964894735,0.337892033311262,0.0742368347001196,-0.289483617400492,0.543682474996253,-0.0115878328334377,-0.0439224931420598,-0.126066729720131,-0.0531030002317168,-1.73935225838159,-0.362475329471615,-0.168497563220977,0.237887540464979,-0.269431545765108,1.59444921535243,-2.07046599491831,-0.385237252608171,0.310625568047008,0.374570833548577,5.07581160144947,1.53369685873752,1.39490743123491,-0.322810277016426,-0.0094594123049049,1.37406955146918,-0.640789725789507,1.82540582501842,0.264940313085133,-0.139213220362173,1.45860454027996,0.418115895641417,1.59780161989336,0.0410578634128881,0.102687882469948,0.577055703419997,9.10140231365335,1.66017037015848,-0.0695705242129999,0.250563787350261,-0.653993402662188,0.0618001805457699,-0.156473116097762,0.149867322233335,-0.221027498349529,0.0184789618260173,0.16874388675372,-0.202082067757013,0.312721387383848,0.227320069365873,1.42685913255743,-0.535326684500969,-1.45249858044069,0.6553578576772,-0.930526103560306,-0.23185944985589,-0.400443850094627,-0.0646995868481641,-1.30729214497853,0.173970645474375,0.415208464708831,0.150089357294978,2.09675419791919,-0.85430901915284,0.141193554144417,-0.104207981515626,-1.0599978531915,-1.31549734554743,-0.145362051936295,0.941887775061909,0.340143329570071,0.581757335116438,0.0986473013393894,0.205475715810327,-0.924797983299299,-0.743767492129238,0.293542023370123,-0.0025820145852291,0.827958775499167,0.710464929456466,-1.45729556077223,-0.364770800251102,0.0991709612660929,-0.343898236292434,-0.615521351885592,1.28925975519844,-0.0299624705927027,-0.668458458963198,-0.112070202210729,0.0669552530839356,0.934328336874205,2.15100936370979,-0.910101992531359,-0.654887760423994,-0.0379593621913622,-0.904076081002724,0.117444473868926,0.180582209139978,-0.872577150527372,-0.221985823902143,-0.891155799226471,-0.191994713100395,-0.65360101789277,-0.0114306249467935,0.876755573354196,-0.855542926048439,-0.0950558909755218,-0.0541472926097911,0.254421084184031,0.248993543659246,-0.754311041927401,0.798967535338367,-0.142538697569217,-1.11653693059002,0.367741013247022,-0.141170775515064,-0.596475034173662,-0.121340989125647,0.682118318356352,5.88572751121879,1.05727890809409,0.310005861525613,-0.0522167753187611,-0.567592257530486,0.482235865217335,-0.211787100348309,-0.681341868529104,-0.265223275974536,1.85881186173652,-1.1969679253598,-0.514375015529248,0.655067197703941,0.664215156409321,0.652200737872322,-0.747502123905551,1.98699685834469,1.42897152295056,-0.788457496225903,1.3716631691187,-0.110586045068072,-0.653834307413683,-0.795182545447338,0.0456519333079763,0.0540714035398653,0.932414188420879,-2.0390220039165,1.57362373538046,-1.07204992070877,0.0556042796233514,-0.589886900421184,-2.01716975046735,-0.632707056551981,-0.1413656977412,2.9805133951192,0.311152117202867,1.63795553980724,0.203680854091231,-0.147487162813619,-0.675251768897319,0.927131740430615,-0.98691564240897,-2.67399025535519,0.297237905166168,-1.30586759057276,-0.0352043720365089,-0.536392783484399,-0.154839543963811,1.01968462660013,0.168897316932779,-1.87694744577874,-0.644305704201013,1.27830734147995,-0.0626578446907844,-0.0905919459983964,-0.540862578759865,-0.215988118377487,-1.46873261954432,0.0354872599302482,0.0757723552776566,0.982557679713825,-0.283324608832411,-0.5035142022015,-0.482063399440104,-0.161058112821394,-1.19982544096918,-0.53771574450754,0.0776678044851743,0.31279393701936,-0.168148219860413,0.0884810096929745,-0.562294297930397,0.997131264519238,5.50542383997804,1.28235043157865,0.868640039413523,-0.666919922578831,-0.490352568540929,-0.287141589024009,-0.436288495792005,-0.547437541142792,-0.369827698540688,0.133609816709407,-0.236416590590578,1.61305297655354,0.176385359502364,0.158531330463264,-0.119688935167779,-1.82440358156673,-0.518258784764837,-0.213183133437208,0.136689451429382,0.0077581380657732,1.38595005574929,0.801324651820405,-1.49786802934524,0.380999161540494,1.52757567208582,-0.0472496402062155,0.352714478020412,-0.563587808722992,-0.0859690431699648,3.03668012699189,0.343252963095731,1.56660139919438,-0.562504715505505,-0.181805502050558,-0.133870322249673,-0.792222108957813,-0.380986780526359,-1.35324639195409,-1.50597238453434,-0.060581075168387,-1.35527932899159,0.99086244029942,-0.869751927035036,1.22475436920873,-0.351149629278644,-0.0838023568308136,1.36664838455401,-0.540827689624106,0.414791018643661,-0.25142560305247,-0.552122628808136,5.27016227887576,0.72545246686889,-1.25648104790313,0.042834788478388,0.903058724018,-0.805109176160932,1.66340720225537,-0.0998412659078283,-1.14658862052044,-1.54066990242807,-1.2962643718892,1.06465008601382,-0.214376144972515,0.305645410937554,-0.0893714824232083,-0.109013867332819,-0.668564110712268,0.93261165387525,0.374074994715684,-0.0346987030163679,0.011260528658166,0.681013120463851,-0.0568972023574938,0.666875958028246,0.189237672030759,-0.946419928154515,-0.246114828727906,-0.290331355019222,0.449822021541495,-0.134690662403866,-0.101014914274412,3.31582344300788,-0.659179751865576,-0.0642842618444655,0.0157874869725683,-0.754306400721832,0.311568135370157,0.61395343271394,-0.998844050501635,-0.261999580401242,0.161219295666546,-1.23110141699323,0.355362481317308,0.164697018433082,1.39174908402523,-0.721615972702225,-1.35941234198336,0.856381699827864,0.736298917479387,-1.75552690031177,-0.318560760554698,0.721686688376445,-0.719273921657274,0.474441496086289,-0.497042943139737,-0.185049360062573,-0.166805153055343,0.0101784181364132,-0.547341039533318,2.38038623620284,-0.609459521359164,-2.63486561034371,1.48217389838381,1.45345528684656,0.498064092986705,0.735048392073043,-1.01935811668867,1.52608249039995,-0.271961912543022,-0.138990011935536,0.105914500943093,-0.756818525052203,-1.0222802511057,-0.672787259229256,-0.109330622123087,0.156839782516295,-0.0653943458803409,1.76181658439871,-0.79980713602313,0.526088345100987,-0.491847125415923,0.291183341288389,-0.0715561011148179,-0.133858505895965,-0.0321756360747781,-0.211659664532547,-1.18614504158933,0.940250475333811,0.473522005473131,1.16680509669726,-0.111536972908599,-0.696445461974875,0.535837128295189,0.0737286807971917,-0.0878840550451482,-1.29651028243989,-0.524967771613691,0.277317116654598,0.0363191821537957,-0.375168240160033,-0.320945045076564,-0.257872850162351,-0.177803660458635,-0.326137241145112,0.1717840250879,-0.213595657227243,0.658871569018348,-0.622529944349028,-0.141765142925941,1.3704584957483,-0.980371928917778,-1.07700246322299,-0.610550424979896,-0.353688701091747,-0.307581863592739,-0.224101870230961,0.106750489600496,-0.151237572416339,-0.594233681032627,-0.221473380746281,0.25786055999785,-0.628371721038911,-0.0554325281298101,-1.47653068660631,0.0440001964101087,-0.781925525065389,0.0190542092810508,0.978870104191748,3.62073929009464,-1.04156716798929,-0.771896815635902,-0.468516883299827,1.21196260556796,-1.07388844418687,-1.28956407967086,-1.85848998881825,0.0780498901586222,0.138605772072966,0.0207265915975273,-0.847810238211724,2.16833779332242,0.935760343750861,-0.134501389775699,-0.568591032594727,-0.71968687478541,1.89090040005192,-0.199739058944673,1.51491420363072,0.3998329485202,-0.425770621476461,1.36710785828188,-0.127829109573802,0.094206154933421,0.825779491285219,-0.386443786193979,0.637395943812408,-1.53860729857193,0.0541565158500923,6.44959910333463,-0.45111900019455,0.285130669296366,0.0305966424670315,-1.33960116283389,0.952649693503947,0.749213289005596,0.763437091314491,-0.644197522161548,0.0346696145749799,-0.931147978046506,-0.336603342610386,0.187717127875285,0.668310195718139,0.364818310689195,0.281060675896377,0.167758422980316,-0.788094542821684,-0.195047640517074,1.72309535594312,1.58613191452435,-1.19794800830463,-0.298910430993942,-1.11582335876278,-1.08472738006424,-0.588066834490181,-0.240163017673633,-0.390336730883327,0.476764960988977,-0.605479965574277,0.820711196261342,-1.00975588429371,0.791205228827329,-0.860548094135987,0.493968806673843,0.867942077303421,-0.807203600658299,4.84161826566741,-0.35285428833362,-0.453004462641366,-1.14467356767594,3.72950425722278,-0.621453792615932,0.626555262280831,1.33437888503267,0.684518653021879,-0.0820380660475477,0.204352272032034,-0.270069025570517,-0.478732535199045,-0.540878187655186,-1.09969786394776,1.18833533204376,0.762813538152001,-0.19496753473537,-0.160578102267125,-0.367891934059413,-0.442551139202479,-0.403368660499304,-0.0211102824318283,-2.77227214465915,-0.838586564582682,-1.52541162656194,-4.80163740602813,-2.44746925511151,-6.18789062970647,-6.04546779778801,-5.13445447110633,-4.95949291161496,-4.62498495406596,-5.00924850212751,-3.95581234352737,-6.23456133227108,-6.19988176274188,-3.94423849794435,-7.45484065078351,-6.81081309938215,-5.52627805985834,-5.3903302556601,-6.7167200227127,-6.99990663386522,-5.57602263642415,-7.19160424618226,-7.29780335001461,-1.9877731876087,-12.8409338181318,-5.15309460989926,-11.4204509744097,-13.1934150665232,-4.13784019622865,-4.59495176285009,-4.13889121357616,1.01511287978593,-11.853866972601,-11.5619497720699,-13.1366983691039,-11.7971810675777,-11.7121866242875,1.07741752106048,-0.592472935320844,-0.554223900525873,-0.164562674892883,-11.6271935556579,-11.7868116556041,-11.2014000859835,-13.6705451263516,-12.9389293107706,-14.166794659606,-13.3482776536659,-13.2616517082667,-13.175198078736,-13.0888909176936,-13.0027093010697,-12.9166361091709,-12.8306571996417,-12.7447607871859,-0.859862301810301,-9.66878891236125,-9.22282550730978,-9.15336803834587,-0.369908966047961,-9.04039624894471,-8.9286556608751,-8.85919405880884,-8.78972336330438,-8.72024451506225,-8.6507583293562,-8.58126551626339,-8.51176669710133,-8.44226241787632,-8.37275316035861,-8.303239351259,-8.233721369876,-3.46568908576121,-8.12096173759343,-3.65142656863483,-8.00915938639777,-7.93964241937325,-7.87012194292549,-7.80059820772759,-7.7310714411342,-1.88484243991678,-2.33593332652232,-4.59238980599474,-2.89525166830126,3.24508640095346,-2.73415555507211,-3.58281002008802,-2.13317644293659,0.644549730341658,-2.83487115980611,-3.71744992918956,-7.06074618169306,-0.121653217684609,-3.55198400939375,-6.0677981503786,-6.31970750896333,-6.54624181523522,-6.60046062150676,-7.52436833681058,-7.8335555711125,-7.50211219093686,-0.794993881662565,-1.96530880945923,-1.95980925751416,-2.04216786301424,-3.97652513857503,-3.05121035544102,-13.6913151328525,-5.29061006200618,-4.46628416302479,-11.2981564915382,-11.1412776902967,-11.435623996076,-12.981619145004,-11.6344144245911,-11.5198609264142,-11.589748311433,-12.2653238444006,-13.3866834395246,-13.2151722995049,-12.8881582878915,-12.8056831898117,-13.6081431627279,-12.8357376825339,-13.0740681657723,-12.6959474039839,-12.7806339362021,-14.6764702497464,-15.1241628144947,-14.2266980575287,-13.0094028057641,-14.1101844415457,-3.22678710680364,-14.5571590528859,-4.75830407509117,-4.15583783449678,-6.40337055173194,-16.6496281595399,-18.2711681738888,-5.69992228265959,-4.07758540918968,-4.56525209408734,-7.14219911358407,-7.78135276287243,-2.96199570179906,-4.98092843827312,-1.25028553742691,-5.72681709632961,-1.48124586053984,-2.97526724837752,-0.792937990748917,-2.75579692797163,-3.84391103993778,-3.36401057980002,-0.55054534794377,-0.585778431385528,-0.433393925731893,-3.50579032571994,-3.94238290411726,0.225933803313285,-0.552902906422504,-2.49561924548174,-2.89261176082088,-6.24624318477127,-6.13490688724113,-6.06578236274727,-5.99659592015915,-5.92735916911943,-0.150129182778684,-0.283731283967387,-3.09650359868717,-0.0450882478448673,-3.09509360697848,-2.9966693020716,-2.70501138232752,-5.45960189444545,1.01029102209398,-7.14513662527302,-8.12216107491307,-8.33286306292127,-8.40315026242229,-0.0492328559624844,-3.24510859732028,-7.74848004950582,-7.86450647898838,-5.97492543825504,-3.55583492739064,-4.88114292689057,-5.71150474047788,-9.33212806886128,-6.77833138248069,-2.8084555425423,-3.07669858515182,-0.867899742347565,-3.39355348115172,-4.17062288702767,-3.28820356526528,-4.35068531246963,-4.00174208524931,-3.23678401592309,-3.42605225253339,-3.25263359468289,-3.55038539904852,-2.30110989675506,0.169572797878818,-4.15369240632128,-3.83477508791878,-2.12697274994354,-4.83482799462627,-3.9905513318108,-0.0913533730643921,-5.11725920989043,-3.16213595485783,-0.157696445821874,-0.194120466505581,-3.62477471396623,-0.371671945168217,-4.32053577559936,0.264544748886681,-2.85611682977408,-2.65971794652165,-3.95100289197434,-1.7690597207318,0.517567879914365,-5.05250236713858,0.54318725600578,-1.87964382107016,-4.7117686842189,-2.89499040084744,-4.05629261571005,-5.03202838566819,0.324238886093679,-4.99341703829647,-4.68423332514029,0.334532824069685,-3.9433368210052,-3.53865023182429,-2.9989262562074,-1.03963769713185,0.166830707878014,-5.51550707258062,-6.44720227383046,-6.28780335064533,-6.56125741097377,-6.8254901042394,-2.15530254380865,-2.10066651278309,-1.92527812380296,-2.544410418956,-1.02533539256113,-2.15251889070952,-4.62691916410905,-2.23120932812687,-6.26070551479114,-3.8337413849476,0.269561809170344,-1.88617599041763,-2.9328952580311,-5.63894131284807,-8.0991193981365,-8.33770697381781,-8.74597261185534,-0.71347376073502,-3.99521073403213,-8.40966487562735,-8.53775768653457,-6.2133552491157,-6.35388725151755,-5.99567612703198,-5.822449155685,-2.06990438955593,-0.133950251206468,1.987861862693,-3.93629417027159,0.541699242973355,0.369936028027435,-4.15635447965382,-4.72309174576035,-3.37617706712688,-2.8290982053899,-3.71748137540216,-4.09564897273592,-5.56794705115052,-13.540168238225,-12.0111608836062,-11.2350479111446,-11.1821254546586,-12.9654812039222,-13.3207888671784,-11.0923923688428,-15.2399619587112,-14.9246547735487,-13.2025771482197,-15.5637913387301,-12.4389449056023,-14.5331616869738,-12.618162687238,-16.7460441053944,-15.3460988468775,-15.1237521803455,-22.1870885620007,-17.1415136412892,0.912806096143303,-0.357616193093852,-16.3035376590131,-16.2556117491401,-2.85032390160027,-5.66586179854092,-6.62569249371823,-16.6011969664137,-15.2318333653018,-18.9132433348732,-20.9491915543611,-0.870997150804889,-19.836148851696,1.78592177154007,-23.2282548357516,-4.4318096317282,-24.4031849699728,-4.36310219273296,-6.68368922880726,-8.99381088354112,-6.80713525144464,-24.5882624372475,-7.17534972178322,-7.57563437993936,-5.11072764247853,-7.33437708370839,-6.86850850672582,-6.86416435989436,-4.51390660472333,-4.54693575081085,-4.45800770078481,1.07295520625891,-5.20833459337633,-5.62467713431414,1.7837390603636,-3.51413330486723,-4.54261203828437,0.453505060416619,0.566679814004086,-4.82077941422469,-1.53160798206082,-2.77674714436829,-4.89115620289902,-3.15812700566592,0.0422275201898101,-2.27673307339047,-3.21618771830464,-4.5652600954372,-1.4706452575308,-2.29773425918487,-5.48742458295368,-0.0844995591396119,1.71353755281029,-2.9716952359177,-3.90674573293228,-3.8517216648754,-3.22455914814995,-5.56914249554635,-5.83645272742826,-1.4294901237515,0.0856615347524881,-2.24811517395215,-2.31474716368481,-3.73965947930309,-3.89824038104731,-2.64940583024547,-2.27152578398956,-3.07403431268054,-4.07025686324581,-3.52012767367189,-0.989431189994817,-3.8410981507899,-5.17993471366321,-4.50131480977758,-6.56465926230671,4.03143505114991,-4.25071651144568,-5.41603688884657,0.217630453611954,-6.42823083022309,-1.34755671450971,-5.11297108805175,-5.16533081830893,-0.159325098707444,-0.0451253297662453,-0.423783865294484,-4.93742665954554,-3.07555830950402,-3.75405392305562,0.955004466801798,-2.73279196653765,-5.6536376856402,-4.61450773315675,-4.40092985049667,-6.54098852025393,-7.04922935969585,-4.06309810827338,-0.628463195272087,-4.85148719411703,-4.91934829935247,-0.887241636246378,-1.44537495699985,-6.28542447506796,-3.20243612238872,-3.41920738405664,-1.87333085278999,-4.81640080035747,-5.17565967956169,-3.89016924226376,-2.63744174460075,-3.23543895742654,-3.26300672553831,0.398155064675901,-4.48548270396242,-2.79633153858609,-0.373927299894818,-3.50892466189359,-4.75993137385013,-3.99178463209724,-4.86874726825181,-3.47341070390428,-2.49756054724841,-2.4112720149303,-2.32511344137919,-2.23906626105695,1.28016674259048,-1.47497416110315,-2.12045759469323,-3.35647371355361,-4.23098383571181,-3.44381902213252,-4.44148408070017,-1.13445381068391,-4.02912871953916,-4.70757080611204,-5.57641879575659,-5.25809597551632,-5.17281182346005,-3.92650993997042,0.228849430580481,0.259411077154011,-5.9548382969224,-6.64615382952148,-5.5334430286147,-1.61361833850235,1.08151398923906,-3.06472953093127,-3.96322447209244,-3.27256917385192,-2.22307032799021,-1.67234597814111,-2.16206139007752,-5.33475387061743,-6.12071508667922,-1.00080505203989,-5.94563397292191,-4.5335154033258,-7.50955747436829,-5.52913123107677,-0.39438126178315,2.68866993252224,-2.5166280017922,1.33441406239882,0.24931080342673,-4.39084192218279,-5.58779378195338,-3.23215317539514,-3.46389087904573,-5.24598383776964,-0.888721675865145],\"type\":\"box\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"V12\",\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y\":[0.951402617133848,0.944906247802881,-0.407786859473999,-1.46147612801106,0.604059370374081,0.359418687549613,0.239701461125508,-0.693387919638551,-0.350940106010462,-0.934563796727493,-0.732487718666899,0.966281623970264,0.199068280186305,-0.865596762107636,0.930889522486273,1.38331515038534,2.26365425096294,-0.252303154139843,-0.0798534641229137,0.303309474899603,0.149363226551896,0.374960476890234,0.66081706317574,0.213380571551124,0.845141755666506,1.06772905930615,1.27193369115764,-0.271940399905881,-0.149250779725897,-0.217437299182141,-0.937922483348395,0.0175582555702993,-2.53659766969103,0.268185409475735,-1.81687675000423,0.480934293573833,-0.153499471849359,0.0405616296938517,0.196057285610864,0.173640752608991,0.434321612226044,0.810759934174101,-0.481863044765586,0.906638019823129,-1.33210948672289,1.11722800144441,1.17916079384991,0.75745898435153,-0.78265661589145,-0.267078776514627,0.924375922168442,-0.289561526579576,0.773415930289313,-0.557500024996554,-0.08131385247047,1.17707691037169,-0.0278077643369752,0.468917578601364,0.806893912759849,0.948673878342846,-0.228653125520959,0.927721132273441,0.0942292907655487,-3.12912436187899,0.774149213595931,1.00375111132357,0.822067333135957,1.30776813237096,0.470627569731986,0.78422808441202,0.175792023820598,0.624054443708653,-0.391149369532353,1.25673441667707,-0.280917985339562,-0.0718637850133924,0.731298001652437,1.20524956480138,1.49978322172691,-0.302379134921305,-0.810891160178278,-2.36888762102475,-2.61760658966782,-0.0046223860871845,1.27855294804429,0.349770673085462,0.52447501343559,-1.71929896430037,0.603397281509684,0.0739864366704824,0.958421843046132,0.125317265624846,-0.515002280898818,0.928662673779337,-0.761324133355199,0.562383135254024,-0.182752704550275,-0.725042850277102,0.723122150072464,0.673982105311908,-0.0603618259283892,0.753835149394165,-0.780790669267756,-0.455807017646987,-2.21153575114728,-0.491841966346324,-0.37761398481616,0.417394820666489,-0.538444473447014,0.92833898587488,-0.0076257902637665,0.479436591611204,-0.0348316429107153,-0.528133372895011,-0.107780587174076,0.357252230846547,0.360871189800661,0.510274668929562,1.84806823949831,1.07644402523139,1.16283613751011,0.984496792677102,0.0951492585229347,-0.20825665205814,0.124844448405343,-1.73587096169135,0.609317697459755,0.23563086787942,-0.511590839769263,0.688251118816129,-0.144893280313596,-0.102996911095008,0.302601005404919,-0.499143159325653,0.387542966504827,-0.984256984453272,0.133540653615736,0.80441409008027,-0.529348260511183,0.275385340515342,-1.04651902101773,1.20769639883181,-2.37128620602688,-0.25345883089597,-0.139055883778005,0.205912667927106,1.15120056569333,0.998611185681855,-0.349357960375658,0.44353547492249,-0.684185960669344,1.02236830066145,0.356855166623377,0.745841255998124,0.855938872231888,0.796262777593676,0.773066240002718,1.39480440450576,-0.703869679617599,-0.22262994318499,0.304984471326312,0.441788790600335,-0.471578809355447,-0.193429667382002,0.628965723084475,-0.757883682985347,0.211637207742545,-2.23998814119974,0.0448555029788471,0.512285139896946,1.16155967748878,0.447025928946078,-0.11512738907098,0.799583082934496,-0.797054513111082,-0.285223122432906,0.416375268699833,0.0713953414564843,-0.242074532627282,-1.02222412739787,0.451808065362238,0.993586815475873,-3.88480996621945,-0.325803067877678,-0.374364518750207,0.418250277174755,-0.768828889975534,0.0192438067240008,-1.42606061085345,-0.531451226424981,0.716746432525691,0.185994648403553,0.702240304373703,0.833432472048312,0.203946447257409,-0.190694425712841,0.894607996543752,-0.0720329554855831,0.735213084082945,1.39196129810194,-0.280411737722037,-0.0597211596338832,-2.1526591495173,-1.33490728356919,-0.679183429199656,-1.06050705370883,-0.948886247591603,-0.382233907230471,0.940378255639359,-0.226609933053563,0.288826013662636,0.106721397351392,0.912888623700815,-2.91603520135782,0.0833654297884399,-0.284287295753507,-0.736373252643164,1.10901306949624,-0.274648023510576,0.143827637863585,-2.52549252463935,0.0411714239281436,-0.773987552796704,1.13993732527813,-0.0288869464731245,-0.40723447181716,-0.209692951726237,-0.772802827711479,-0.11266664517689,0.257277910441213,-0.728203313728115,-0.0290276709867411,0.302034505381855,0.0574009156368273,-0.404866131651234,-1.19867812049595,0.482597991481359,-3.35442992168018,0.715993822530708,-0.327676906523977,0.327782425120188,0.913412999168539,-0.0107723888274523,0.130737749396936,0.185294887278768,1.52418930172955,0.831723974602797,-0.37913999380006,0.419383985676404,1.07944154827496,-0.156002192081384,0.446954606614331,0.368257475539599,-0.324882343016372,-0.0648038322483319,1.39315064230762,0.969077362279434,0.318362195813531,0.108961170870211,-1.4301593560658,0.120406389135556,-0.256896314704487,-2.21800677539069,-2.5031062182442,-0.0183606825226656,0.380935166954912,-0.367635592503177,-0.354235458908589,1.08099966698344,-1.89545910980571,0.93231583029978,0.11584652368533,-0.0865874916669111,0.588627012212333,1.00976900073432,-1.27036556526468,-0.216228967324865,0.219333964564751,0.561526741302754,0.0439052166842476,-1.01794842949814,1.35644712277983,1.05000814893846,0.242340472023799,0.161023990161283,0.603823536668096,1.51888861504471,-1.49481709884389,1.06295402625841,1.0160105718354,-0.313201269242962,-0.218812461559158,-0.179788941405194,-0.289001864501485,-0.465771284287297,0.780661640250653,-0.382884516594185,-0.49133364610227,-0.284699758443913,0.169363544114987,-0.255110680473042,0.58726099119604,0.178968796649997,0.143669037704827,-0.3464924644014,0.287540715510163,-0.795883113427055,0.23028513618138,0.789075254243545,-0.416089738125677,0.252769208213916,0.603574288387655,-0.334629435484178,0.699769596818169,-0.776913090585897,-1.99812651576229,-3.14425769026634,-0.425714440314346,-0.981869041242337,-0.602543029767358,-0.106833808443645,-1.1372556351922,-0.936777122304345,-0.211744196720975,-1.38135019994234,0.354463705823705,1.07543347427854,-0.202052098817225,0.485290934373975,0.0790984066445104,-0.20017036635166,-0.54658603709957,0.276881708100253,0.256812203118567,0.0556291038778816,-2.36490461309811,0.685524160521458,0.675954209670542,-0.445554873900186,0.949598320402089,-0.650606020179129,0.89936312649968,0.0709970621766113,-0.132570747563671,-0.930958347129252,-1.65684825060274,0.136023173265899,-0.0809765866066423,0.369783518242588,-0.301028457196277,0.7866301959028,-0.103713392374025,0.919008174551261,0.674944390581409,0.0268035291702719,-0.0966445869337422,0.478108815497295,1.459907775677,0.883517173446608,0.599123956003035,0.379950005394678,1.09443685207168,0.853462400668676,0.325613572070239,-0.819796117537399,-0.511391216001949,-2.59638593919576,-0.447227107227533,-0.935726668189867,-0.268231288257976,0.352988322432224,1.07419458530612,-0.135010343260164,0.436116350036497,0.91232374187578,-0.147530587486925,0.64344160077557,-0.342469384871998,-1.998695872791,0.979468251405491,0.35190172367551,-0.306372103224254,0.052095545213851,0.611544799290733,0.63114308525865,0.186439870389716,-2.59630355098586,-1.95379361984709,1.63649938736232,0.61079936343728,0.0937454586232479,0.338164102539319,1.14873644822638,0.633701776185641,0.151545826628143,-0.0528969432710722,0.490151802628047,0.822297775201186,1.08740322368657,-0.235961655520438,-0.282253754340014,-0.0203932336264811,-1.17605931276587,-2.58313062437783,0.363781057196576,-0.449661212435271,0.794135229595446,0.274717558436815,-1.08006985288735,1.00663318675641,-1.64989358139146,-0.368601808220348,1.27061505293108,-0.080964577850804,1.22706380035287,0.506858590430036,0.485311707049726,-0.727191559673887,-0.6427432208441,-0.363327238201037,-0.932215455468393,0.322672452371464,0.715152485602238,1.76097090061537,0.581510982067654,1.39157919703369,-0.308419760198259,0.239517336424933,0.19021870856509,-0.579922023901312,0.560001059487459,0.485353546722768,-0.277531608365269,0.456569339408196,0.71493192706372,0.987809618420702,-0.359036263673036,-1.79954289725782,0.172520577784215,1.39956435427797,-0.192558673615743,-2.45235249643624,-2.04674033978336,0.022184931087617,0.847493543483814,-0.107037579388403,-0.202295452639066,0.228780228292728,0.228873915423319,-0.131392580532948,-3.10022181041655,0.74857299952447,0.616272264887393,0.310490405887333,-0.221256899071582,-1.680698031207,-0.719242356625352,-0.3154607098525,-0.693700156362429,1.31536418007163,0.382286531439021,-0.249655688189071,-0.0860103620302687,0.298457126443621,0.54916758947964,-3.31484098914117,0.704244417482061,-0.996191089221215,-0.513836618825209,-1.84927886096249,-0.0596106242342892,0.351788268370153,0.613835663145415,-2.89990738849473,-0.503140859566824,-6.56012429505962,-10.9128193194019,-4.6096283906446,-9.85448482287037,-8.94817857893317,-8.87374836164535,-7.52011739288703,-7.14824263637845,-8.16718805173089,-7.18645159050588,-7.33371406736393,-8.24326243368313,-7.30974798382371,-10.4752286504099,-10.2852825163315,-8.52546492534563,-8.48534657377678,-8.60164826276464,-8.67081800476226,-10.833164469314,-9.92869994299538,-10.001046368327,-6.9980424321007,-17.7691434633638,-7.83953899762349,-15.969207520809,-17.6316063138707,-7.62916958856017,-11.3490285500915,-11.1240186070579,-7.00432728360605,-17.2286622386187,-15.4790524832016,-17.1313009454468,-16.7283393320915,-16.5581971409376,-6.54261034532574,-2.54755681422931,-2.77675657494788,-3.0217601822032,-16.3880541668327,-15.0941631493865,-13.1049334662012,-15.0226996343749,-13.5561301301468,-14.9854337328686,-14.5639797552132,-14.3947668016721,-14.2254557039818,-14.0560611837648,-13.8865951585248,-13.7170673789468,-13.5474858999444,-13.3778574339457,-3.76387384832398,-11.6356300484755,-8.95219071159749,-8.77857203246194,-0.491243315415958,-8.46396612952571,-8.26164983722413,-8.08803351213651,-7.91442236630349,-7.7408158639401,-7.56721354069937,-7.39361499215009,-7.22001986441493,-7.0464278465108,-6.87283866404082,-6.6992520739678,-6.52566786025865,-3.82670531942496,-6.21094112120869,-3.83478156926117,-6.00866000668561,-5.83507521523889,-5.66149242261771,-5.4879114860488,-5.31433227604015,-1.46047112296734,-2.59194964968951,-5.65785754091816,-2.54917730779636,-0.677096334427304,-3.65680265130054,-3.50054226479879,-2.24286436771513,1.23777331256672,-4.39273243849001,-7.22000368560677,-8.62905440849263,-1.07381224038496,-6.98477147722078,-8.27784094846266,-8.07709364590223,-8.04228514248667,-7.88897751950988,-7.09982534281257,-7.7814479532704,-7.64298306727846,-2.71918495125522,-0.490697387341298,0.312424168769405,-2.42593281501277,-5.03186814827248,-4.74769250131792,-14.1681208819376,-7.49227616878309,-7.34671678644283,-14.2750918465127,-14.4686550955305,-14.2960914258331,-14.1541653609607,-13.6976856184689,-13.3802218737527,-13.542095596465,-13.7429528415799,-13.351815018081,-13.2796997105282,-13.2116950297251,-13.0642398936784,-12.6110036871047,-12.15623949431,-12.375374654316,-11.9608660326622,-11.898065148453,-10.7495919949504,-11.6767222367813,-11.7939788348294,-11.0584014244364,-10.8340064814734,-2.45433920979968,-10.3800731219167,-6.5331067689397,-2.87240010922107,-6.85557098142662,-9.44531478308794,-9.58356643737056,-6.63622904939297,-5.84955800710779,-5.4509164388957,-9.40706094796316,-9.65660635996176,-2.37959961108923,-6.40982235504524,-4.58309584545642,-6.48911156043177,0.9221844195147,-3.68263987014104,-0.567380064895921,-3.52152936013651,-3.95604520140947,-3.78445965821089,-0.105359122514952,0.654566719272309,-0.46034845602669,-3.34217599575955,-3.39426561777896,-0.787372737955552,-0.818803693746743,-3.53043627008024,-2.38526266137636,-6.51238933713471,-6.30984277729399,-6.13603446645473,-5.9622614216576,-5.7885170305197,-0.795988136674965,-0.158825775049249,-2.45083242908802,0.687487636238951,-3.1005456578695,-4.59661151187479,-4.38191956749248,-2.33027064686235,0.0443966388940644,-9.15082268467043,-9.22585530778592,-8.70787929219866,-8.6407464115182,-0.814309846145704,-2.82004218823068,-8.67967880327782,-8.24589788162945,-5.09503162409832,-5.47980167679906,-4.68638689759229,-4.5403416445233,-7.74312234505579,-6.94917182528041,-2.4148223375383,-3.96968929955842,-0.657947690982211,-3.57039373078107,-4.22622469486547,-6.84897793447677,-2.71873063246571,-2.21069105518154,-3.91467935228848,-4.28352931016896,-5.31444220386187,-6.04023537903875,-3.8309980112302,-2.31695189213093,-5.65326970240352,-4.97692104108215,-0.468571538051367,-7.75128547808951,-6.11638322304304,-0.61381552858098,-8.06609609331146,-4.63512694781183,-0.935863286411531,-0.276308752749667,-5.58369692598496,1.37594135044076,-3.70174966668488,-0.324703760782435,-3.58137450130299,-3.46236188507757,-3.4119829114195,-0.0054232908009888,-0.238382663867126,-4.61075647740608,0.285261608751792,-0.487849732811135,-5.17173460782892,-2.82494562476694,-2.74355135914945,-2.22739840581069,-0.868686295319925,-5.29376010254684,-5.00744082816051,0.196886900487791,-2.28866350030302,-3.99337305447702,-3.67771661422902,-0.664683930228673,-0.85805991589575,-7.12825076846601,-7.49878345527601,-7.26754953396678,-6.86166051434144,-6.94389061823948,0.0444153214634158,-0.94491647902938,-0.309218873424363,-0.835695915134352,-0.417898026653376,0.092848590126307,-2.99881490434833,-0.535839387011391,-6.16353737959229,-3.61123136485112,0.933215784460268,-4.00241403073237,-3.24614143685335,-6.65573446968769,-9.44594338249901,-9.42484446049178,-8.16412507731485,0.0236821347785728,-2.32517912777326,-8.57676143258937,-8.68160893168352,-6.6528440527591,-6.4532473302497,-6.11966735264192,-5.69192578583088,0.999716276092526,-0.284367998317494,-0.863430853145281,-6.60065448140166,0.257697090947377,-2.26293253493218,-5.12231410931103,-8.75277008726404,-3.9842567303491,-3.9181998797616,-5.03402974701745,-6.06726194524698,-5.94840312668093,-18.0475965708216,-18.6837146333443,-18.5536970096458,-18.4311310279993,-17.1829184301947,-17.003289445516,-17.1504052507291,-16.0603057628826,-16.4655039422141,-15.5316111795156,-15.5923232225286,-16.218610393127,-15.8357188077344,-15.7176066468772,-15.5648376012203,-14.9797547574476,-14.1750301634055,-10.5923050053728,-13.5801472568557,-2.04386838674929,-2.81888227036892,-13.6352161247268,-13.8124040899594,-6.48774641306604,-6.14705358343033,-4.38107755793604,-13.9322487527403,-12.8935202086054,-12.6863075224956,-11.9249546896802,-7.80222778971281,-10.8951335063028,-1.47169658834377,-10.5224940129243,-5.39522117678937,-9.60826735632918,-5.40376835689762,-11.1024933822497,-10.6498396512844,-10.3997491177692,-9.12834128617468,-10.178995535122,-9.95919399367656,-9.29980722738699,-10.6551809118898,-10.2629840447185,-10.1375291936462,-6.11044323287235,-8.50778570734412,-8.76211333956078,-2.777649223895,-7.76119403219115,-7.221590004268,-2.85427542751023,-4.05335784837839,-4.92519869522976,-5.14273660303602,-4.93828359985114,-4.61900987976999,-0.220718797789479,-4.48267863575862,-6.40830067684822,-3.29947236985172,-0.929370065771482,-1.96119460001748,-3.27270458494442,-3.17193661178549,-5.83973605661705,-1.94444112769897,-3.05540513135176,-0.540534807018906,-0.708657345883242,-4.47804406487578,-3.61312502993317,-4.85831164395338,-3.46854525803227,-5.89693656310926,-5.96148766039896,0.17909486429195,-0.0543808429292316,-0.690550364277623,-0.407550442912615,-2.84444933585435,-4.15249885001879,-2.58749931359948,-3.68294346446482,-3.47486296690245,-4.5477421854241,-3.01077173816878,0.903819349613327,-3.90687694585664,-5.25999613299847,-5.41888894354848,-5.69407428254804,-0.578913742704862,-4.56367473788251,-5.01960988798824,-0.0757071123077077,-5.29231414644205,-1.4629451764881,-4.10212741074135,-4.12572224190365,0.281744446861465,-0.629085830718882,-3.24482729860534,-4.60317614883077,-3.19191476820242,-3.48937464729063,-0.240056328492088,-3.541687479312,-5.8837243606062,-3.15815569757752,-5.73781516761686,-4.93815929027047,-4.48127959922503,-6.15136219091534,-0.741087888346352,-6.88763735718558,-5.29781140208753,-0.338775118165825,-3.25970246526323,-7.95962843222551,-3.98641621648026,-3.97843975507806,-6.17262991831307,-6.28512495176061,-6.01115469172088,-4.16211519175474,-0.553179939159781,-7.56286042898412,-2.77234880583364,-0.0225614827826197,-2.64421945060054,-2.56260240774572,-1.46320692427849,-1.95992749618623,-4.165202322571,-6.15018666957144,-5.96916163430263,-9.32115263136084,-9.0019148555682,-8.83250972518326,-8.66303057554101,-8.49348798082106,0.43554195900858,0.483019027615191,-3.62025176254298,-3.00268415590657,-4.50380121641622,-1.6898355101423,-3.80546898374331,0.979674835308759,-3.308721722205,-5.20837397192841,-6.11770391144604,-5.81040712597652,-5.64041745782421,-5.43735368941346,0.144622386270367,-0.280523276849375,-5.51714762692598,-6.51864882248249,-6.33182479621436,0.501435242117417,-0.97376404264957,-3.73515295429888,-4.6550713248721,-2.13473197122041,-3.5018037792943,-3.10347667138871,-3.12745594474482,-7.10148829773798,-7.83625279832226,-0.323794189703165,-7.60726146360792,-5.26720466981905,-5.99363242425938,-4.83615901427864,0.974058515963307,-0.0504679838548109,-2.51310432869389,-0.722023081820061,-0.329759339656804,-3.91052150018815,-5.4174240819973,-3.09691489835154,-2.77502154036273,-5.03046479695456,0.728903319843614],\"type\":\"box\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"V14\",\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y\":[0.190258281346303,0.123923488835983,-0.460737143017989,2.36890687042344,-0.172642258486432,0.433124327426684,0.211119896128419,1.06149586081482,0.436972160697332,0.200789814803846,-0.283359750443991,-0.382151799829465,0.812468034127352,-0.334766110364959,-2.44119003634122,-0.0827344809422958,-0.723222245619165,-1.78504464689751,0.499500720494577,0.239454615593965,0.537856203882174,0.875075321320562,-1.7929325412581,-0.440966204709946,-0.0553443117244555,0.406726888758386,-0.327123395909422,-0.103600213391545,1.384748398146,-0.27735841475366,-0.787505959386649,-1.55900562419465,0.759443535214882,-0.0385084910605329,-0.0347743796478232,0.945767539085811,0.599784408415192,-0.425111479479355,1.46448181720003,-0.593821520655953,-0.795056668792036,0.0235009552306959,-0.807675767260454,0.794082292698536,-0.267524852299921,0.696970894204497,-0.53457738041539,-0.326938982211591,-0.535728171176597,-0.387464721118122,0.256337673932392,-1.03104930118208,-1.14218528168756,-0.0629291172401967,-0.153561992489444,0.317333971726105,0.0836848450694229,0.636036469414099,0.167393963335706,-0.0627438593270136,0.346241822868056,0.329107137326535,-0.321429686954772,1.76178209935619,-3.33372064335903,0.540335960822781,0.89380006941862,-0.790459939506849,-0.362145213383802,-0.200257375435067,-1.07785540292756,-0.0494788346451489,0.668009450986021,0.314665008567755,0.0747252173651707,-1.62955562558838,0.446132812117889,0.189442989628079,0.36060325931984,-0.634929503245775,0.0230733416743188,1.45740863379934,0.995844571794255,-0.112227572424338,0.476144758376116,-0.597403234884687,0.329783324166947,0.482651970255454,0.686799710634406,0.42731391747386,0.12954612594058,-0.143802008531378,0.392983155897311,0.431073330995614,-0.0272664799261037,-1.24268722406585,-0.0646214801200214,-1.38488198755549,-0.586873314365296,-0.835302362804275,-0.0484114059688906,0.653987113784743,-0.573983075134569,0.243139200171079,0.76762130782109,-0.550804377271648,0.0830299672766742,-0.86467663176151,-0.354968031641238,-1.42360531349192,0.247834244585368,0.0949224602766427,-1.25079752169114,0.78555879244089,-0.999149688795371,0.072596239356718,-0.721654670488682,0.354298991068493,1.16307088071951,-0.0829126092993173,-0.341093217936146,0.420819625722602,0.703912192866024,-0.663036451844091,0.0912057237494023,0.603771911993739,-1.76157748813093,0.441425598115859,0.16199330197848,0.322793785410457,-0.330775821818228,-2.86215000371337,0.793406026252717,1.0810242261702,0.382524942535961,0.550443476717004,-0.0104088419648569,-0.590504567793751,-1.15584632739084,-0.992389599706482,0.358083630245672,0.245658059524377,2.15295072536003,-0.963527021235016,-0.646681984813935,0.0220018761785255,1.08470429867618,-0.793999481479274,-0.155305890974771,0.0888721413375357,-0.583905089202708,0.376343839248842,-0.702815714491347,0.603491085050949,0.348671491212681,0.143029188579682,-0.340976186859302,-1.60208945483423,-0.367280007666704,-0.369617584933805,0.292143419706576,0.92502601571693,-1.94426749669334,0.900507136160186,0.34323102639397,-0.997308084948198,-0.966396364783176,0.0569568876042456,0.856992656804398,0.97278874594094,-0.0079349089518171,-0.00128807688434,-0.754059778267245,-0.193016224947055,-0.115112926884902,-0.705443044147846,-0.17675162419697,-0.333819610103239,0.291042674372723,0.0759819727891444,0.299827367840032,-0.292909027215452,1.36890748793247,-0.716159345183306,0.720421451999445,0.0532705146312531,1.28370506942222,-0.599506826092022,1.22122849938873,0.495650916703817,-1.66667929687443,0.012001781168647,-0.27366912737358,0.651146241827983,-0.445367473277862,0.821312526648024,-0.0980847274250604,0.184456407682875,0.478582643212905,0.13525382526506,0.084085344971895,-1.21666853287196,2.01903958375222,-0.203534700773322,-1.69671404748656,-0.504275595487604,-0.587790937975527,-0.0872911552183537,-0.590460825475282,0.220594519872788,-1.09653053813741,-1.16174539216845,0.357078664091409,1.62182386086336,-1.02368729104378,-0.0355014473402522,0.801196183838131,0.442521509286443,0.374570344839098,1.6105533490761,2.42801187132929,0.167106160395181,0.437125821620888,0.381516374403912,-0.625566629359006,-0.171628052646928,-1.18788884763426,-0.323418572633664,-0.243865442144882,0.328816567149395,-2.26243383346169,-1.17495385753279,-0.382307682499448,-1.27085201320824,0.785635962341161,-0.306359964166952,-0.146550235108406,1.36154651868434,0.0171842904608707,-0.0818416614119682,-0.224987048489463,-0.440795894743043,-1.55016250414868,0.763116031815235,-0.0572410061370544,1.00342086875162,0.0818736741248907,-0.941050204934537,-0.784175168071233,0.013542345319024,-0.0337774522526473,-0.514532560599679,-0.971520641658866,-0.079207040441824,-0.374418817643553,0.612993173700984,0.164587223211771,1.01330373324028,0.34493804526352,-0.272535593326265,0.540862624819667,-0.45586669227251,1.48290650144641,0.149755322886475,0.300650401845227,-1.77271681138324,-0.642266175824391,0.302993558131787,0.595691172342105,0.375351767306664,0.239955484214817,-0.167203263270521,0.130794721017918,-0.14068807457294,0.500227285036294,-0.357747836651158,0.0634512109878779,0.295399456674622,-0.635029572506938,0.995816634188194,-1.93998381442514,-0.71732274465617,-1.07678764773273,0.961046027681357,-0.302325090949643,0.204752548239907,-1.62625053302117,-1.06444015256294,-0.466575921838797,0.250706245390442,-3.61680971628661,-1.24184982999447,0.318200218104669,0.991773216016358,-0.258447331229937,0.874191962143159,-0.182481879287512,0.723823996555407,0.844897238967395,1.02806706354685,-0.0372326798450454,-0.673465502806751,0.669703463473964,-0.0477042451187596,-2.37055545317152,-0.0308012309863723,-0.273181941637687,-0.871574696875864,-0.568821235658615,0.746988550020754,-0.518911382322572,-0.397458292626052,0.566729765130616,-0.508418227451793,0.32485747571447,1.18587543888601,1.82599298572493,0.227885958981582,0.460591716678559,0.854530065707668,-0.18885130230247,0.210379353183192,0.124656757765673,-0.273576961234714,0.19820249337056,0.79683423432285,0.635725848944766,0.264014126781424,-0.840543581381417,0.49150922939204,0.535739354682251,0.608808531889315,0.890465000413754,-0.0352400467382885,0.152557364361836,1.65334045984221,-0.31738699144337,0.924610779608624,0.0059072770124562,0.394380415758838,-0.152203541613365,0.507369349746513,0.195029536241852,-0.646240923322412,2.21467277242031,2.02748878421801,0.483438867170885,-0.0310892982815697,1.24701261168952,1.55312380179408,-0.0206177568127872,1.91718604797999,-0.0769098183231945,0.445275320414145,-0.791423605771572,0.145107892474214,0.649716616648185,1.38562745940323,0.156589738549241,0.231326908822245,0.0957872586632504,0.188387498362479,-1.22437134641013,0.245385863849269,-0.552373233501265,0.357154567782868,1.77406850492713,-1.07503120543062,0.503953929205325,-0.54862309510498,-0.0676478789083565,0.763028373306144,0.743403211542917,-1.35836210414532,-0.765714761584702,0.127258406559501,0.215939533229202,0.81942683219776,1.49565900262699,0.0744500547386839,0.904053344195092,0.567171904429235,0.334238928893814,0.436507918584757,-0.843841098796297,-0.611697251483034,1.62084271733831,-0.481936508519027,0.0214041643590221,0.85013745581521,0.313777777071917,0.301593471831543,1.37655164711291,0.180990324010046,-1.02238806645071,-0.685534787815429,0.200449267449296,-0.937404040212791,-1.26378740047319,-0.650036381282888,0.327112565847693,-0.458195088713503,-0.489195335521398,2.04839139032248,0.0293456299666803,-0.436447835843139,0.0511256237674712,0.249936099678699,-0.325672538908927,0.844219352393215,-0.760519518767115,-1.62018968839388,0.454620017123532,-1.1622816454751,0.125557166643482,0.384222779846772,-0.0826578560089894,-0.838399685073495,0.633567554898418,-0.092872210367197,-0.869109886663364,-0.119001911698397,0.521625333636128,1.08165783011371,-0.296808041403954,0.577791040773113,0.284433041740584,0.0631048311371923,-0.1739338402386,-0.322755598376947,0.136776129373001,-0.571122329741066,-0.327291818895531,0.399487039070583,0.0004842581542224,-0.464711413421649,-0.384563351092033,-0.371539685943302,-1.39985813737692,-0.0226609683634372,0.724791044490438,1.14019242397769,1.54015160652519,-0.661044419161621,-0.598699224296153,-0.228398725119693,-2.07867136552732,-0.334963863571069,0.878700403030728,-0.111972600624612,-0.690612793885614,-0.343939896380253,0.568746236098905,-0.403838173804459,-0.860878077430724,1.40096709450739,-0.829010490060935,-0.551628152815844,0.272078422469045,0.288514187098137,-0.708353305205578,-0.260155950277059,0.606663911898608,0.466133897092251,-0.200465518071982,0.879136085733495,-0.236830515019068,0.0533783722935618,0.391682350816483,1.44489388636118,-0.275456864883989,-0.964441634209121,0.328235478003751,-4.28925378244217,-1.69202893305906,-1.47010153611197,-6.77109672468083,-6.07933719308005,-10.6911962118171,-10.7338541032306,-9.17716637009146,-9.25230724747513,-6.21025774661028,-6.76333439062322,-5.24930454889762,-6.60806825219469,-6.59055029705192,-9.05799252943745,-11.7367291212569,-11.5434979157865,-7.67866801029943,-7.01990155916612,-7.50616937408145,-7.41771206475053,-9.40542306160986,-10.924186865147,-10.8606980453666,-3.73802333366749,-19.2143254902614,-9.63468971263612,-14.690729133641,-18.8220867423816,-9.44037499459843,-8.13869488434773,-7.84094220494304,-6.22060535304292,-18.4937733551053,-13.8837785491112,-18.0499976898594,-17.7216383537133,-17.4759212828566,-3.26647554459315,-0.330305803751441,-0.45607695680899,1.50079377517002,-17.230202160711,-11.8521613037824,-10.140200337183,-15.0663743633461,-9.80988150207055,-14.6663889726541,-14.4915983463022,-14.2483158270781,-14.0047761755606,-13.7610179615936,-13.5170724083842,-13.2729650621928,-13.0287170264518,-12.7843458873548,-0.971757538368114,-8.64045910049478,-9.82505442102721,-9.57466229922106,-2.23862224442526,-9.09253265181295,-8.82935922766409,-8.57897327333454,-8.32860088836825,-8.078240669038,-7.82789139878016,-7.57755201800709,-7.3272215995796,-7.07689932873899,-6.82658448658054,-6.57627643636006,-6.32597461208273,-4.8528669146236,-5.84352838067721,-3.18216808481143,-5.58044712038062,-5.33014378246253,-5.07984568135779,-4.82955244300835,-4.57926372815218,-7.07736060637589,-7.31157981735935,-10.3848897408947,-2.97131675769274,-0.913786970583513,-4.74441333023745,-2.73594037401519,-4.65280380668112,0.0383719793321978,-5.32728665168661,-9.6576265944335,-11.1820634139742,-0.895433620751722,-9.37787845231763,-8.41668121212274,-7.89190877856627,-8.05104890186539,-7.62865191597326,-7.68780276684597,-8.60475886835984,-8.29965953059956,-5.274865818881,-1.95887596969497,-4.66257695501824,-7.2083115791564,-10.7870505700202,-10.7163393018774,-17.6206343516773,-8.52767862203589,-8.22556891234807,-14.5559572107641,-13.602211465597,-15.4450258118019,-16.3375959447735,-13.0441824003561,-13.0268638593173,-12.623316046432,-14.1074642630375,-14.9794773489142,-13.4170122721265,-13.7789556397675,-13.694873039573,-13.9062968240505,-10.4686770874209,-11.4706925061593,-9.88721406724695,-9.56016927087188,-9.79801207658904,-12.3816058947985,-11.6069703760766,-8.59204740189288,-9.37385858364976,-5.16060809721957,-6.91763950579126,-6.07398900285949,-4.55566674751092,-8.03661487513855,-7.24346097400378,-8.19969002891841,-7.24554959537009,-11.5838983872121,-10.9044588731508,-10.7395718907673,-10.7321089251086,-4.01578678027745,-8.50943318717532,-5.20830522179452,-7.05231095228929,-0.499349578859305,-5.16522922685485,-1.38121354248053,-4.45210024854037,-4.63463139323434,-3.98562600822203,-0.819901849432008,-1.04370522504569,-1.16833941780754,-4.82032224395007,-4.32979551307589,-0.126756361711439,-0.994580854433906,-3.45519657744236,-3.72454345377605,-7.54364593187217,-7.27986921938704,-7.02898027290706,-6.77818372152522,-6.52746224116063,0.578869439330842,-2.37665364067708,-6.39717031528651,-0.0077912302905812,-4.51012391529804,-4.75707449850737,-2.95382425341893,-4.05852343611281,-0.931614224984722,-9.98258470738767,-10.3093341893072,-9.57719439289905,-9.46613912320431,-0.83148260879597,-5.41958986916794,-8.10797466085831,-7.97425052332349,-10.0181060613614,-5.5887855765974,-6.17428834800643,-6.28431406964108,-7.14041803349475,-11.090424813263,-6.5991261303635,-5.87606732124924,-1.63514452424164,-3.98841505479623,-4.71049793587464,-7.46010298330266,-5.58687312563725,-5.28167813117348,-4.45889502952153,-3.65749040377527,-6.23304367078495,-6.22194535944177,-6.35301985790071,-3.43173796295146,-6.332512814541,-4.54955674371782,-4.86186658087283,-10.0185024459282,-6.04339314434942,0.0160870050482155,-8.66077095912039,-6.4358707376348,-1.63347202401986,-1.88027540328199,-6.67997675520914,-0.819319364809584,-4.85777667212588,-1.11273543930467,-6.16045662030601,-4.95582330430277,-4.7327675351632,0.217469760178719,-0.431690053731737,-9.07271093398351,-0.498521775750102,-4.46105120749925,-6.71387819491558,-5.59136368933409,-5.42878849870488,-5.19918574342056,1.0275841718551,-6.42527621352443,-6.19247526385522,-0.472025637126337,-5.33871420959882,-3.82289410599595,-4.62948099682303,-0.660967626671015,-0.264936238828755,-7.49518733635876,-8.65826843157538,-8.45897495556967,-7.7552536640417,-6.94701030902337,-5.05382476474338,-4.68361969585018,-4.42919458671376,-4.99399178918475,-1.07499904137371,-5.01220235869184,-6.76663337149207,-5.14182349291966,-5.60634642932959,-5.29192495475268,0.521483689902165,-2.80191542309724,-5.42936187944371,-9.50514082568186,-12.9914655817567,-12.8754942229841,-10.1935303551514,0.727242085814848,-5.41749934539643,-11.5340460181508,-11.6080022570993,-8.60448620191387,-8.44287285721034,-8.14932178394224,-5.41378669142638,-1.50855714024168,-0.429211904447448,-1.01691553500414,-9.9585309187018,-2.420715975085,-1.88061870491121,-3.10393771952109,-8.5520227319441,-5.96790496861639,-4.7045087050312,-4.22036591807154,-3.50170251648822,-4.21175592358692,-15.3930448312636,-15.2976561861343,-15.6231873302985,-15.0216572999306,-14.1161560074304,-14.094451660329,-11.0301103643432,-14.9529810390579,-14.224403603167,-11.4123295951252,-13.2478885958622,-8.72864506518152,-11.5670059165135,-8.65374335706751,-14.0295376738875,-9.93567958156078,-6.55255368427192,-3.92620731586873,-8.33476258691073,1.32288725448265,-1.10869894034456,-7.35279224297253,-7.01360737195925,-2.24151634571345,-4.32898899462283,-0.673818453194249,-7.58102324741972,-3.54722989444144,-7.38337003956967,-3.83678146634435,-7.56013197197136,0.116303256118652,3.44242199594215,-3.79279543594993,-4.60379669207464,0.240060357919937,-3.08774290682652,-10.447632938235,-12.9136317373077,-11.872845098188,0.796579962453559,-8.98305216762269,-8.88487177224851,-6.10655192524523,-10.242859083204,-10.1275247811671,-9.90916805374299,-4.18455528093394,-7.62871014660448,-7.32027202211023,1.5710801214626,-5.23161145654992,-3.8114281425371,1.26814661675691,-5.76582302154173,-6.42437211273331,-8.7554491326517,-8.49081262174082,-7.63696288811138,1.0752476539262,-4.61013844047447,-5.853545070898,-6.39337284276668,-3.51284546122181,-7.12231638408937,-5.74894325155799,-8.56945415472099,-6.17736456586248,-4.3463476308633,-7.86280852638766,0.712541142762088,0.27471029150754,-7.77219735461502,-7.36463881998297,-10.0062434296255,-6.0205789709702,-11.2218047709786,-11.0022890615302,-2.13515486441111,-2.30664478783159,-2.37255179777895,-5.87143807802568,-4.79973713485762,-10.2588514782991,-4.68380643176166,-4.69278763834241,-5.25425346321937,-10.5164652105548,-5.38783122686352,-1.88616230658692,-4.89818303490097,-6.98927231350758,-3.82826817896473,-7.13215063894307,-0.729706928009483,-6.96497247579046,-7.91498900748283,1.06526242773606,-7.67225031168781,-7.44529583374444,-4.35043446756499,-3.5181311704857,-0.658246292064356,-4.71552123988097,-5.15247483394519,-6.61909019992345,-4.2672960668817,-4.57126773103714,0.139567417265152,-7.55572894101666,-9.26612018494559,-3.41515194777416,-8.89372633557037,-7.46296062676276,-7.11387278226069,-9.15095100562097,-4.94261241607845,-11.2723158701978,-7.03588005080407,-3.68882599540221,-1.80810297319338,-12.4579989307142,-8.48579450596077,-8.63629739365259,-3.94196510459461,-6.80009808768536,-6.74556131619148,-10.2667581077355,-6.45502910306118,-11.5714234295766,-6.28109364908023,-2.96920095585607,-4.69115085524464,-1.18166939064494,-4.25246559869278,-4.97811801438515,-7.62431631397779,-8.76069451926062,-8.72449560202264,-14.2668362798028,-13.9694706254616,-13.7256846134361,-13.4817046750119,-13.2375585139603,-0.142098601080574,-2.33279338224807,-1.58334340543936,-5.94500331282299,-9.86137210765166,-4.39363360177944,-6.1061832734711,0.984993219111346,-5.75721608217278,-10.5440113995705,-12.451498657048,-12.2891333850899,-12.0438056158463,-8.39657296658687,-2.95416672265135,-2.75755676655084,-8.5604228759795,-12.4567059527055,-12.1565865835299,-1.81638414654661,0.141331683969234,-8.22995199210048,-10.1498129226371,-4.56600986017187,-6.0656218797665,-6.03440257566619,-5.92613104122097,-11.0816168429851,-13.2025053438681,-1.42206385294204,-13.0107493697978,-4.28799577702192,-8.38844296921614,-2.90118981074214,-1.42561990549746,0.98434361557577,-3.56511884467947,0.334119448067333,-1.82483910494673,-4.69799687128777,-6.66517689463338,-5.21014084572584,-4.05716237716209,-6.41662797597451,-1.94888334870021],\"type\":\"box\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"name\":\"V17\",\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y\":[-0.828441984571064,-0.271921864830932,-0.291044980952806,0.127933143180832,-0.137874087895594,-0.650204391866319,-0.508260630718865,-0.765309563261809,0.194852900429397,0.472282509619356,-0.135902406809451,-0.171372201497484,-0.520704934791598,-0.075712045845858,0.571681084363017,-1.05653808308392,0.542906844001823,0.819614989630165,-0.330931306083134,-1.23843801859417,-0.382843342727654,0.102961741460021,0.34125636018748,-0.0714479636697889,-0.0923709166624011,-0.722388233026374,0.0971104517590714,0.268202954443694,-0.417323946122925,-0.291009879227983,0.591162720145895,0.410566242241914,0.900549693704011,-1.26708462405362,0.5770078409894,-0.25287462624658,-0.015416276063241,-1.28682087006128,-0.094011779910848,0.0525232119484009,0.227130008341655,0.364623492829823,0.109394701364872,-0.331124674145517,0.434300237541995,-0.226912328115495,-0.197804457325928,-0.144630098442626,1.19705049761538,0.167722004350934,-0.526825387206487,0.325078344310698,0.447703244954516,-0.711052471578556,-0.764001014616634,-1.1809107903991,-0.391613537952035,-0.134886020191102,-0.743862769635162,0.222558769443807,0.126660341736758,-0.8296387170098,0.241443965806781,0.539281450715608,2.68261263852543,0.0280204475401321,0.133526605408568,0.246683762987843,0.292023384477003,0.261105641095224,0.888303692057875,-0.968321629434453,0.21001663574047,-0.752709585266426,-0.182280431288574,1.70995668316361,-0.726160465233803,-0.19049154557887,1.37504447972709,0.950037601278266,-0.0373019033538426,0.248377476007211,0.867488687303113,0.314223783675981,0.0452896634035353,0.482260432262303,-0.832440734680914,0.888817810030952,-0.449233579281882,-0.909999030218705,-0.442698756742063,0.44425724752707,-0.422079858390394,-0.378885098397676,0.0039413034587632,-0.009192040478654,0.593105649199079,0.493887277911031,-0.934166257907453,0.156391212345444,-0.722705049709742,-0.427108457525929,1.45524414153005,0.28513550540268,0.486682553690475,0.242415490623881,-0.247260033957162,1.00530597135217,-0.161958359852839,0.724620341136013,-0.76314592787814,-0.260244725118618,0.572170656216174,-0.0167239564801834,-0.0681680252081273,0.266923790260965,-0.800640481675561,-1.1924062203116,-0.31137688909703,-0.242641778308354,-1.29509035018157,-0.925901538295613,0.694643051905159,-0.717201199018336,-0.0253287964069741,0.425060821534753,1.0051566330642,-0.197711082929029,-0.143930939453174,-0.601501925406352,-0.564937279238443,-1.38453619685557,-0.486622202738628,-0.0318114461797913,-0.0107625627219663,-1.20725313379479,0.357280168304306,0.355750850314477,0.683874021145705,0.879676297413093,-0.0685256647827616,0.525490866340581,0.811772858744273,-1.25177323582883,0.347685703358067,0.461120400689689,0.335071002473085,-0.381368310458849,-1.2363067928521,-0.562811995025813,0.0747355282363681,-0.390573875932259,0.246485619631091,0.0976627101403305,-0.837287393675373,-0.322967821100732,-0.769763475899982,-0.374219488483753,0.352065460358655,0.338800870738185,-0.578043461982587,0.0896335725570397,2.17911002274022,0.487079388323249,-0.643142941488127,0.678764020379268,-1.02350881712777,0.528650634845433,-0.976201298296376,-0.272315847265041,0.492282264646472,-0.0297720183701329,0.106487042251953,0.0464275046940434,-0.694598199173748,1.37001151194038,-0.0336619354461371,0.95199493914227,-0.286511635987952,-0.432067310033368,-1.11904315680996,-0.676894923772914,0.0386410275425704,-0.24795538715293,-0.48732717492602,-0.0109924805562255,-0.4214361364708,-0.153582589186872,0.681434620912673,-0.46793092460289,0.111280430793239,-0.703287465056369,-0.174047843331038,-0.251048546064901,0.274135645627848,-0.719027043545268,0.434233290124982,-0.153953702439825,0.145510606935275,-0.831413510992614,-0.285699778776806,0.843140228369363,0.675015694240414,0.315102977810622,-1.15578480905134,-0.262247712087066,0.737262191427523,-0.349231599508261,0.979158231257863,1.1858923099798,0.0978620387357186,0.378997393415991,-0.789327501108632,0.855418575689781,0.203532968116979,0.349718651918874,0.828817585241538,-0.831949363429533,-0.549183633742223,-0.101015898137091,1.82223449304873,-0.488747240818974,-0.0243876790513601,-0.677694949728226,0.0906551959713995,0.588498658643175,1.10492697596502,-0.104299268170131,0.324487246010048,-0.610676017929663,1.82809321735281,-0.870773959422604,2.34687594502294,0.0049583025748938,0.0840898502389423,0.556644901504054,0.249960538464453,0.976455556487928,-0.184764631663279,0.0990333921489309,-0.269736503720552,0.660835505488329,0.934446162072664,-0.0156265835797072,0.847022021260084,-0.0874779059909268,-0.0161060018739664,-0.849978940662458,0.740242425422866,-0.654101188776915,-0.523527709525973,-0.297372886504887,0.321819375966197,0.0527149905966225,0.294526229350461,0.407352830730795,0.115665730241673,-0.422730079058668,-0.656698845926144,0.179950008498499,-0.554218218847298,-0.300454145251866,1.49456153299214,0.867810625345165,0.166033799393908,0.386020495190203,-0.366948038126012,-0.574199933398342,-0.580096099902121,0.307077440586699,-0.647090538856976,0.527025147264207,-0.521723417230775,-1.03741505363886,-0.42691026062759,-0.141420680650571,-0.933780882705781,-0.406398993839685,-0.292140205996285,0.264371571610337,0.816764978537816,0.343538244338326,-0.15120676720325,-0.434718650189745,0.632129605688797,1.18777216002512,0.23044548888873,1.22436094125838,-0.802623862539027,-0.216623974316661,2.92249382786611,0.406140286967816,0.423514170081931,0.0190018242486631,-0.129376639135013,-0.51153879929341,-0.436509249472317,-0.536380659596176,-0.43091303686954,0.614303974635814,-0.200650986113841,0.754883972425506,-0.302826604175432,0.760111864627864,2.51000346561949,0.143518514607822,-0.052042668740731,-1.11480721919951,0.460930425649946,-0.66332503481697,0.091869931021025,-0.618109586151631,-0.417980818698567,-0.622632682723697,-0.205666580296062,0.899003389480568,-0.0447740065372378,-0.729405023696591,0.432918993143728,0.496478460466925,-0.0204729238907364,-0.600908376137261,0.271267171225828,-0.291285971075701,-0.379654707815042,-0.22921979859137,0.188437782735031,0.0865956134932811,0.0391993271501326,-0.687448089419384,0.255099917713094,-0.0073518258774743,-0.164171791345262,-0.780470780647598,0.0709179124513433,-0.0188973453878399,-1.57429755724836,-0.0889548190918545,-0.698624560859612,0.241034971608002,0.0234240786674688,1.25229754146729,-0.259576802312614,0.361462686728174,1.30293461835767,0.260474179011697,-1.16471138211793,0.0103436751510783,0.179821035331923,-0.465755299096572,-0.250523132382498,-0.044851766776773,-1.14281239402426,-0.211645537192841,0.4996605321794,0.617395713250652,0.317096294054258,0.938640295493356,-0.915164537995375,-0.589966626907866,0.234929353726608,0.391082905936283,-0.300975248639663,-0.192107687054023,0.246566103806436,0.181866036568908,-0.252545993671024,0.797826312894644,-0.317665010384454,0.249489425294986,0.0248638783731829,-1.00065449514957,-0.430985014013356,0.587196264160918,0.0210028445159912,-1.47746042466104,-0.337423716472387,-0.66856221007419,1.03036155126034,-0.34265608761729,-0.0638372807782435,-0.69002524585673,-0.400337086995713,1.17125285194224,0.966536743780196,0.771790209118544,0.126567233784371,0.209260654340672,0.0240236790446461,-0.56001402114914,-0.756061405657521,-0.301848319435038,0.428638137729432,-1.16094761855627,0.57539407642616,-0.148204648936844,-0.442162470898721,-0.380804674591097,-0.292601436453748,0.977783964714588,0.214271805516705,0.124716044421754,0.408185608172224,0.663797166686689,-0.429630249832897,0.432223497165835,0.7766304693084,-0.477410850756633,-0.0027873881993597,-0.50532476405013,0.0389188003151181,1.29746192752979,-0.327571893415064,-0.473948366801639,0.643126062095242,-0.100273605412674,-0.0661607094502479,-0.130862042878523,0.467542894725939,0.0070864986389989,0.0736181825310695,0.550405376949946,-0.31769885817491,1.73074511609888,0.374953719556473,-0.616533993743866,-0.129171578259154,-0.661597771600829,-0.634149144649196,-1.11284511304943,-0.625079301671993,0.142262777502033,0.08820926113861,-1.16717925690696,-1.37689672736331,0.141812932942295,0.712334787040042,0.682132933598783,1.63832412502961,0.284367876781129,-0.0180265147705405,-0.0182088218723429,0.139298815250028,-1.08282649772168,0.863439577535347,-0.0492687291836595,1.8670080674306,-0.185546629924736,0.257703673852877,-1.01949283220097,-0.934210778381876,-0.387482132036018,-0.50508779679691,-0.849504090915929,0.485788772477659,0.0996569407072982,-0.281169920204952,0.372459517864776,0.948835617591618,0.0101452282572587,0.172235006371986,-0.288181038136711,-0.723331917568594,-0.164492346760436,-1.19165665922744,0.666712114182145,-0.771706367127915,-0.216258048745639,-0.932198750713165,0.840507641557727,0.911788996039641,0.385970830692182,-0.558652705913594,-2.83005567450437,0.599717413841732,-4.78183085597533,-12.5984185405511,6.73938438478335,-1.12905587703585,-1.74635013628103,1.31301362907797,0.784426598154274,-4.83032424210571,-3.75412806618729,-1.31205856007348,-4.83511205239717,-4.21448627485607,1.52450091526025,-3.53552351168246,-3.20438340295762,-5.84426647937357,-6.2883575087823,-6.30475338603049,-6.29314531907376,-9.8025617903912,-2.77511389701838,-2.76009701528795,-5.1361351026702,-15.5033921000669,0.891934540534899,-18.5873662058916,-15.2270075099256,1.63200885764087,-10.2467554066001,-9.93176515376766,-5.04473569177435,-14.4412111342765,-18.1030037037729,-14.7449024646768,-13.9590853730538,-13.7991476446987,-5.269876299726,2.29899822072815,1.70702446635297,0.115114264650572,-13.6392089915234,-18.3888105354245,-17.5066115481045,-12.8041408991277,-17.5420303090874,-12.6025964553952,-12.4398049728466,-12.2809648581754,-12.1220088158237,-11.9629542349435,-11.8038151924676,-11.6446032058862,-11.4853277896478,-11.3259968724596,2.61145033447876,-13.6841395944616,-14.2595985921417,-14.1027718764864,1.77645429510255,-13.7974745003699,-13.6297209427085,-13.4728970076501,-13.3160791903173,-13.1592668578419,-13.0024594617382,-12.8456565242928,-12.6888576275064,-12.5320624040465,-12.375270529796,-12.2184817176797,-12.0616957125199,-4.83555830647772,-11.7562556050179,-5.84121800175148,-11.5885435992809,-11.4317569116986,-11.2749725851252,-11.1181904509172,-10.9614103561188,6.24498710234308,6.50927165018434,0.409735840500415,-4.90809850732764,0.0220452070437295,-4.93111196829858,-5.07947908460579,-3.21861825150599,-0.219143226460215,-5.09518287931609,-9.27663556929158,-13.3892507167674,2.03119574973193,-9.09423129737693,-14.5708366290177,-14.2650559534715,-14.3296261567476,-14.0646239413114,-13.2772997431934,-12.6243936527694,-12.075932061394,-4.69843344927136,2.49832484974359,3.90282478361756,6.4435098643744,0.636412737308571,0.91859080878698,-21.675483501012,-9.6988394108884,-8.81578542555918,-25.1627993693248,-23.8156358284126,-22.5416517287861,-21.090612716108,-24.0190985475902,-22.8839985767803,-23.2415971479491,-21.6739867132891,-20.2992165093576,-21.90649321637,-20.5780220491922,-20.5835927904158,-19.7162573051191,-22.6088681905866,-21.047629901985,-21.7101876525534,-21.5368016259059,-20.7406637223494,-19.6718814509262,-19.8997264249367,-21.0178983428443,-19.2362923697613,-4.69556272249452,-20.2545556896053,-9.85592743669396,-4.67466711122835,-7.65470424350142,-18.7506411474674,-18.4854603221489,-8.85187850534679,0.635694232941605,0.835639563488731,-13.5021528919623,-13.5706825019333,-6.6493577879714,-9.06907940021057,-5.24911146794949,-8.58807007314333,-0.207706529097452,-5.67173864053893,1.1321602098483,-5.24864639527919,-5.63549400383391,-5.15759639749234,0.874890632270019,1.14313007770305,0.601804858067329,-4.40585022452865,-4.48018356526203,0.327006411459276,0.705794271683871,-7.14032596614864,-2.81560029569659,-7.33969796421674,-7.17167241498026,-7.01462170672071,-6.85761265464239,-6.70063744821132,-0.119204381070058,1.59150614830401,-4.44847225233098,-0.868182736046053,-6.05331938825344,-5.35646454386042,-5.58579436647491,-5.60340034818128,-0.152470829644753,-13.691474448179,-12.8221770045808,-12.5039309695675,-12.4480392359586,0.536817322665437,-4.2850705920981,-13.7531307979331,-12.7600939511044,-4.37710568381017,-7.45709493793125,-6.53652073527011,-7.36832064555377,-12.1205390025684,-1.68547301699574,6.60936580903842,-4.42475717388751,1.32579410174258,-4.82624611607161,-6.13188675183675,-9.87456039324105,-4.46049463214891,-4.44208205885268,-5.07145010804216,-3.94831185243281,-9.51641148491956,-10.441008666182,-4.86297149937169,-3.90149898369755,-4.92916202340023,-5.36934877847861,4.08248488419359,-9.78580026201852,-10.0756455907271,-0.0572786796405291,-11.0463816554829,-3.65425828769231,1.59352878606579,1.52266169956075,-8.76078602293495,-0.397245548944671,-4.18680753704806,0.831442610720144,-5.30127339068683,-5.19779447735003,-4.23102187544855,0.24334710955825,-0.0539606012956825,-6.24814535335983,0.564761098405632,3.61925125200524,-6.8238312134789,-4.9615343155062,-3.94629958919926,-3.82052232662867,0.120608339589106,-6.34745330751181,-6.18883415213498,0.570459827436018,-5.23142512742468,-5.21187516766885,-4.60568646763486,0.278141865207384,1.42505965449185,-12.2236328477344,-10.7080182544535,-10.5760149147501,-10.6117146970978,-10.564346602529,4.02736603913411,4.13366666889167,3.9705869371836,3.63919954823548,0.22388685433899,4.15208557256771,-0.370333268936992,4.09098324669186,-11.4083675448063,-4.33311795972043,0.306339379229928,-6.42673430721498,-2.72734300093373,-10.0062528282393,-12.7343938853776,-12.719207160428,-14.6687710766351,-0.5663900830288,-3.70070702592749,-11.8875700201872,-11.9390915052116,-9.33893779428438,-9.5180378916264,-9.31500138499105,-11.1432410242579,2.27027117814029,1.67998551904683,-2.04385766822656,-6.38809273753128,0.799832475247662,3.32156931100987,-3.96062268909989,-6.46540863418339,5.58611468683053,6.02439676670687,-2.37242320724166,-2.941876323532,-2.53235540606601,-21.2979057823155,-21.3381950868483,-20.1590474539227,-20.1655673800665,-18.716764511809,-18.9124938172188,-22.6679054064789,-15.4869899240937,-15.8416159780561,-18.1746174349071,-16.0445243414767,-20.6850275533272,-19.1729963590355,-21.5851521412337,-15.8335888785336,-18.3838524599849,-20.1645422294456,-12.4623149481086,-17.2709851692259,0.752610596119435,2.20265154365361,-17.5988535455879,-16.6683693822389,-6.12719357199364,-3.35463814070962,-5.16021301572915,-16.0920320589503,-18.3720191223339,-13.8065681285297,-15.8251362851177,-3.41027456780471,-18.1082610229766,1.41821495932655,-12.8672447953713,-3.00361530529652,-12.9575309948449,-3.17202752176385,-11.6471577741668,-7.80963509977466,-9.75077638654123,-13.0327849564566,-9.78567719982127,-10.4451050316273,-13.5663252216994,-8.69777741257031,-8.6557110398096,-8.52297487191683,-3.35318018239636,-5.30462366328046,-4.25115786762875,-0.122016068028642,-4.84799196061678,-7.31140729142311,0.8110054093379,-9.56726769048681,-5.14703878335167,-3.26143516010375,-3.09301268981888,-7.60471483249934,0.0933209955444861,-7.52418833345318,-12.62385610867,-3.34889609796046,1.7333815808837,6.44364914460203,-2.70505213033344,-2.57746443422373,-10.3405128633486,-3.74648955100281,-2.28474841411287,-0.391051374531861,0.472995390747944,-1.30436979397668,-0.515302055109939,0.188469552514539,-1.31075238207209,-1.58833565600268,-1.3519003888026,1.77869660251824,1.1657365409567,1.75931419392615,5.54086531862428,-3.16695515760391,0.167601789076859,-3.03516584667273,-2.28614467887841,-2.42153561881163,0.462929331041335,-2.28557270821558,0.978546240489057,-9.33432947229458,-5.99533723596091,-7.5509680917538,-5.5220880540876,-0.10294607389286,-6.41953891153561,-5.8569977597527,-0.223768268609043,-5.70117436362661,5.66542906834794,-8.07801049835537,-7.9253889983055,0.653662125212474,3.87161756353604,-1.64650484628376,-7.16504438660351,-2.81990611139418,-9.25063451000699,-0.798201084554281,-2.11442919291931,-5.70908680498665,-9.26164098662644,-4.3689859085708,-4.47240325411649,-5.05600998750159,-2.89255533222526,3.70206529090756,-0.0529325394075147,-2.51518280017187,2.34702289955703,-4.81586301103402,-3.24368593233723,-1.37262938444618,2.13460635695284,-8.15282937205818,-5.01790786864794,-5.55806727496643,0.113665405648114,5.5802092523309,-9.28518598266033,-1.38555652893852,0.671240576431668,-3.48343626722796,-4.446191868553,2.93448122378549,-0.817261404200648,-6.71717654755023,-6.29347862779442,-7.16443030217363,-6.62696817708246,-5.96998693103967,-5.81091981744958,-5.65176527245489,-5.49253578625626,-1.27478714656577,1.46805197816555,-6.16763653803023,-3.08227352537105,0.591319064375358,-1.8597389700645,-2.08406707082134,-0.0524194348357059,-1.90901678581052,-5.13308149079721,-2.12802655387511,-2.03970261739192,-1.87992827944447,-6.64248226272335,1.71451073880902,1.92934969114042,-4.33599801203682,-2.71855972503703,-1.55854452752772,0.716591309767583,-0.828192503935611,-1.48128347210329,1.40450707513401,-2.86574970146517,0.334315623693923,-4.16647877527802,-3.71275186652084,-5.84890261106356,-3.00895800089691,1.73474160368315,-2.87134152887014,-8.71392005149206,-6.1039030730781,-7.2909602133188,2.84494961758243,0.327463514418321,-1.7314131905532,-0.824644210487403,1.19421171382239,-2.68352089790884,-4.57052943365069,-3.26711568106648,-5.03532591722409,-4.61471706851594,0.903562376617253],\"type\":\"box\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(234,234,242)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"rgb(234,234,242)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(231,231,240)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(183,183,191)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"rgb(67,103,167)\"},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"colorscale\":{\"sequential\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"sequentialminus\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]]},\"colorway\":[\"rgb(76,114,176)\",\"rgb(221,132,82)\",\"rgb(85,168,104)\",\"rgb(196,78,82)\",\"rgb(129,114,179)\",\"rgb(147,120,96)\",\"rgb(218,139,195)\",\"rgb(140,140,140)\",\"rgb(204,185,116)\",\"rgb(100,181,205)\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"rgb(234,234,242)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"rgb(234,234,242)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"bgcolor\":\"rgb(234,234,242)\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"fillcolor\":\"rgb(67,103,167)\",\"line\":{\"width\":0},\"opacity\":0.5},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"bgcolor\":\"rgb(234,234,242)\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"}},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.2125],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.2625,0.475],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.525,0.7375],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.7875,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V10 vs Class\",\"x\":0.10625,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V12 vs Class\",\"x\":0.36875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V14 vs Class\",\"x\":0.6312500000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V17 vs Class\",\"x\":0.89375,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"width\":700,\"title\":{\"text\":\"Boxplots for Negative Correlations\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f4b953c6-2c89-41f6-94e0-915bfb9a433b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outlier Removal"
      ],
      "metadata": {
        "id": "WyrdP4Ngs4ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Outlier Removal\n",
        "def outlier_removal(df,feature, fraud):\n",
        "    array = df[feature].loc[df['Class'] == fraud].values \n",
        "    q25, q75 = np.percentile(array, 25), np.percentile(array,75)\n",
        "    print('25th percentile: {} | 75th percentile: {}'.format(q25,q75))\n",
        "    iqr = q75 - q25\n",
        "    print('Interquartile Range: {}'.format(iqr))\n",
        "    cutoff = iqr*1.5\n",
        "    lower_threshold, upper_threshold = q25 - cutoff, q75 + cutoff\n",
        "    print('Cutoff: {}'.format(cutoff))\n",
        "    print('Lower Threshold: {} | Upper Threshold: {}'.format(lower_threshold, upper_threshold))\n",
        "    outliers = [a for a in array if a < lower_threshold or a > upper_threshold]\n",
        "    print('{} Outliers: {}'.format(feature,outliers))\n",
        "    print('Number of outliers detected for feature {}: {}'.format(feature,len(outliers)))\n",
        "    df = df.drop(df[(df[feature] > upper_threshold) | (df[feature] < lower_threshold)].index)\n",
        "    print('Number of records after outlier removal: {}'.format(len(df)))\n",
        "    print('-'*117)\n",
        "    return df"
      ],
      "metadata": {
        "id": "w8ifdPN6s-51"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saya akan mencoba menghapus outlier untuk fitur V10 dan V2 karena melalui boxplot di atas kita dapat melihat bahwa ini memiliki jumlah outlier maksimum. Kode akan menunjukkan outlier yang terdeteksi dan jumlah totalnya dan akhirnya menghapus semua outlier."
      ],
      "metadata": {
        "id": "NqbTkkRZtFkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Removal of outliers for features V10 and V2. Since, these two features seem to have the most number of outliers.\n",
        "df_rs_out = outlier_removal(df_rs,'V10', 1)\n",
        "df_rs_out = outlier_removal(df_rs_out,'V2',1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj3mamtFtGuH",
        "outputId": "f4299317-8018-41a3-8664-14cb4b3b2347"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25th percentile: -7.29780335001461 | 75th percentile: -2.44746925511151\n",
            "Interquartile Range: 4.850334094903101\n",
            "Cutoff: 7.275501142354651\n",
            "Lower Threshold: -14.57330449236926 | Upper Threshold: 4.8280318872431405\n",
            "V10 Outliers: [-14.6764702497464, -15.1241628144947, -16.6496281595399, -18.2711681738888, -15.2399619587112, -14.9246547735487, -15.5637913387301, -16.7460441053944, -15.3460988468775, -15.1237521803455, -22.1870885620007, -17.1415136412892, -16.3035376590131, -16.2556117491401, -16.6011969664137, -15.2318333653018, -18.9132433348732, -20.9491915543611, -19.836148851696, -23.2282548357516, -24.4031849699728, -24.5882624372475]\n",
            "Number of outliers detected for feature V10: 22\n",
            "Number of records after outlier removal: 917\n",
            "---------------------------------------------------------------------------------------------------------------------\n",
            "25th percentile: 1.12825627326543 | 75th percentile: 4.143964921917915\n",
            "Interquartile Range: 3.0157086486524847\n",
            "Cutoff: 4.523562972978727\n",
            "Lower Threshold: -3.395306699713297 | Upper Threshold: 8.667527894896642\n",
            "V2 Outliers: [9.06761342731767, 8.7759971528627, 9.22369194937548, 9.66990017304097, 10.1148157246654, 10.5586001882538, 10.3939171427504, 10.5417508026636, 10.8196653713117, 11.5863805198184, 11.8179219897853, 12.0958932259299, 12.3739891389716, 12.6521968313004, 12.9305051249875, 13.2089042844176, 13.4873857909274, 13.7659421584186, 14.0445667815106, 14.3232538097233, 14.6019980426299, 15.3658043803315, 15.5981926625554, 15.8769229879536, 16.1557014298057, 16.4345245512223, 16.7133892350242, -5.19836019923329, 8.71325017095966, -3.93073139597263, -6.97642000754641, -4.81446073955621, -3.4204679837707, 12.785970638298, -7.15904171709445, -3.95232008590575, -3.48813018118561, -3.93591892431521, -7.44901515872674, -7.19697963053735, -8.40215367768915]\n",
            "Number of outliers detected for feature V2: 41\n",
            "Number of records after outlier removal: 861\n",
            "---------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Di bawah ini kita dapat melihat boxplot yang mewakili keadaan sebelum dan sesudah outlier untuk fitur V10 dan V2. Jelas jelas bahwa jumlah outlier telah berkurang setelah melalui penghapusan outlier."
      ],
      "metadata": {
        "id": "zhHCgWqstSdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows=2\n",
        "cols=2\n",
        "features=['V2','V10']\n",
        "fig = make_subplots(rows=rows,cols=cols,\n",
        "                    shared_yaxes=True,subplot_titles=[features[0]+' vs Class <br> (Before Outlier Removal)',\n",
        "                                                        features[0]+' vs Class <br> (After Outlier Removal)',\n",
        "                                                        features[1]+' vs Class <br> (Before Outlier Removal)',\n",
        "                                                        features[1]+' vs Class <br> (After Outlier Removal)'])\n",
        "for r in range(1,rows+1):\n",
        "    fig.add_trace(go.Box(name=features[r-1]+'(Before)',x=df_rs['Class'],y=df_rs[features[r-1]]),r,1)\n",
        "    fig.add_trace(go.Box(name=features[r-1]+'(After)',x=df_rs_out['Class'],y=df_rs_out[features[r-1]]),r,2)\n",
        "    fig.update_xaxes(mirror=True,linewidth=2,linecolor='black',row=r,col=1)\n",
        "    fig.update_yaxes(mirror=True,linewidth=2,linecolor='black',row=r,col=1)\n",
        "    fig.update_xaxes(mirror=True,linewidth=2,linecolor='black',row=r,col=2)\n",
        "    fig.update_yaxes(mirror=True,linewidth=2,linecolor='black',row=r,col=2)\n",
        "fig.update_layout(width=700,template='seaborn',title='Comparison of Box Plots after outlier removal - V10 & V2')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "W8jbRQ6GtVz2",
        "outputId": "b4f2fa05-b62c-43d6-9f52-bccd38d9105f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"e54c5607-15e6-4089-8b4e-8cd1eaa7c204\" class=\"plotly-graph-div\" style=\"height:525px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e54c5607-15e6-4089-8b4e-8cd1eaa7c204\")) {                    Plotly.newPlot(                        \"e54c5607-15e6-4089-8b4e-8cd1eaa7c204\",                        [{\"name\":\"V2(Before)\",\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y\":[0.845049887711819,0.289451215514098,1.11240286511215,-0.304729028381382,2.20260681912487,0.244146827746643,-0.291998470715872,0.107844134081402,1.25755819863272,-0.520790176541268,1.04530218627027,0.0480480404344114,0.810832483494633,-0.982365774608878,1.00810734415515,-0.73496076417937,-0.218979181883603,-1.18013212573691,0.251615559948883,-0.158335153132416,-0.780597577080009,-0.976606515094946,0.628001926863028,0.285336872881923,0.142539767632473,-0.0973665560827295,0.173167880225157,-1.04592907853102,0.305727574143632,-0.201067188363743,-0.600069481773746,-0.139181786113265,3.87276690346742,0.0932350387312718,-3.05154330777863,1.08040739172587,-0.164416845514618,0.306456586499518,-6.23455827632605,-0.16656777640275,-3.30959883981807,0.208210191167264,-1.5307248973014,0.0535093979504338,-1.37320232381817,0.0767488195849404,0.946692600188286,-1.59395351391978,7.17938467908911,-1.69799083883406,-0.213970797999707,-1.99475863327522,0.212323245442363,-0.523847557088687,-0.473087274542781,0.419921026881072,-0.281539572919166,0.757838767607048,1.02741320318584,-0.109287298837858,-0.484431343170466,-0.834103103106904,0.626404913442672,-0.31307923022107,1.26562134412589,-1.59307762599303,-1.32952305598059,0.171539673653981,-0.453440471186524,2.18110055117648,-0.0574641145125285,-0.588805841337802,2.30886052896075,0.230973857400454,1.41265322884918,1.32157092478166,1.37978749908678,0.155522126568606,3.35746996910571,1.2441005466941,-0.399043431192449,0.273845246172641,-0.787810737570159,-0.385510957258575,-0.281894720950206,0.537213555140211,0.832951572074477,1.03988044344268,-0.129807055624538,-0.0591476158884826,-0.460365190029883,-1.42468105118869,-0.289979529183619,1.31095611184636,-3.67098623611817,-0.55514004820599,-0.123955045299557,-1.99889297049104,-0.383553031278584,0.999475786477637,1.03230983402302,-0.159278387841857,-5.1576266728117,1.69537560610727,1.29286455678085,0.748125626786121,1.39806493177594,-1.88749019335918,-4.00234863713444,-1.28634680497618,0.444956541339119,-0.0002199379866521,0.235831492983495,-1.28970559118716,-1.12049427305432,-4.29066065611674,0.699042522079849,1.05325984810943,2.83025614271582,-0.688860664295587,-0.54589502614551,-0.215371352917759,1.43338202186554,1.3066853960225,0.151283263052917,0.371330451416721,-0.505182011222985,0.150507107990991,0.469781383166897,0.0272539538173025,-0.892398723169813,2.32670771180798,-1.32096899109068,0.179386142350764,-0.233325147374722,0.258373304438679,0.26884286870288,0.0902190662347362,0.255391679696322,-4.21478939184768,-1.2700711897775,-6.7013222332589,-0.537869920416053,-2.84349152162381,1.00686984904641,0.0083540761103252,2.78395686154948,2.26707383348303,0.358499901896443,1.05035517991459,-1.08472451816846,-0.806304161542783,0.916362308314718,1.28009100996168,-0.421787435898091,0.0009986193010034,-1.21279582219431,-1.74911712571452,-1.66789863346922,0.861138884740616,-0.0048183249710915,0.283203969247135,1.79111599543344,1.18949919426491,0.979674031666892,3.67058689267286,-0.694284408026982,-1.50569014245939,-0.179061836319441,-1.66019364851153,-3.12550226522242,-0.681052918571311,0.415116139703453,-2.58816304678763,-1.10883709769699,0.735569495815441,-0.357409779042041,-1.57136153914171,-1.72679404135114,0.422960621106459,0.883701843651683,0.828786964261286,-1.56459977992726,-0.958016110501147,-0.117492525101854,0.173597595219352,1.11500018104507,1.33101254993869,-0.230346675695229,0.205222381564503,-0.846843192888548,-1.22068857289616,-0.233371611900075,-1.74989892910373,-0.476584586017255,0.848043189368033,-2.05529168391975,0.0348915794197302,0.111321696197022,-0.195197182739533,0.941771896773746,-0.430952630904701,0.998563364236628,0.358475808646652,3.14939829224608,-0.682919350829677,-1.40583011624512,-2.69037585851636,0.0295556488881886,-0.463998665104347,-0.533432811067365,1.23235464582969,0.217979827812106,1.25083141074522,1.31808097325688,-1.04968639016844,0.828537257247369,0.303986651793274,-1.10422887749768,-0.655433010406284,0.0338961928217827,-0.636479577658582,0.921722229657323,-0.0318081334341202,-0.561826132660578,-2.05707130098489,0.526279939710425,-3.50565984896473,-4.31317092955023,0.962176922889664,0.921867399813143,-0.774068708287915,0.487481844664075,-5.33442998147911,1.14059752452552,-1.45449377681068,0.94757774201131,-0.303914759646803,0.354062029907008,0.719532741000052,0.981350798114768,1.4260828037032,0.0843365854216652,-0.749387618633821,1.67672720960281,3.05488759085627,1.85372304382719,1.55967295311106,0.338045533680299,-0.765221444360345,0.473077816013397,-0.698047121216126,-0.98774050751679,0.281164665585179,1.07291224802079,1.60315906206145,-0.813457298247516,-0.265364437829375,0.96827529656638,-1.24084822904664,-1.86290531957446,-1.79570512634645,2.20518259563365,0.840075838712625,-1.12375788632213,0.197091720857992,1.38654219607514,-0.706390828065863,0.0704838327773704,-0.492785433058984,-0.0314503325085741,0.629052237930811,1.65237181947361,1.44144444032476,1.41812326990055,0.677114305122622,0.935834472072616,0.23340138735185,-2.14896072870566,1.49150485678254,0.292014404166136,1.65792569555354,0.331587071151496,-0.0126860478765513,0.706040566454597,3.21685095685852,4.61962540185116,1.34218461186089,-0.294175529798448,0.105478395503115,2.29617824944046,-0.954271665893699,0.27762350334459,-2.55560703060359,-0.0468326402133002,-0.0347019512918347,0.111936624310367,0.0331593862938891,1.21779669222041,2.29529837373035,0.202655018299461,0.660328667461514,1.31160861434817,0.937172263850164,1.35727537982145,0.180593456349989,-1.14603485267853,0.518165919501172,-0.781541353019939,1.15036649632921,0.03880076809591,0.0678458879936522,0.253286878578568,-1.40879078001667,2.06149683253478,0.008049314347863,-4.11565268800608,0.496866745812988,-8.99558579115041,-3.87204999289945,-0.824774245853075,0.579378038186027,-0.528414955072736,0.308331869234123,-0.450339257219067,0.0394816685456661,2.13979633024363,-0.482972627114514,0.949853367593469,0.774136596604257,1.05809575573284,-0.124003535547818,1.93422194325501,0.705487317437279,0.226921423088963,0.212967697592384,-0.464878068728155,1.37061913057378,-0.602947670204498,0.705635828898778,-0.230241097471607,1.25017055153989,-0.738638333849812,-0.534910066384916,5.14640414195253,-0.0276665288919688,0.790364203485281,0.343285018814307,1.88560990761428,1.52725912782321,1.13203317880889,-12.5418756802282,-0.476209616975543,-0.389576048901283,0.112872146022207,-0.33059130105668,1.58264621381955,4.30785106414498,0.802948208890463,0.0179905405851439,1.44386362337134,-0.996003222456892,-1.44333524573434,-0.0724984095644677,-2.01845494977419,0.388395462420792,0.925160398991203,0.787339779797896,0.694968432937459,1.00216067189044,-0.0459664763878103,2.60563953892384,0.975817142225953,0.166505112451768,0.128643410183662,-0.135345677869838,0.0391128382244271,0.631078709640344,-0.368349552742064,0.0262741413560445,-2.48544020647002,-0.0866689198139185,1.67943041502349,5.36793836452304,1.44214763100119,0.77053291770848,0.306266129846816,-0.558610531829825,-0.773026660692042,1.98701971073461,0.415883486545098,-0.0610776520819693,1.91892866977249,-0.398389249656593,1.0588232909094,-7.87581549630857,-0.631090569453572,-1.0315153973939,-0.344926540017081,1.22611416219327,-0.989990430039284,1.31177044498585,-0.619572335561426,1.34242048894166,0.889239179821693,-1.0812152436375,-0.363111792377686,0.0005834550621947,-1.56992280547199,1.37423051610531,-0.849333024382971,-0.305366818007106,0.156250377975621,4.59599121984537,-0.917071782183458,1.86862165461269,0.0563010574533621,-0.414220787564603,-0.756339951383187,-0.859713051109423,-1.22860132924012,0.974614721309015,-0.215061049108612,0.837789165859423,0.329961113432019,0.519209158290435,-0.394850670845737,1.30057497478002,1.4392082315988,0.440426273961192,-1.13643105685537,0.0648341309608802,-1.51891544155035,0.541718926792891,1.31869830053118,0.223633557199262,1.27281173569643,0.710994662992385,1.63726583518657,-0.240443123238698,1.07931282095759,1.34300590189136,-0.185498578335175,-1.08541931071127,1.78704444936253,-1.26989404251081,0.569737327437784,-0.95890291632381,3.07652979869269,0.662172230757403,1.16080666483672,1.09709502471832,-2.46014329197146,0.225062315334088,2.61814229418264,-0.10637621775832,0.0885459547376937,-1.26367974061369,-0.868940826219834,-0.662946046501578,1.15913542828521,0.303128919944435,1.02212527966067,0.496830209146534,0.444739038660954,-1.31068418858126,-1.02303120797375,-0.525726564017027,-1.01639324593184,-0.131770527205656,-0.166191208218461,0.171750612060459,0.0349071043493868,1.95199201064158,-3.15730712090228,1.759247460267,1.35836702839758,3.0197404207034,4.13783683497998,4.13246389713003,3.71288929524103,3.80907594667829,2.30089443776603,2.42643280600508,2.00148526626613,3.26158454822833,3.40279371307631,4.09391182702914,4.91785071056565,4.31352332575143,2.66067027657541,2.48195386638743,3.6396539992044,3.44264397684973,1.69569365346656,5.8563932148043,5.79364414692454,0.258555160773118,5.97355569173344,3.91479678866992,4.14198623236944,7.09891625215749,4.19963266902077,2.69386747884008,3.04446910225824,3.10093489093256,7.01671438495857,5.22544230971559,8.28742055534983,8.20479650456012,8.63621438967976,2.90208643306647,0.898474023721059,0.942289402014327,1.11145278248281,9.06761342731767,6.96770866359565,3.85415032971366,6.50318451651946,4.48826730168204,7.47232389650112,7.42136996239257,7.87515679273047,8.32658106147414,8.7759971528627,9.22369194937548,9.66990017304097,10.1148157246654,10.5586001882538,1.33897371069007,10.3939171427504,10.5417508026636,10.8196653713117,1.13014648418496,11.5863805198184,11.8179219897853,12.0958932259299,12.3739891389716,12.6521968313004,12.9305051249875,13.2089042844176,13.4873857909274,13.7659421584186,14.0445667815106,14.3232538097233,14.6019980426299,0.965681439446855,15.3658043803315,-0.0713403777285035,15.5981926625554,15.8769229879536,16.1557014298057,16.4345245512223,16.7133892350242,2.82916799881581,2.60857946990866,3.54975512877325,0.34404807190464,0.885657038258755,1.72873464521162,0.0202179180614602,1.5548897630737,0.416413936043849,1.69987344643198,2.59145816263611,3.13178963278262,1.49126972926361,2.70853541135777,3.36830621710984,4.04560138120513,4.14086717613266,4.51835470349753,4.38289736244467,5.64943864783758,5.77651621042963,-5.19836019923329,-1.64354066791439,1.17950120574809,2.84479469928473,-0.0147931576652609,0.520539361927579,4.10487145129475,3.36734230912012,3.65809481979987,4.51904694695796,5.08369023030901,4.14594361146639,4.57174320411303,4.75051466030858,4.96089229123138,5.38101952251685,6.24165891255794,6.14765332384605,6.61328394324752,5.9183066586857,6.30238478416897,6.26158585106885,6.33288209288301,6.57461542943546,6.72050777097643,6.99038924197379,6.34428045616839,8.07523975163174,8.40142101040258,7.37804241221284,8.58497179585822,1.30021877705413,8.71325017095966,2.978121790406,1.0734990949761,6.15577293013926,9.28684735978866,9.84315322329519,3.35345148012501,2.09815186657166,3.37511020399082,0.963031254092613,1.64804777413239,0.811069300236989,2.42650326490524,0.716241580332591,3.66339525318756,0.355412643473604,2.12231379246165,0.047938380305255,2.30849245367643,1.78649494921925,2.13243062687771,1.05954227713479,0.557090903443645,1.39000150924187,1.44352346510311,2.24411874456383,-1.46426898705405,0.524525772902587,1.39436766175691,1.69422928947167,6.86619841481805,7.09219680097303,7.36554648639464,7.63974510878724,7.91463349246877,-1.63244121283891,0.407227280182074,1.38735982061524,0.417447287721689,1.2176203228402,1.34452078912347,1.26397355628777,1.57357807373238,-0.0008912294816884,0.577609830544052,1.46871292315117,2.39704134824746,2.94820920837905,-3.93073139597263,1.95609915073809,2.72047248689249,2.79103028235041,2.40082554709233,1.81235458422751,2.46267526851135,2.22537994112476,4.54367201286394,5.12575923008793,3.38613996883911,2.01523346310003,1.27139528958141,1.55276821126964,2.22514650025341,3.26466481012305,-3.34843873033788,-6.97642000754641,1.28663756547088,-4.81446073955621,-0.364223121381638,0.581573270980264,0.68382137690334,1.50515204317029,3.1298519330804,2.60772002929222,1.22131743135767,2.50671895922695,-0.285760408166142,-0.0855947885921835,2.94149944882418,2.52282067569291,0.872988038728802,0.962830680816555,-3.4204679837707,-0.571085006532232,1.52483716405302,-0.668973794096954,0.78144226309285,1.39934474808556,0.403326526860602,-0.0454102784513458,-1.30465465035444,12.785970638298,-0.548931183157109,1.13424300279892,1.13723897606434,1.63677796226183,1.13313858781029,-0.457654560738072,1.18975728641634,0.185734554774403,0.194120636801706,-0.257575207100777,1.33566696241079,1.80869795041448,2.36575487772312,0.985632693552081,0.435519332206195,2.34694943137396,3.41891065333381,3.56875123426923,3.48062317879011,3.56342789803106,1.29119504187036,1.15643107873873,1.09486151295003,1.07967115744319,0.608590312773943,1.29185826269199,2.26827061391536,1.43530513012275,2.77308160372497,1.88647569827836,1.03612940153875,1.79064923163963,1.97552752738073,2.42837911824053,3.46288948991687,1.82762056700016,1.26441977404559,-0.802528699267131,2.09615030972986,3.42199090467553,3.92110415204576,3.26657425418237,3.25907610397605,2.92854110729003,2.60912703784891,0.94520635153406,-1.15597800832635,-0.45806896998712,2.63288131193679,0.951966571156228,3.73823496480673,1.55496360697718,2.88180518239049,2.36518252886777,1.63005630331209,3.63344238024837,3.44895257232738,3.25389242362715,4.4011941515981,5.66724730913206,5.43726336227612,5.8907352377921,7.10298492227346,7.1515323543223,5.36741605145469,6.72746568826853,7.25193622855414,7.35214833905529,7.50878980635543,6.1391827154247,6.48309458751086,7.1919501426236,8.21302215295327,7.76395304621262,8.21517673687939,16.497471901867,10.4325276778611,0.0248807914815549,-0.365518405631879,11.6148005425867,12.5721178535385,3.54138524292281,5.42646054559111,4.10787318567637,12.864988563015,12.3525186682391,14.7063346696674,15.53613332478,5.15109356872598,16.6978316913154,-1.09337687781209,19.1672390103062,1.1453810871791,21.4672029942752,1.49695912243222,4.0664132778545,4.06404334190313,3.74030556080113,22.0577289904909,4.35901910783724,4.56964856472544,2.87112058054735,5.22219270751471,5.2133398229232,5.67813391258695,2.50022390414582,2.80929887414381,3.34685000184439,0.650677737498259,2.23275183861699,2.10772866087808,-1.67492805871463,1.08868850191044,1.33351901279168,5.31338185985134,5.52929920087665,2.2756363708417,-7.15904171709445,0.415616496914758,4.43991138307409,1.3422122564916,1.07309853428207,2.99449857558056,1.92765003845063,1.33765782444144,2.76253994253031,2.66427399774238,2.93522576984167,-1.64676405421121,0.0492431315858544,2.48710339519253,1.8564996040552,3.05725030538059,2.28498795250353,2.618584398377,3.22594669094366,-0.51942947320952,-1.23755547027318,1.13347191665669,1.86137334473124,-2.48482353043406,3.14191813880044,1.53170785726036,3.22201046223725,2.09801863238761,3.23806951076392,0.938943680000523,-0.124051888133202,1.7654516187093,1.18363142021427,1.94810044909488,1.74636046414013,-3.95232008590575,-1.24493887246577,1.1001181155631,-0.751792062726136,-0.228062380877632,3.2529263650346,-2.72266032465254,-2.37033515007664,0.76676154669164,1.974141135114,1.86341353532436,0.0992494427033949,1.66171286952217,-0.922135693038651,1.37376948070694,2.07443887131076,3.31249456257958,0.364541282922338,3.67657741239774,2.94382338959853,1.65851450876035,2.84902401493181,1.90580604250552,4.25118050159519,2.79541433019956,2.62973923034009,-0.408409922870926,4.36280068444382,2.72680028914035,0.727831411106392,2.71585507956703,3.68287614423407,3.8467996764866,3.15208420536211,-0.0254646126717458,1.42110000741665,2.37982185248504,0.74533277919767,2.18791662800118,-2.71426804459821,1.06959286384179,1.65909255408015,2.55133767783118,3.32956068110382,3.83594330652809,3.19993870654465,3.29943622098785,3.74859690056241,4.19597576169878,4.64182734988813,1.31042652386526,-0.843910597775511,3.16472117285823,1.40345824321907,3.69877241384725,2.21907469290599,-3.48813018118561,-3.93591892431521,-7.44901515872674,3.04150237620527,4.67255275192187,4.82706041999945,5.26231210944906,2.61710490740972,1.36307703789779,1.32562957435462,3.10670266443901,4.60150558710842,4.86453518123444,0.141547455482355,1.1762702245705,2.50103820829712,4.14718554774299,-7.19697963053735,3.13294449795257,1.51260401518904,1.59682357624614,3.30938527728796,4.70005527392636,0.705607819703042,5.00235242592827,2.71988211593934,3.97788074139497,0.623013013517624,-0.360628009949399,-8.40215367768915,2.36159360978361,-1.13189035724166,-0.757459362256544,2.79318461104641,1.12565266367046,1.28938093711056,1.1263660623459,0.58586417180689,0.158475887304227],\"type\":\"box\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"V2(After)\",\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y\":[0.845049887711819,0.289451215514098,1.11240286511215,-0.304729028381382,2.20260681912487,0.244146827746643,-0.291998470715872,0.107844134081402,1.25755819863272,-0.520790176541268,1.04530218627027,0.0480480404344114,0.810832483494633,-0.982365774608878,1.00810734415515,-0.73496076417937,-0.218979181883603,-1.18013212573691,0.251615559948883,-0.158335153132416,-0.780597577080009,-0.976606515094946,0.628001926863028,0.285336872881923,0.142539767632473,-0.0973665560827295,0.173167880225157,-1.04592907853102,0.305727574143632,-0.201067188363743,-0.600069481773746,-0.139181786113265,0.0932350387312718,-3.05154330777863,1.08040739172587,-0.164416845514618,0.306456586499518,-0.16656777640275,-3.30959883981807,0.208210191167264,-1.5307248973014,0.0535093979504338,-1.37320232381817,0.0767488195849404,0.946692600188286,-1.59395351391978,-1.69799083883406,-0.213970797999707,-1.99475863327522,0.212323245442363,-0.523847557088687,-0.473087274542781,0.419921026881072,-0.281539572919166,0.757838767607048,1.02741320318584,-0.109287298837858,-0.484431343170466,-0.834103103106904,0.626404913442672,-0.31307923022107,1.26562134412589,-1.59307762599303,-1.32952305598059,0.171539673653981,-0.453440471186524,2.18110055117648,-0.0574641145125285,-0.588805841337802,2.30886052896075,0.230973857400454,1.41265322884918,1.32157092478166,1.37978749908678,0.155522126568606,3.35746996910571,1.2441005466941,-0.399043431192449,0.273845246172641,-0.787810737570159,-0.385510957258575,-0.281894720950206,0.537213555140211,0.832951572074477,1.03988044344268,-0.129807055624538,-0.0591476158884826,-0.460365190029883,-1.42468105118869,-0.289979529183619,1.31095611184636,-0.55514004820599,-0.123955045299557,-1.99889297049104,-0.383553031278584,0.999475786477637,1.03230983402302,-0.159278387841857,1.69537560610727,1.29286455678085,0.748125626786121,1.39806493177594,-1.88749019335918,-1.28634680497618,0.444956541339119,-0.0002199379866521,0.235831492983495,-1.28970559118716,-1.12049427305432,0.699042522079849,1.05325984810943,2.83025614271582,-0.688860664295587,-0.54589502614551,-0.215371352917759,1.43338202186554,1.3066853960225,0.151283263052917,0.371330451416721,-0.505182011222985,0.150507107990991,0.469781383166897,0.0272539538173025,-0.892398723169813,-1.32096899109068,0.179386142350764,-0.233325147374722,0.258373304438679,0.26884286870288,0.0902190662347362,0.255391679696322,-1.2700711897775,-0.537869920416053,-2.84349152162381,1.00686984904641,0.0083540761103252,2.78395686154948,2.26707383348303,0.358499901896443,1.05035517991459,-1.08472451816846,-0.806304161542783,0.916362308314718,1.28009100996168,-0.421787435898091,0.0009986193010034,-1.21279582219431,-1.74911712571452,-1.66789863346922,0.861138884740616,-0.0048183249710915,0.283203969247135,1.79111599543344,1.18949919426491,0.979674031666892,3.67058689267286,-0.694284408026982,-1.50569014245939,-0.179061836319441,-1.66019364851153,-3.12550226522242,-0.681052918571311,0.415116139703453,-2.58816304678763,-1.10883709769699,0.735569495815441,-0.357409779042041,-1.57136153914171,-1.72679404135114,0.422960621106459,0.883701843651683,0.828786964261286,-1.56459977992726,-0.958016110501147,-0.117492525101854,0.173597595219352,1.11500018104507,1.33101254993869,-0.230346675695229,0.205222381564503,-0.846843192888548,-1.22068857289616,-0.233371611900075,-1.74989892910373,-0.476584586017255,0.848043189368033,-2.05529168391975,0.0348915794197302,0.111321696197022,-0.195197182739533,0.941771896773746,-0.430952630904701,0.998563364236628,0.358475808646652,-0.682919350829677,-1.40583011624512,-2.69037585851636,0.0295556488881886,-0.463998665104347,-0.533432811067365,1.23235464582969,0.217979827812106,1.25083141074522,1.31808097325688,-1.04968639016844,0.828537257247369,0.303986651793274,-1.10422887749768,-0.655433010406284,0.0338961928217827,-0.636479577658582,0.921722229657323,-0.0318081334341202,-0.561826132660578,-2.05707130098489,0.526279939710425,0.962176922889664,0.921867399813143,-0.774068708287915,0.487481844664075,1.14059752452552,-1.45449377681068,0.94757774201131,-0.303914759646803,0.354062029907008,0.719532741000052,0.981350798114768,1.4260828037032,0.0843365854216652,-0.749387618633821,1.67672720960281,3.05488759085627,1.85372304382719,1.55967295311106,0.338045533680299,-0.765221444360345,0.473077816013397,-0.698047121216126,-0.98774050751679,0.281164665585179,1.07291224802079,-0.813457298247516,-0.265364437829375,0.96827529656638,-1.24084822904664,-1.86290531957446,-1.79570512634645,2.20518259563365,0.840075838712625,-1.12375788632213,0.197091720857992,1.38654219607514,-0.706390828065863,0.0704838327773704,-0.492785433058984,-0.0314503325085741,0.629052237930811,1.65237181947361,1.44144444032476,1.41812326990055,0.677114305122622,0.935834472072616,0.23340138735185,-2.14896072870566,1.49150485678254,0.292014404166136,1.65792569555354,0.331587071151496,-0.0126860478765513,0.706040566454597,3.21685095685852,4.61962540185116,1.34218461186089,-0.294175529798448,0.105478395503115,2.29617824944046,-0.954271665893699,0.27762350334459,-2.55560703060359,-0.0468326402133002,-0.0347019512918347,0.111936624310367,0.0331593862938891,1.21779669222041,2.29529837373035,0.202655018299461,0.660328667461514,1.31160861434817,0.937172263850164,1.35727537982145,0.180593456349989,-1.14603485267853,0.518165919501172,-0.781541353019939,1.15036649632921,0.03880076809591,0.0678458879936522,0.253286878578568,-1.40879078001667,2.06149683253478,0.008049314347863,0.496866745812988,-0.824774245853075,0.579378038186027,-0.528414955072736,0.308331869234123,-0.450339257219067,0.0394816685456661,2.13979633024363,-0.482972627114514,0.949853367593469,0.774136596604257,1.05809575573284,-0.124003535547818,1.93422194325501,0.705487317437279,0.226921423088963,0.212967697592384,-0.464878068728155,1.37061913057378,-0.602947670204498,0.705635828898778,-0.230241097471607,1.25017055153989,-0.738638333849812,-0.534910066384916,5.14640414195253,-0.0276665288919688,0.790364203485281,0.343285018814307,1.88560990761428,1.52725912782321,1.13203317880889,-0.476209616975543,-0.389576048901283,0.112872146022207,-0.33059130105668,1.58264621381955,4.30785106414498,0.802948208890463,0.0179905405851439,1.44386362337134,-0.996003222456892,-1.44333524573434,-0.0724984095644677,-2.01845494977419,0.388395462420792,0.925160398991203,0.787339779797896,0.694968432937459,1.00216067189044,-0.0459664763878103,2.60563953892384,0.975817142225953,0.166505112451768,0.128643410183662,-0.135345677869838,0.0391128382244271,0.631078709640344,-0.368349552742064,0.0262741413560445,-2.48544020647002,-0.0866689198139185,1.67943041502349,5.36793836452304,1.44214763100119,0.77053291770848,0.306266129846816,-0.558610531829825,-0.773026660692042,1.98701971073461,0.415883486545098,-0.0610776520819693,1.91892866977249,-0.398389249656593,1.0588232909094,-0.631090569453572,-1.0315153973939,-0.344926540017081,1.22611416219327,-0.989990430039284,1.31177044498585,-0.619572335561426,1.34242048894166,0.889239179821693,-1.0812152436375,-0.363111792377686,0.0005834550621947,-1.56992280547199,1.37423051610531,-0.849333024382971,-0.305366818007106,0.156250377975621,-0.917071782183458,1.86862165461269,0.0563010574533621,-0.414220787564603,-0.756339951383187,-0.859713051109423,-1.22860132924012,0.974614721309015,-0.215061049108612,0.837789165859423,0.329961113432019,0.519209158290435,-0.394850670845737,1.30057497478002,1.4392082315988,0.440426273961192,-1.13643105685537,0.0648341309608802,-1.51891544155035,0.541718926792891,1.31869830053118,0.223633557199262,1.27281173569643,0.710994662992385,1.63726583518657,-0.240443123238698,1.07931282095759,1.34300590189136,-0.185498578335175,-1.08541931071127,1.78704444936253,-1.26989404251081,0.569737327437784,-0.95890291632381,3.07652979869269,0.662172230757403,1.09709502471832,-2.46014329197146,0.225062315334088,2.61814229418264,-0.10637621775832,0.0885459547376937,-1.26367974061369,-0.868940826219834,-0.662946046501578,1.15913542828521,0.303128919944435,1.02212527966067,0.496830209146534,0.444739038660954,-1.31068418858126,-1.02303120797375,-0.525726564017027,-1.01639324593184,-0.131770527205656,-0.166191208218461,0.171750612060459,0.0349071043493868,1.95199201064158,-3.15730712090228,1.759247460267,1.35836702839758,3.0197404207034,4.13783683497998,4.13246389713003,3.71288929524103,3.80907594667829,2.30089443776603,2.42643280600508,2.00148526626613,3.26158454822833,3.40279371307631,4.09391182702914,4.91785071056565,4.31352332575143,2.66067027657541,2.48195386638743,3.6396539992044,3.44264397684973,1.69569365346656,5.8563932148043,5.79364414692454,0.258555160773118,5.97355569173344,3.91479678866992,4.14198623236944,7.09891625215749,4.19963266902077,2.69386747884008,3.04446910225824,3.10093489093256,7.01671438495857,5.22544230971559,8.28742055534983,8.20479650456012,8.63621438967976,2.90208643306647,0.898474023721059,0.942289402014327,1.11145278248281,6.96770866359565,3.85415032971366,6.50318451651946,4.48826730168204,7.47232389650112,7.42136996239257,7.87515679273047,8.32658106147414,1.33897371069007,1.13014648418496,0.965681439446855,-0.0713403777285035,2.82916799881581,2.60857946990866,3.54975512877325,0.34404807190464,0.885657038258755,1.72873464521162,0.0202179180614602,1.5548897630737,0.416413936043849,1.69987344643198,2.59145816263611,3.13178963278262,1.49126972926361,2.70853541135777,3.36830621710984,4.04560138120513,4.14086717613266,4.51835470349753,4.38289736244467,5.64943864783758,5.77651621042963,-1.64354066791439,1.17950120574809,2.84479469928473,-0.0147931576652609,0.520539361927579,4.10487145129475,3.36734230912012,3.65809481979987,4.51904694695796,5.08369023030901,4.14594361146639,4.57174320411303,4.75051466030858,4.96089229123138,5.38101952251685,6.24165891255794,6.14765332384605,6.61328394324752,5.9183066586857,6.30238478416897,6.26158585106885,6.33288209288301,6.57461542943546,6.72050777097643,6.99038924197379,8.40142101040258,7.37804241221284,8.58497179585822,1.30021877705413,2.978121790406,1.0734990949761,6.15577293013926,3.35345148012501,2.09815186657166,3.37511020399082,0.963031254092613,1.64804777413239,0.811069300236989,2.42650326490524,0.716241580332591,3.66339525318756,0.355412643473604,2.12231379246165,0.047938380305255,2.30849245367643,1.78649494921925,2.13243062687771,1.05954227713479,0.557090903443645,1.39000150924187,1.44352346510311,2.24411874456383,-1.46426898705405,0.524525772902587,1.39436766175691,1.69422928947167,6.86619841481805,7.09219680097303,7.36554648639464,7.63974510878724,7.91463349246877,-1.63244121283891,0.407227280182074,1.38735982061524,0.417447287721689,1.2176203228402,1.34452078912347,1.26397355628777,1.57357807373238,-0.0008912294816884,0.577609830544052,1.46871292315117,2.39704134824746,2.94820920837905,1.95609915073809,2.72047248689249,2.79103028235041,2.40082554709233,1.81235458422751,2.46267526851135,2.22537994112476,4.54367201286394,5.12575923008793,3.38613996883911,2.01523346310003,1.27139528958141,1.55276821126964,2.22514650025341,3.26466481012305,-3.34843873033788,1.28663756547088,-0.364223121381638,0.581573270980264,0.68382137690334,1.50515204317029,3.1298519330804,2.60772002929222,1.22131743135767,2.50671895922695,-0.285760408166142,-0.0855947885921835,2.94149944882418,2.52282067569291,0.872988038728802,0.962830680816555,-0.571085006532232,1.52483716405302,-0.668973794096954,0.78144226309285,1.39934474808556,0.403326526860602,-0.0454102784513458,-1.30465465035444,-0.548931183157109,1.13424300279892,1.13723897606434,1.63677796226183,1.13313858781029,-0.457654560738072,1.18975728641634,0.185734554774403,0.194120636801706,-0.257575207100777,1.33566696241079,1.80869795041448,2.36575487772312,0.985632693552081,0.435519332206195,2.34694943137396,3.41891065333381,3.56875123426923,3.48062317879011,3.56342789803106,1.29119504187036,1.15643107873873,1.09486151295003,1.07967115744319,0.608590312773943,1.29185826269199,2.26827061391536,1.43530513012275,2.77308160372497,1.88647569827836,1.03612940153875,1.79064923163963,1.97552752738073,2.42837911824053,3.46288948991687,1.82762056700016,1.26441977404559,-0.802528699267131,2.09615030972986,3.42199090467553,3.92110415204576,3.26657425418237,3.25907610397605,2.92854110729003,2.60912703784891,0.94520635153406,-1.15597800832635,-0.45806896998712,2.63288131193679,0.951966571156228,3.73823496480673,1.55496360697718,2.88180518239049,2.36518252886777,1.63005630331209,3.63344238024837,3.44895257232738,3.25389242362715,4.4011941515981,5.66724730913206,5.43726336227612,5.8907352377921,7.10298492227346,7.1515323543223,5.36741605145469,7.35214833905529,6.1391827154247,6.48309458751086,7.1919501426236,0.0248807914815549,-0.365518405631879,3.54138524292281,5.42646054559111,4.10787318567637,5.15109356872598,-1.09337687781209,1.1453810871791,1.49695912243222,4.0664132778545,4.06404334190313,3.74030556080113,4.35901910783724,4.56964856472544,2.87112058054735,5.22219270751471,5.2133398229232,5.67813391258695,2.50022390414582,2.80929887414381,3.34685000184439,0.650677737498259,2.23275183861699,2.10772866087808,-1.67492805871463,1.08868850191044,1.33351901279168,5.31338185985134,5.52929920087665,2.2756363708417,0.415616496914758,4.43991138307409,1.3422122564916,1.07309853428207,2.99449857558056,1.92765003845063,1.33765782444144,2.76253994253031,2.66427399774238,2.93522576984167,-1.64676405421121,0.0492431315858544,2.48710339519253,1.8564996040552,3.05725030538059,2.28498795250353,2.618584398377,3.22594669094366,-0.51942947320952,-1.23755547027318,1.13347191665669,1.86137334473124,-2.48482353043406,3.14191813880044,1.53170785726036,3.22201046223725,2.09801863238761,3.23806951076392,0.938943680000523,-0.124051888133202,1.7654516187093,1.18363142021427,1.94810044909488,1.74636046414013,-1.24493887246577,1.1001181155631,-0.751792062726136,-0.228062380877632,3.2529263650346,-2.72266032465254,-2.37033515007664,0.76676154669164,1.974141135114,1.86341353532436,0.0992494427033949,1.66171286952217,-0.922135693038651,1.37376948070694,2.07443887131076,3.31249456257958,0.364541282922338,3.67657741239774,2.94382338959853,1.65851450876035,2.84902401493181,1.90580604250552,4.25118050159519,2.79541433019956,2.62973923034009,-0.408409922870926,4.36280068444382,2.72680028914035,0.727831411106392,2.71585507956703,3.68287614423407,3.8467996764866,3.15208420536211,-0.0254646126717458,1.42110000741665,2.37982185248504,0.74533277919767,2.18791662800118,-2.71426804459821,1.06959286384179,1.65909255408015,2.55133767783118,3.32956068110382,3.83594330652809,3.19993870654465,3.29943622098785,3.74859690056241,4.19597576169878,4.64182734988813,1.31042652386526,-0.843910597775511,3.16472117285823,1.40345824321907,3.69877241384725,2.21907469290599,3.04150237620527,4.67255275192187,4.82706041999945,5.26231210944906,2.61710490740972,1.36307703789779,1.32562957435462,3.10670266443901,4.60150558710842,4.86453518123444,0.141547455482355,1.1762702245705,2.50103820829712,4.14718554774299,3.13294449795257,1.51260401518904,1.59682357624614,3.30938527728796,4.70005527392636,0.705607819703042,5.00235242592827,2.71988211593934,3.97788074139497,0.623013013517624,-0.360628009949399,2.36159360978361,-1.13189035724166,-0.757459362256544,2.79318461104641,1.12565266367046,1.28938093711056,1.1263660623459,0.58586417180689,0.158475887304227],\"type\":\"box\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"V10(Before)\",\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y\":[-0.255273958239804,-0.0928539979788115,-0.506742534469509,-0.280493243493316,1.59662294123342,-0.240603346477903,-0.0586729488008763,0.894620785734476,-0.242868217662484,1.38350639766463,-0.487015959032126,-0.218095609483542,-0.405060915681314,0.372110964894735,0.337892033311262,0.0742368347001196,-0.289483617400492,0.543682474996253,-0.0115878328334377,-0.0439224931420598,-0.126066729720131,-0.0531030002317168,-1.73935225838159,-0.362475329471615,-0.168497563220977,0.237887540464979,-0.269431545765108,1.59444921535243,-2.07046599491831,-0.385237252608171,0.310625568047008,0.374570833548577,5.07581160144947,1.53369685873752,1.39490743123491,-0.322810277016426,-0.0094594123049049,1.37406955146918,-0.640789725789507,1.82540582501842,0.264940313085133,-0.139213220362173,1.45860454027996,0.418115895641417,1.59780161989336,0.0410578634128881,0.102687882469948,0.577055703419997,9.10140231365335,1.66017037015848,-0.0695705242129999,0.250563787350261,-0.653993402662188,0.0618001805457699,-0.156473116097762,0.149867322233335,-0.221027498349529,0.0184789618260173,0.16874388675372,-0.202082067757013,0.312721387383848,0.227320069365873,1.42685913255743,-0.535326684500969,-1.45249858044069,0.6553578576772,-0.930526103560306,-0.23185944985589,-0.400443850094627,-0.0646995868481641,-1.30729214497853,0.173970645474375,0.415208464708831,0.150089357294978,2.09675419791919,-0.85430901915284,0.141193554144417,-0.104207981515626,-1.0599978531915,-1.31549734554743,-0.145362051936295,0.941887775061909,0.340143329570071,0.581757335116438,0.0986473013393894,0.205475715810327,-0.924797983299299,-0.743767492129238,0.293542023370123,-0.0025820145852291,0.827958775499167,0.710464929456466,-1.45729556077223,-0.364770800251102,0.0991709612660929,-0.343898236292434,-0.615521351885592,1.28925975519844,-0.0299624705927027,-0.668458458963198,-0.112070202210729,0.0669552530839356,0.934328336874205,2.15100936370979,-0.910101992531359,-0.654887760423994,-0.0379593621913622,-0.904076081002724,0.117444473868926,0.180582209139978,-0.872577150527372,-0.221985823902143,-0.891155799226471,-0.191994713100395,-0.65360101789277,-0.0114306249467935,0.876755573354196,-0.855542926048439,-0.0950558909755218,-0.0541472926097911,0.254421084184031,0.248993543659246,-0.754311041927401,0.798967535338367,-0.142538697569217,-1.11653693059002,0.367741013247022,-0.141170775515064,-0.596475034173662,-0.121340989125647,0.682118318356352,5.88572751121879,1.05727890809409,0.310005861525613,-0.0522167753187611,-0.567592257530486,0.482235865217335,-0.211787100348309,-0.681341868529104,-0.265223275974536,1.85881186173652,-1.1969679253598,-0.514375015529248,0.655067197703941,0.664215156409321,0.652200737872322,-0.747502123905551,1.98699685834469,1.42897152295056,-0.788457496225903,1.3716631691187,-0.110586045068072,-0.653834307413683,-0.795182545447338,0.0456519333079763,0.0540714035398653,0.932414188420879,-2.0390220039165,1.57362373538046,-1.07204992070877,0.0556042796233514,-0.589886900421184,-2.01716975046735,-0.632707056551981,-0.1413656977412,2.9805133951192,0.311152117202867,1.63795553980724,0.203680854091231,-0.147487162813619,-0.675251768897319,0.927131740430615,-0.98691564240897,-2.67399025535519,0.297237905166168,-1.30586759057276,-0.0352043720365089,-0.536392783484399,-0.154839543963811,1.01968462660013,0.168897316932779,-1.87694744577874,-0.644305704201013,1.27830734147995,-0.0626578446907844,-0.0905919459983964,-0.540862578759865,-0.215988118377487,-1.46873261954432,0.0354872599302482,0.0757723552776566,0.982557679713825,-0.283324608832411,-0.5035142022015,-0.482063399440104,-0.161058112821394,-1.19982544096918,-0.53771574450754,0.0776678044851743,0.31279393701936,-0.168148219860413,0.0884810096929745,-0.562294297930397,0.997131264519238,5.50542383997804,1.28235043157865,0.868640039413523,-0.666919922578831,-0.490352568540929,-0.287141589024009,-0.436288495792005,-0.547437541142792,-0.369827698540688,0.133609816709407,-0.236416590590578,1.61305297655354,0.176385359502364,0.158531330463264,-0.119688935167779,-1.82440358156673,-0.518258784764837,-0.213183133437208,0.136689451429382,0.0077581380657732,1.38595005574929,0.801324651820405,-1.49786802934524,0.380999161540494,1.52757567208582,-0.0472496402062155,0.352714478020412,-0.563587808722992,-0.0859690431699648,3.03668012699189,0.343252963095731,1.56660139919438,-0.562504715505505,-0.181805502050558,-0.133870322249673,-0.792222108957813,-0.380986780526359,-1.35324639195409,-1.50597238453434,-0.060581075168387,-1.35527932899159,0.99086244029942,-0.869751927035036,1.22475436920873,-0.351149629278644,-0.0838023568308136,1.36664838455401,-0.540827689624106,0.414791018643661,-0.25142560305247,-0.552122628808136,5.27016227887576,0.72545246686889,-1.25648104790313,0.042834788478388,0.903058724018,-0.805109176160932,1.66340720225537,-0.0998412659078283,-1.14658862052044,-1.54066990242807,-1.2962643718892,1.06465008601382,-0.214376144972515,0.305645410937554,-0.0893714824232083,-0.109013867332819,-0.668564110712268,0.93261165387525,0.374074994715684,-0.0346987030163679,0.011260528658166,0.681013120463851,-0.0568972023574938,0.666875958028246,0.189237672030759,-0.946419928154515,-0.246114828727906,-0.290331355019222,0.449822021541495,-0.134690662403866,-0.101014914274412,3.31582344300788,-0.659179751865576,-0.0642842618444655,0.0157874869725683,-0.754306400721832,0.311568135370157,0.61395343271394,-0.998844050501635,-0.261999580401242,0.161219295666546,-1.23110141699323,0.355362481317308,0.164697018433082,1.39174908402523,-0.721615972702225,-1.35941234198336,0.856381699827864,0.736298917479387,-1.75552690031177,-0.318560760554698,0.721686688376445,-0.719273921657274,0.474441496086289,-0.497042943139737,-0.185049360062573,-0.166805153055343,0.0101784181364132,-0.547341039533318,2.38038623620284,-0.609459521359164,-2.63486561034371,1.48217389838381,1.45345528684656,0.498064092986705,0.735048392073043,-1.01935811668867,1.52608249039995,-0.271961912543022,-0.138990011935536,0.105914500943093,-0.756818525052203,-1.0222802511057,-0.672787259229256,-0.109330622123087,0.156839782516295,-0.0653943458803409,1.76181658439871,-0.79980713602313,0.526088345100987,-0.491847125415923,0.291183341288389,-0.0715561011148179,-0.133858505895965,-0.0321756360747781,-0.211659664532547,-1.18614504158933,0.940250475333811,0.473522005473131,1.16680509669726,-0.111536972908599,-0.696445461974875,0.535837128295189,0.0737286807971917,-0.0878840550451482,-1.29651028243989,-0.524967771613691,0.277317116654598,0.0363191821537957,-0.375168240160033,-0.320945045076564,-0.257872850162351,-0.177803660458635,-0.326137241145112,0.1717840250879,-0.213595657227243,0.658871569018348,-0.622529944349028,-0.141765142925941,1.3704584957483,-0.980371928917778,-1.07700246322299,-0.610550424979896,-0.353688701091747,-0.307581863592739,-0.224101870230961,0.106750489600496,-0.151237572416339,-0.594233681032627,-0.221473380746281,0.25786055999785,-0.628371721038911,-0.0554325281298101,-1.47653068660631,0.0440001964101087,-0.781925525065389,0.0190542092810508,0.978870104191748,3.62073929009464,-1.04156716798929,-0.771896815635902,-0.468516883299827,1.21196260556796,-1.07388844418687,-1.28956407967086,-1.85848998881825,0.0780498901586222,0.138605772072966,0.0207265915975273,-0.847810238211724,2.16833779332242,0.935760343750861,-0.134501389775699,-0.568591032594727,-0.71968687478541,1.89090040005192,-0.199739058944673,1.51491420363072,0.3998329485202,-0.425770621476461,1.36710785828188,-0.127829109573802,0.094206154933421,0.825779491285219,-0.386443786193979,0.637395943812408,-1.53860729857193,0.0541565158500923,6.44959910333463,-0.45111900019455,0.285130669296366,0.0305966424670315,-1.33960116283389,0.952649693503947,0.749213289005596,0.763437091314491,-0.644197522161548,0.0346696145749799,-0.931147978046506,-0.336603342610386,0.187717127875285,0.668310195718139,0.364818310689195,0.281060675896377,0.167758422980316,-0.788094542821684,-0.195047640517074,1.72309535594312,1.58613191452435,-1.19794800830463,-0.298910430993942,-1.11582335876278,-1.08472738006424,-0.588066834490181,-0.240163017673633,-0.390336730883327,0.476764960988977,-0.605479965574277,0.820711196261342,-1.00975588429371,0.791205228827329,-0.860548094135987,0.493968806673843,0.867942077303421,-0.807203600658299,4.84161826566741,-0.35285428833362,-0.453004462641366,-1.14467356767594,3.72950425722278,-0.621453792615932,0.626555262280831,1.33437888503267,0.684518653021879,-0.0820380660475477,0.204352272032034,-0.270069025570517,-0.478732535199045,-0.540878187655186,-1.09969786394776,1.18833533204376,0.762813538152001,-0.19496753473537,-0.160578102267125,-0.367891934059413,-0.442551139202479,-0.403368660499304,-0.0211102824318283,-2.77227214465915,-0.838586564582682,-1.52541162656194,-4.80163740602813,-2.44746925511151,-6.18789062970647,-6.04546779778801,-5.13445447110633,-4.95949291161496,-4.62498495406596,-5.00924850212751,-3.95581234352737,-6.23456133227108,-6.19988176274188,-3.94423849794435,-7.45484065078351,-6.81081309938215,-5.52627805985834,-5.3903302556601,-6.7167200227127,-6.99990663386522,-5.57602263642415,-7.19160424618226,-7.29780335001461,-1.9877731876087,-12.8409338181318,-5.15309460989926,-11.4204509744097,-13.1934150665232,-4.13784019622865,-4.59495176285009,-4.13889121357616,1.01511287978593,-11.853866972601,-11.5619497720699,-13.1366983691039,-11.7971810675777,-11.7121866242875,1.07741752106048,-0.592472935320844,-0.554223900525873,-0.164562674892883,-11.6271935556579,-11.7868116556041,-11.2014000859835,-13.6705451263516,-12.9389293107706,-14.166794659606,-13.3482776536659,-13.2616517082667,-13.175198078736,-13.0888909176936,-13.0027093010697,-12.9166361091709,-12.8306571996417,-12.7447607871859,-0.859862301810301,-9.66878891236125,-9.22282550730978,-9.15336803834587,-0.369908966047961,-9.04039624894471,-8.9286556608751,-8.85919405880884,-8.78972336330438,-8.72024451506225,-8.6507583293562,-8.58126551626339,-8.51176669710133,-8.44226241787632,-8.37275316035861,-8.303239351259,-8.233721369876,-3.46568908576121,-8.12096173759343,-3.65142656863483,-8.00915938639777,-7.93964241937325,-7.87012194292549,-7.80059820772759,-7.7310714411342,-1.88484243991678,-2.33593332652232,-4.59238980599474,-2.89525166830126,3.24508640095346,-2.73415555507211,-3.58281002008802,-2.13317644293659,0.644549730341658,-2.83487115980611,-3.71744992918956,-7.06074618169306,-0.121653217684609,-3.55198400939375,-6.0677981503786,-6.31970750896333,-6.54624181523522,-6.60046062150676,-7.52436833681058,-7.8335555711125,-7.50211219093686,-0.794993881662565,-1.96530880945923,-1.95980925751416,-2.04216786301424,-3.97652513857503,-3.05121035544102,-13.6913151328525,-5.29061006200618,-4.46628416302479,-11.2981564915382,-11.1412776902967,-11.435623996076,-12.981619145004,-11.6344144245911,-11.5198609264142,-11.589748311433,-12.2653238444006,-13.3866834395246,-13.2151722995049,-12.8881582878915,-12.8056831898117,-13.6081431627279,-12.8357376825339,-13.0740681657723,-12.6959474039839,-12.7806339362021,-14.6764702497464,-15.1241628144947,-14.2266980575287,-13.0094028057641,-14.1101844415457,-3.22678710680364,-14.5571590528859,-4.75830407509117,-4.15583783449678,-6.40337055173194,-16.6496281595399,-18.2711681738888,-5.69992228265959,-4.07758540918968,-4.56525209408734,-7.14219911358407,-7.78135276287243,-2.96199570179906,-4.98092843827312,-1.25028553742691,-5.72681709632961,-1.48124586053984,-2.97526724837752,-0.792937990748917,-2.75579692797163,-3.84391103993778,-3.36401057980002,-0.55054534794377,-0.585778431385528,-0.433393925731893,-3.50579032571994,-3.94238290411726,0.225933803313285,-0.552902906422504,-2.49561924548174,-2.89261176082088,-6.24624318477127,-6.13490688724113,-6.06578236274727,-5.99659592015915,-5.92735916911943,-0.150129182778684,-0.283731283967387,-3.09650359868717,-0.0450882478448673,-3.09509360697848,-2.9966693020716,-2.70501138232752,-5.45960189444545,1.01029102209398,-7.14513662527302,-8.12216107491307,-8.33286306292127,-8.40315026242229,-0.0492328559624844,-3.24510859732028,-7.74848004950582,-7.86450647898838,-5.97492543825504,-3.55583492739064,-4.88114292689057,-5.71150474047788,-9.33212806886128,-6.77833138248069,-2.8084555425423,-3.07669858515182,-0.867899742347565,-3.39355348115172,-4.17062288702767,-3.28820356526528,-4.35068531246963,-4.00174208524931,-3.23678401592309,-3.42605225253339,-3.25263359468289,-3.55038539904852,-2.30110989675506,0.169572797878818,-4.15369240632128,-3.83477508791878,-2.12697274994354,-4.83482799462627,-3.9905513318108,-0.0913533730643921,-5.11725920989043,-3.16213595485783,-0.157696445821874,-0.194120466505581,-3.62477471396623,-0.371671945168217,-4.32053577559936,0.264544748886681,-2.85611682977408,-2.65971794652165,-3.95100289197434,-1.7690597207318,0.517567879914365,-5.05250236713858,0.54318725600578,-1.87964382107016,-4.7117686842189,-2.89499040084744,-4.05629261571005,-5.03202838566819,0.324238886093679,-4.99341703829647,-4.68423332514029,0.334532824069685,-3.9433368210052,-3.53865023182429,-2.9989262562074,-1.03963769713185,0.166830707878014,-5.51550707258062,-6.44720227383046,-6.28780335064533,-6.56125741097377,-6.8254901042394,-2.15530254380865,-2.10066651278309,-1.92527812380296,-2.544410418956,-1.02533539256113,-2.15251889070952,-4.62691916410905,-2.23120932812687,-6.26070551479114,-3.8337413849476,0.269561809170344,-1.88617599041763,-2.9328952580311,-5.63894131284807,-8.0991193981365,-8.33770697381781,-8.74597261185534,-0.71347376073502,-3.99521073403213,-8.40966487562735,-8.53775768653457,-6.2133552491157,-6.35388725151755,-5.99567612703198,-5.822449155685,-2.06990438955593,-0.133950251206468,1.987861862693,-3.93629417027159,0.541699242973355,0.369936028027435,-4.15635447965382,-4.72309174576035,-3.37617706712688,-2.8290982053899,-3.71748137540216,-4.09564897273592,-5.56794705115052,-13.540168238225,-12.0111608836062,-11.2350479111446,-11.1821254546586,-12.9654812039222,-13.3207888671784,-11.0923923688428,-15.2399619587112,-14.9246547735487,-13.2025771482197,-15.5637913387301,-12.4389449056023,-14.5331616869738,-12.618162687238,-16.7460441053944,-15.3460988468775,-15.1237521803455,-22.1870885620007,-17.1415136412892,0.912806096143303,-0.357616193093852,-16.3035376590131,-16.2556117491401,-2.85032390160027,-5.66586179854092,-6.62569249371823,-16.6011969664137,-15.2318333653018,-18.9132433348732,-20.9491915543611,-0.870997150804889,-19.836148851696,1.78592177154007,-23.2282548357516,-4.4318096317282,-24.4031849699728,-4.36310219273296,-6.68368922880726,-8.99381088354112,-6.80713525144464,-24.5882624372475,-7.17534972178322,-7.57563437993936,-5.11072764247853,-7.33437708370839,-6.86850850672582,-6.86416435989436,-4.51390660472333,-4.54693575081085,-4.45800770078481,1.07295520625891,-5.20833459337633,-5.62467713431414,1.7837390603636,-3.51413330486723,-4.54261203828437,0.453505060416619,0.566679814004086,-4.82077941422469,-1.53160798206082,-2.77674714436829,-4.89115620289902,-3.15812700566592,0.0422275201898101,-2.27673307339047,-3.21618771830464,-4.5652600954372,-1.4706452575308,-2.29773425918487,-5.48742458295368,-0.0844995591396119,1.71353755281029,-2.9716952359177,-3.90674573293228,-3.8517216648754,-3.22455914814995,-5.56914249554635,-5.83645272742826,-1.4294901237515,0.0856615347524881,-2.24811517395215,-2.31474716368481,-3.73965947930309,-3.89824038104731,-2.64940583024547,-2.27152578398956,-3.07403431268054,-4.07025686324581,-3.52012767367189,-0.989431189994817,-3.8410981507899,-5.17993471366321,-4.50131480977758,-6.56465926230671,4.03143505114991,-4.25071651144568,-5.41603688884657,0.217630453611954,-6.42823083022309,-1.34755671450971,-5.11297108805175,-5.16533081830893,-0.159325098707444,-0.0451253297662453,-0.423783865294484,-4.93742665954554,-3.07555830950402,-3.75405392305562,0.955004466801798,-2.73279196653765,-5.6536376856402,-4.61450773315675,-4.40092985049667,-6.54098852025393,-7.04922935969585,-4.06309810827338,-0.628463195272087,-4.85148719411703,-4.91934829935247,-0.887241636246378,-1.44537495699985,-6.28542447506796,-3.20243612238872,-3.41920738405664,-1.87333085278999,-4.81640080035747,-5.17565967956169,-3.89016924226376,-2.63744174460075,-3.23543895742654,-3.26300672553831,0.398155064675901,-4.48548270396242,-2.79633153858609,-0.373927299894818,-3.50892466189359,-4.75993137385013,-3.99178463209724,-4.86874726825181,-3.47341070390428,-2.49756054724841,-2.4112720149303,-2.32511344137919,-2.23906626105695,1.28016674259048,-1.47497416110315,-2.12045759469323,-3.35647371355361,-4.23098383571181,-3.44381902213252,-4.44148408070017,-1.13445381068391,-4.02912871953916,-4.70757080611204,-5.57641879575659,-5.25809597551632,-5.17281182346005,-3.92650993997042,0.228849430580481,0.259411077154011,-5.9548382969224,-6.64615382952148,-5.5334430286147,-1.61361833850235,1.08151398923906,-3.06472953093127,-3.96322447209244,-3.27256917385192,-2.22307032799021,-1.67234597814111,-2.16206139007752,-5.33475387061743,-6.12071508667922,-1.00080505203989,-5.94563397292191,-4.5335154033258,-7.50955747436829,-5.52913123107677,-0.39438126178315,2.68866993252224,-2.5166280017922,1.33441406239882,0.24931080342673,-4.39084192218279,-5.58779378195338,-3.23215317539514,-3.46389087904573,-5.24598383776964,-0.888721675865145],\"type\":\"box\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"name\":\"V10(After)\",\"x\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y\":[-0.255273958239804,-0.0928539979788115,-0.506742534469509,-0.280493243493316,1.59662294123342,-0.240603346477903,-0.0586729488008763,0.894620785734476,-0.242868217662484,1.38350639766463,-0.487015959032126,-0.218095609483542,-0.405060915681314,0.372110964894735,0.337892033311262,0.0742368347001196,-0.289483617400492,0.543682474996253,-0.0115878328334377,-0.0439224931420598,-0.126066729720131,-0.0531030002317168,-1.73935225838159,-0.362475329471615,-0.168497563220977,0.237887540464979,-0.269431545765108,1.59444921535243,-2.07046599491831,-0.385237252608171,0.310625568047008,0.374570833548577,1.53369685873752,1.39490743123491,-0.322810277016426,-0.0094594123049049,1.37406955146918,1.82540582501842,0.264940313085133,-0.139213220362173,1.45860454027996,0.418115895641417,1.59780161989336,0.0410578634128881,0.102687882469948,0.577055703419997,1.66017037015848,-0.0695705242129999,0.250563787350261,-0.653993402662188,0.0618001805457699,-0.156473116097762,0.149867322233335,-0.221027498349529,0.0184789618260173,0.16874388675372,-0.202082067757013,0.312721387383848,0.227320069365873,1.42685913255743,-0.535326684500969,-1.45249858044069,0.6553578576772,-0.930526103560306,-0.23185944985589,-0.400443850094627,-0.0646995868481641,-1.30729214497853,0.173970645474375,0.415208464708831,0.150089357294978,2.09675419791919,-0.85430901915284,0.141193554144417,-0.104207981515626,-1.0599978531915,-1.31549734554743,-0.145362051936295,0.941887775061909,0.340143329570071,0.581757335116438,0.0986473013393894,0.205475715810327,-0.924797983299299,-0.743767492129238,0.293542023370123,-0.0025820145852291,0.827958775499167,0.710464929456466,-1.45729556077223,-0.364770800251102,-0.343898236292434,-0.615521351885592,1.28925975519844,-0.0299624705927027,-0.668458458963198,-0.112070202210729,0.0669552530839356,2.15100936370979,-0.910101992531359,-0.654887760423994,-0.0379593621913622,-0.904076081002724,0.180582209139978,-0.872577150527372,-0.221985823902143,-0.891155799226471,-0.191994713100395,-0.65360101789277,0.876755573354196,-0.855542926048439,-0.0950558909755218,-0.0541472926097911,0.254421084184031,0.248993543659246,-0.754311041927401,0.798967535338367,-0.142538697569217,-1.11653693059002,0.367741013247022,-0.141170775515064,-0.596475034173662,-0.121340989125647,0.682118318356352,1.05727890809409,0.310005861525613,-0.0522167753187611,-0.567592257530486,0.482235865217335,-0.211787100348309,-0.681341868529104,1.85881186173652,-0.514375015529248,0.655067197703941,0.664215156409321,0.652200737872322,-0.747502123905551,1.98699685834469,1.42897152295056,-0.788457496225903,1.3716631691187,-0.110586045068072,-0.653834307413683,-0.795182545447338,0.0456519333079763,0.0540714035398653,0.932414188420879,-2.0390220039165,1.57362373538046,-1.07204992070877,0.0556042796233514,-0.589886900421184,-2.01716975046735,-0.632707056551981,-0.1413656977412,2.9805133951192,0.311152117202867,1.63795553980724,0.203680854091231,-0.147487162813619,-0.675251768897319,0.927131740430615,-0.98691564240897,-2.67399025535519,0.297237905166168,-1.30586759057276,-0.0352043720365089,-0.536392783484399,-0.154839543963811,1.01968462660013,0.168897316932779,-1.87694744577874,-0.644305704201013,1.27830734147995,-0.0626578446907844,-0.0905919459983964,-0.540862578759865,-0.215988118377487,-1.46873261954432,0.0354872599302482,0.0757723552776566,0.982557679713825,-0.283324608832411,-0.5035142022015,-0.482063399440104,-0.161058112821394,-1.19982544096918,-0.53771574450754,0.0776678044851743,0.31279393701936,-0.168148219860413,0.0884810096929745,-0.562294297930397,0.997131264519238,1.28235043157865,0.868640039413523,-0.666919922578831,-0.490352568540929,-0.287141589024009,-0.436288495792005,-0.547437541142792,-0.369827698540688,0.133609816709407,-0.236416590590578,1.61305297655354,0.176385359502364,0.158531330463264,-0.119688935167779,-1.82440358156673,-0.518258784764837,-0.213183133437208,0.136689451429382,0.0077581380657732,1.38595005574929,0.801324651820405,-1.49786802934524,-0.0472496402062155,0.352714478020412,-0.563587808722992,-0.0859690431699648,0.343252963095731,1.56660139919438,-0.562504715505505,-0.181805502050558,-0.133870322249673,-0.792222108957813,-0.380986780526359,-1.35324639195409,-1.50597238453434,-0.060581075168387,-1.35527932899159,0.99086244029942,-0.869751927035036,1.22475436920873,-0.351149629278644,-0.0838023568308136,1.36664838455401,-0.540827689624106,0.414791018643661,-0.25142560305247,-0.552122628808136,0.72545246686889,-1.25648104790313,0.042834788478388,0.903058724018,-0.805109176160932,1.66340720225537,-0.0998412659078283,-1.14658862052044,-1.54066990242807,-1.2962643718892,1.06465008601382,-0.214376144972515,0.305645410937554,-0.0893714824232083,-0.109013867332819,-0.668564110712268,0.93261165387525,0.374074994715684,-0.0346987030163679,0.011260528658166,0.681013120463851,-0.0568972023574938,0.666875958028246,0.189237672030759,-0.946419928154515,-0.246114828727906,-0.290331355019222,0.449822021541495,-0.134690662403866,-0.101014914274412,3.31582344300788,-0.659179751865576,-0.0642842618444655,0.0157874869725683,-0.754306400721832,0.311568135370157,0.61395343271394,-0.998844050501635,-0.261999580401242,0.161219295666546,-1.23110141699323,0.355362481317308,0.164697018433082,1.39174908402523,-0.721615972702225,-1.35941234198336,0.856381699827864,0.736298917479387,-1.75552690031177,-0.318560760554698,0.721686688376445,-0.719273921657274,0.474441496086289,-0.497042943139737,-0.185049360062573,-0.166805153055343,0.0101784181364132,-0.547341039533318,2.38038623620284,-0.609459521359164,1.48217389838381,0.735048392073043,-1.01935811668867,1.52608249039995,-0.271961912543022,-0.138990011935536,0.105914500943093,-0.756818525052203,-1.0222802511057,-0.672787259229256,-0.109330622123087,0.156839782516295,-0.0653943458803409,1.76181658439871,-0.79980713602313,0.526088345100987,-0.491847125415923,0.291183341288389,-0.0715561011148179,-0.133858505895965,-0.0321756360747781,-0.211659664532547,-1.18614504158933,0.940250475333811,0.473522005473131,1.16680509669726,-0.111536972908599,-0.696445461974875,0.535837128295189,0.0737286807971917,-0.0878840550451482,-1.29651028243989,0.277317116654598,0.0363191821537957,-0.375168240160033,-0.320945045076564,-0.257872850162351,-0.177803660458635,-0.326137241145112,0.1717840250879,-0.213595657227243,0.658871569018348,-0.622529944349028,-0.141765142925941,1.3704584957483,-0.980371928917778,-1.07700246322299,-0.610550424979896,-0.353688701091747,-0.307581863592739,-0.224101870230961,0.106750489600496,-0.151237572416339,-0.594233681032627,-0.221473380746281,0.25786055999785,-0.628371721038911,-0.0554325281298101,-1.47653068660631,0.0440001964101087,-0.781925525065389,0.0190542092810508,0.978870104191748,3.62073929009464,-1.04156716798929,-0.771896815635902,-0.468516883299827,1.21196260556796,-1.07388844418687,-1.28956407967086,-1.85848998881825,0.0780498901586222,0.138605772072966,0.0207265915975273,-0.847810238211724,0.935760343750861,-0.134501389775699,-0.568591032594727,-0.71968687478541,1.89090040005192,-0.199739058944673,1.51491420363072,0.3998329485202,-0.425770621476461,1.36710785828188,-0.127829109573802,0.094206154933421,0.825779491285219,-0.386443786193979,0.637395943812408,-1.53860729857193,0.0541565158500923,-0.45111900019455,0.285130669296366,0.0305966424670315,-1.33960116283389,0.952649693503947,0.749213289005596,0.763437091314491,-0.644197522161548,0.0346696145749799,-0.931147978046506,-0.336603342610386,0.187717127875285,0.668310195718139,0.364818310689195,0.281060675896377,0.167758422980316,-0.788094542821684,-0.195047640517074,1.72309535594312,1.58613191452435,-1.19794800830463,-0.298910430993942,-1.11582335876278,-1.08472738006424,-0.588066834490181,-0.240163017673633,-0.390336730883327,0.476764960988977,-0.605479965574277,0.820711196261342,-1.00975588429371,0.791205228827329,-0.860548094135987,0.493968806673843,0.867942077303421,-0.807203600658299,-0.35285428833362,-0.453004462641366,-1.14467356767594,3.72950425722278,-0.621453792615932,0.626555262280831,1.33437888503267,0.684518653021879,-0.0820380660475477,0.204352272032034,-0.270069025570517,-0.478732535199045,-0.540878187655186,-1.09969786394776,1.18833533204376,0.762813538152001,-0.19496753473537,-0.160578102267125,-0.367891934059413,-0.442551139202479,-0.403368660499304,-0.0211102824318283,-2.77227214465915,-0.838586564582682,-1.52541162656194,-4.80163740602813,-2.44746925511151,-6.18789062970647,-6.04546779778801,-5.13445447110633,-4.95949291161496,-4.62498495406596,-5.00924850212751,-3.95581234352737,-6.23456133227108,-6.19988176274188,-3.94423849794435,-7.45484065078351,-6.81081309938215,-5.52627805985834,-5.3903302556601,-6.7167200227127,-6.99990663386522,-5.57602263642415,-7.19160424618226,-7.29780335001461,-1.9877731876087,-12.8409338181318,-5.15309460989926,-11.4204509744097,-13.1934150665232,-4.13784019622865,-4.59495176285009,-4.13889121357616,1.01511287978593,-11.853866972601,-11.5619497720699,-13.1366983691039,-11.7971810675777,-11.7121866242875,1.07741752106048,-0.592472935320844,-0.554223900525873,-0.164562674892883,-11.7868116556041,-11.2014000859835,-13.6705451263516,-12.9389293107706,-14.166794659606,-13.3482776536659,-13.2616517082667,-13.175198078736,-0.859862301810301,-0.369908966047961,-3.46568908576121,-3.65142656863483,-1.88484243991678,-2.33593332652232,-4.59238980599474,-2.89525166830126,3.24508640095346,-2.73415555507211,-3.58281002008802,-2.13317644293659,0.644549730341658,-2.83487115980611,-3.71744992918956,-7.06074618169306,-0.121653217684609,-3.55198400939375,-6.0677981503786,-6.31970750896333,-6.54624181523522,-6.60046062150676,-7.52436833681058,-7.8335555711125,-7.50211219093686,-1.96530880945923,-1.95980925751416,-2.04216786301424,-3.97652513857503,-3.05121035544102,-13.6913151328525,-5.29061006200618,-4.46628416302479,-11.2981564915382,-11.1412776902967,-11.435623996076,-12.981619145004,-11.6344144245911,-11.5198609264142,-11.589748311433,-12.2653238444006,-13.3866834395246,-13.2151722995049,-12.8881582878915,-12.8056831898117,-13.6081431627279,-12.8357376825339,-13.0740681657723,-12.6959474039839,-12.7806339362021,-14.2266980575287,-13.0094028057641,-14.1101844415457,-3.22678710680364,-4.75830407509117,-4.15583783449678,-6.40337055173194,-5.69992228265959,-4.07758540918968,-4.56525209408734,-7.14219911358407,-7.78135276287243,-2.96199570179906,-4.98092843827312,-1.25028553742691,-5.72681709632961,-1.48124586053984,-2.97526724837752,-0.792937990748917,-2.75579692797163,-3.84391103993778,-3.36401057980002,-0.55054534794377,-0.585778431385528,-0.433393925731893,-3.50579032571994,-3.94238290411726,0.225933803313285,-0.552902906422504,-2.49561924548174,-2.89261176082088,-6.24624318477127,-6.13490688724113,-6.06578236274727,-5.99659592015915,-5.92735916911943,-0.150129182778684,-0.283731283967387,-3.09650359868717,-0.0450882478448673,-3.09509360697848,-2.9966693020716,-2.70501138232752,-5.45960189444545,1.01029102209398,-7.14513662527302,-8.12216107491307,-8.33286306292127,-8.40315026242229,-3.24510859732028,-7.74848004950582,-7.86450647898838,-5.97492543825504,-3.55583492739064,-4.88114292689057,-5.71150474047788,-9.33212806886128,-6.77833138248069,-2.8084555425423,-3.07669858515182,-0.867899742347565,-3.39355348115172,-4.17062288702767,-3.28820356526528,-4.35068531246963,-3.23678401592309,-3.25263359468289,-3.55038539904852,-2.30110989675506,0.169572797878818,-4.15369240632128,-3.83477508791878,-2.12697274994354,-4.83482799462627,-3.9905513318108,-0.0913533730643921,-5.11725920989043,-3.16213595485783,-0.157696445821874,-0.194120466505581,-0.371671945168217,-4.32053577559936,0.264544748886681,-2.85611682977408,-2.65971794652165,-3.95100289197434,-1.7690597207318,0.517567879914365,0.54318725600578,-1.87964382107016,-4.7117686842189,-2.89499040084744,-4.05629261571005,-5.03202838566819,0.324238886093679,-4.99341703829647,-4.68423332514029,0.334532824069685,-3.9433368210052,-3.53865023182429,-2.9989262562074,-1.03963769713185,0.166830707878014,-5.51550707258062,-6.44720227383046,-6.28780335064533,-6.56125741097377,-6.8254901042394,-2.15530254380865,-2.10066651278309,-1.92527812380296,-2.544410418956,-1.02533539256113,-2.15251889070952,-4.62691916410905,-2.23120932812687,-6.26070551479114,-3.8337413849476,0.269561809170344,-1.88617599041763,-2.9328952580311,-5.63894131284807,-8.0991193981365,-8.33770697381781,-8.74597261185534,-0.71347376073502,-3.99521073403213,-8.40966487562735,-8.53775768653457,-6.2133552491157,-6.35388725151755,-5.99567612703198,-5.822449155685,-2.06990438955593,-0.133950251206468,1.987861862693,-3.93629417027159,0.541699242973355,0.369936028027435,-4.15635447965382,-4.72309174576035,-3.37617706712688,-2.8290982053899,-3.71748137540216,-4.09564897273592,-5.56794705115052,-13.540168238225,-12.0111608836062,-11.2350479111446,-11.1821254546586,-12.9654812039222,-13.3207888671784,-11.0923923688428,-13.2025771482197,-12.4389449056023,-14.5331616869738,-12.618162687238,0.912806096143303,-0.357616193093852,-2.85032390160027,-5.66586179854092,-6.62569249371823,-0.870997150804889,1.78592177154007,-4.4318096317282,-4.36310219273296,-6.68368922880726,-8.99381088354112,-6.80713525144464,-7.17534972178322,-7.57563437993936,-5.11072764247853,-7.33437708370839,-6.86850850672582,-6.86416435989436,-4.51390660472333,-4.54693575081085,-4.45800770078481,1.07295520625891,-5.20833459337633,-5.62467713431414,1.7837390603636,-3.51413330486723,-4.54261203828437,0.453505060416619,0.566679814004086,-4.82077941422469,-2.77674714436829,-4.89115620289902,-3.15812700566592,0.0422275201898101,-2.27673307339047,-3.21618771830464,-4.5652600954372,-1.4706452575308,-2.29773425918487,-5.48742458295368,-0.0844995591396119,1.71353755281029,-2.9716952359177,-3.90674573293228,-3.8517216648754,-3.22455914814995,-5.56914249554635,-5.83645272742826,-1.4294901237515,0.0856615347524881,-2.24811517395215,-2.31474716368481,-3.73965947930309,-3.89824038104731,-2.64940583024547,-2.27152578398956,-3.07403431268054,-4.07025686324581,-3.52012767367189,-0.989431189994817,-3.8410981507899,-5.17993471366321,-4.50131480977758,-6.56465926230671,-4.25071651144568,-5.41603688884657,0.217630453611954,-6.42823083022309,-1.34755671450971,-5.11297108805175,-5.16533081830893,-0.159325098707444,-0.0451253297662453,-0.423783865294484,-4.93742665954554,-3.07555830950402,-3.75405392305562,0.955004466801798,-2.73279196653765,-5.6536376856402,-4.61450773315675,-4.40092985049667,-6.54098852025393,-7.04922935969585,-4.06309810827338,-0.628463195272087,-4.85148719411703,-4.91934829935247,-0.887241636246378,-1.44537495699985,-6.28542447506796,-3.20243612238872,-3.41920738405664,-1.87333085278999,-4.81640080035747,-5.17565967956169,-3.89016924226376,-2.63744174460075,-3.23543895742654,-3.26300672553831,0.398155064675901,-4.48548270396242,-2.79633153858609,-0.373927299894818,-3.50892466189359,-4.75993137385013,-3.99178463209724,-4.86874726825181,-3.47341070390428,-2.49756054724841,-2.4112720149303,-2.32511344137919,-2.23906626105695,1.28016674259048,-1.47497416110315,-2.12045759469323,-3.35647371355361,-4.23098383571181,-3.44381902213252,-4.70757080611204,-5.57641879575659,-5.25809597551632,-5.17281182346005,-3.92650993997042,0.228849430580481,0.259411077154011,-5.9548382969224,-6.64615382952148,-5.5334430286147,-1.61361833850235,1.08151398923906,-3.06472953093127,-3.96322447209244,-2.22307032799021,-1.67234597814111,-2.16206139007752,-5.33475387061743,-6.12071508667922,-1.00080505203989,-5.94563397292191,-4.5335154033258,-7.50955747436829,-5.52913123107677,-0.39438126178315,-2.5166280017922,1.33441406239882,0.24931080342673,-4.39084192218279,-5.58779378195338,-3.23215317539514,-3.46389087904573,-5.24598383776964,-0.888721675865145],\"type\":\"box\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(234,234,242)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"rgb(234,234,242)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2},\"colorscale\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(231,231,240)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(183,183,191)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"rgb(67,103,167)\"},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(36,36,36)\",\"ticklen\":8,\"ticks\":\"outside\",\"tickwidth\":2}},\"colorscale\":{\"sequential\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]],\"sequentialminus\":[[0.0,\"rgb(2,4,25)\"],[0.06274509803921569,\"rgb(24,15,41)\"],[0.12549019607843137,\"rgb(47,23,57)\"],[0.18823529411764706,\"rgb(71,28,72)\"],[0.25098039215686274,\"rgb(97,30,82)\"],[0.3137254901960784,\"rgb(123,30,89)\"],[0.3764705882352941,\"rgb(150,27,91)\"],[0.4392156862745098,\"rgb(177,22,88)\"],[0.5019607843137255,\"rgb(203,26,79)\"],[0.5647058823529412,\"rgb(223,47,67)\"],[0.6274509803921569,\"rgb(236,76,61)\"],[0.6901960784313725,\"rgb(242,107,73)\"],[0.7529411764705882,\"rgb(244,135,95)\"],[0.8156862745098039,\"rgb(245,162,122)\"],[0.8784313725490196,\"rgb(246,188,153)\"],[0.9411764705882353,\"rgb(247,212,187)\"],[1.0,\"rgb(250,234,220)\"]]},\"colorway\":[\"rgb(76,114,176)\",\"rgb(221,132,82)\",\"rgb(85,168,104)\",\"rgb(196,78,82)\",\"rgb(129,114,179)\",\"rgb(147,120,96)\",\"rgb(218,139,195)\",\"rgb(140,140,140)\",\"rgb(204,185,116)\",\"rgb(100,181,205)\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"rgb(234,234,242)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"rgb(234,234,242)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"bgcolor\":\"rgb(234,234,242)\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"rgb(234,234,242)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"fillcolor\":\"rgb(67,103,167)\",\"line\":{\"width\":0},\"opacity\":0.5},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"},\"bgcolor\":\"rgb(234,234,242)\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\"}},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.625,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.625,1.0],\"matches\":\"y\",\"showticklabels\":false,\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.375],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0],\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.375],\"matches\":\"y3\",\"showticklabels\":false,\"mirror\":true,\"linewidth\":2,\"linecolor\":\"black\"},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V2 vs Class <br> (Before Outlier Removal)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V2 vs Class <br> (After Outlier Removal)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V10 vs Class <br> (Before Outlier Removal)\",\"x\":0.225,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"V10 vs Class <br> (After Outlier Removal)\",\"x\":0.775,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.375,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"width\":700,\"title\":{\"text\":\"Comparison of Box Plots after outlier removal - V10 & V2\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e54c5607-15e6-4089-8b4e-8cd1eaa7c204');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifier (Undersampling)"
      ],
      "metadata": {
        "id": "T9tB2XiAw_Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Undersampling before cross validation(prove to overfit)\n",
        "X = df_rs.drop('Class', axis=1)\n",
        "y = df_rs['Class']\n",
        "print(\"Shape of X is {} and that of y is {}\".format(X.shape, y.shape))"
      ],
      "metadata": {
        "id": "G1ygYjE5ySWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b5b25ae-dcc3-4b73-f797-6433cf59c4cd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X is (946, 30) and that of y is (946,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saya akan membagi data menggunakan pemisahan uji kereta api sebesar 0,8:0,2 yang berarti set pelatihan memiliki 80% dari catatan dan sisanya 20% dalam set pengujian."
      ],
      "metadata": {
        "id": "rrr7UM1syT9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the data using train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "print('Shape of training set ', X_train.shape)\n",
        "print('Shape of test set ', X_test.shape)"
      ],
      "metadata": {
        "id": "uVFGHTlCyW0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0aa5505-870f-4835-883a-de22763699bb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training set  (756, 30)\n",
            "Shape of test set  (190, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Di bawah ini saya telah menambahkan pengklasifikasi ke kamus untuk membuat pengkodean lebih mudah. Jika ada perubahan yang diperlukan pada pengklasifikasi maka ini adalah satu-satunya tempat yang perlu diubah.\n"
      ],
      "metadata": {
        "id": "TezHl3rjygvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling and Evaluation"
      ],
      "metadata": {
        "id": "Ct2trfY53UbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(targets,predictions):\n",
        "\n",
        "    differences = predictions - targets                       #the DIFFERENCEs.\n",
        "\n",
        "    differences_squared = differences ** 2                    #the SQUAREs of ^\n",
        "\n",
        "    mean_of_differences_squared = differences_squared.mean()  #the MEAN of ^\n",
        "\n",
        "    rmse_val = np.sqrt(mean_of_differences_squared)           #ROOT of ^\n",
        "\n",
        "    return rmse_val  "
      ],
      "metadata": {
        "id": "01FngpCE3YkO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressors = [LinearRegression(),\n",
        "              DummyClassifier(strategy='most_frequent', random_state=0),\n",
        "              LogisticRegression(solver = 'lbfgs', max_iter=1000),\n",
        "              LGBMClassifier(),\n",
        "              XGBClassifier(),\n",
        "              KNeighborsClassifier(3),\n",
        "              DecisionTreeClassifier(),\n",
        "              RandomForestClassifier(),\n",
        "              AdaBoostClassifier(),\n",
        "              GradientBoostingClassifier(),\n",
        "              GaussianNB()\n",
        "              ]\n",
        "\n",
        "df = pd.DataFrame(columns = ['Method', 'MAE', 'RMSE', 'R2 Score'])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "trQQUNiu4oPq",
        "outputId": "05683ca1-aa71-4afb-beec-3787987ca102"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Method, MAE, RMSE, R2 Score]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24bba934-64c1-45fd-9637-07e81c7dc763\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>MAE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24bba934-64c1-45fd-9637-07e81c7dc763')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24bba934-64c1-45fd-9637-07e81c7dc763 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24bba934-64c1-45fd-9637-07e81c7dc763');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regressors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1u5dcdI5XiG",
        "outputId": "38ee17fb-95ca-4f81-9f75-1eab42ff935f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[LinearRegression(),\n",
              " DummyClassifier(random_state=0, strategy='most_frequent'),\n",
              " LogisticRegression(max_iter=1000),\n",
              " LGBMClassifier(),\n",
              " XGBClassifier(),\n",
              " KNeighborsClassifier(n_neighbors=3),\n",
              " DecisionTreeClassifier(),\n",
              " RandomForestClassifier(),\n",
              " AdaBoostClassifier(),\n",
              " GradientBoostingClassifier(),\n",
              " GaussianNB()]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for regressor in regressors:\n",
        "    print(regressor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uElZWvb5Zpw",
        "outputId": "e47d73a2-19c3-433c-c9c2-b9fa4a203aa7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression()\n",
            "DummyClassifier(random_state=0, strategy='most_frequent')\n",
            "LogisticRegression(max_iter=1000)\n",
            "LGBMClassifier()\n",
            "XGBClassifier()\n",
            "KNeighborsClassifier(n_neighbors=3)\n",
            "DecisionTreeClassifier()\n",
            "RandomForestClassifier()\n",
            "AdaBoostClassifier()\n",
            "GradientBoostingClassifier()\n",
            "GaussianNB()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for regressor in regressors:\n",
        "    regressor.fit(X_train, y_train)\n",
        "    y_pred = regressor.predict(X_test)\n",
        "    \n",
        "    method = str(type(regressor)).split('.')[-1][:-2]\n",
        "    \n",
        "    # MAE score\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    \n",
        "    #RMSE Score\n",
        "    rmse_value = rmse(y_test, y_pred)\n",
        "    \n",
        "    #R2 Score\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    \n",
        "    df = df.append({'Method': method, \n",
        "                    'MAE': mae, \n",
        "                    'RMSE': rmse_value,\n",
        "                    'R2 Score': r2},\n",
        "                     ignore_index=True)\n"
      ],
      "metadata": {
        "id": "d4NrZF6Qy5XL"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "n2cPKuyTzDjj",
        "outputId": "2186dc97-8632-4b52-b5da-d37b6e614933"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        Method       MAE      RMSE  R2 Score\n",
              "0             LinearRegression  0.251781  0.328051  0.569483\n",
              "1              DummyClassifier  0.505263  0.710819 -1.021277\n",
              "2           LogisticRegression  0.057895  0.240613  0.768395\n",
              "3               LGBMClassifier  0.073684  0.271448  0.705230\n",
              "4                XGBClassifier  0.078947  0.280976  0.684176\n",
              "5         KNeighborsClassifier  0.052632  0.229416  0.789450\n",
              "6       DecisionTreeClassifier  0.100000  0.316228  0.599956\n",
              "7       RandomForestClassifier  0.063158  0.251312  0.747340\n",
              "8           AdaBoostClassifier  0.073684  0.271448  0.705230\n",
              "9   GradientBoostingClassifier  0.084211  0.290191  0.663121\n",
              "10                  GaussianNB  0.115789  0.340279  0.536791"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-187c2c4d-cec3-4b0c-8a53-ceed85e57f94\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Method</th>\n",
              "      <th>MAE</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>R2 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LinearRegression</td>\n",
              "      <td>0.251781</td>\n",
              "      <td>0.328051</td>\n",
              "      <td>0.569483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DummyClassifier</td>\n",
              "      <td>0.505263</td>\n",
              "      <td>0.710819</td>\n",
              "      <td>-1.021277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.057895</td>\n",
              "      <td>0.240613</td>\n",
              "      <td>0.768395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LGBMClassifier</td>\n",
              "      <td>0.073684</td>\n",
              "      <td>0.271448</td>\n",
              "      <td>0.705230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.078947</td>\n",
              "      <td>0.280976</td>\n",
              "      <td>0.684176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.229416</td>\n",
              "      <td>0.789450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.316228</td>\n",
              "      <td>0.599956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.063158</td>\n",
              "      <td>0.251312</td>\n",
              "      <td>0.747340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.073684</td>\n",
              "      <td>0.271448</td>\n",
              "      <td>0.705230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.084211</td>\n",
              "      <td>0.290191</td>\n",
              "      <td>0.663121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>0.115789</td>\n",
              "      <td>0.340279</td>\n",
              "      <td>0.536791</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-187c2c4d-cec3-4b0c-8a53-ceed85e57f94')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-187c2c4d-cec3-4b0c-8a53-ceed85e57f94 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-187c2c4d-cec3-4b0c-8a53-ceed85e57f94');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dari tabel diatas kita dapat lihat bahwa model Kneighbours , Logistic regresion dan Random Forest regression memiliki nilai MAE dan RMSE yang cukup kecil (itu menandapakn baik)"
      ],
      "metadata": {
        "id": "FtmLCnW-zk9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressors = [DummyClassifier(strategy='most_frequent', random_state=0),\n",
        "              LogisticRegression(solver = 'lbfgs', max_iter=1000),\n",
        "              LGBMClassifier(),\n",
        "              XGBClassifier(),\n",
        "              KNeighborsClassifier(3),\n",
        "              DecisionTreeClassifier(),\n",
        "              RandomForestClassifier(),\n",
        "              AdaBoostClassifier(),\n",
        "              GradientBoostingClassifier(),\n",
        "              GaussianNB()\n",
        "              ]\n",
        "\n",
        "df_result = pd.DataFrame(columns=['Model', 'tp', 'tn', 'fp', 'fn', 'correct', 'incorrect',\n",
        "                                  'accuracy', 'precision', 'recall', 'f1', 'roc_auc','avg_pre'])\n",
        "df_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "1OsfM11383Qp",
        "outputId": "eba405f0-4da6-4d9a-d094-0d78d22853f2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Model, tp, tn, fp, fn, correct, incorrect, accuracy, precision, recall, f1, roc_auc, avg_pre]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ced423ac-c556-41dc-abdf-ff682c0501b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>tp</th>\n",
              "      <th>tn</th>\n",
              "      <th>fp</th>\n",
              "      <th>fn</th>\n",
              "      <th>correct</th>\n",
              "      <th>incorrect</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>roc_auc</th>\n",
              "      <th>avg_pre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ced423ac-c556-41dc-abdf-ff682c0501b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ced423ac-c556-41dc-abdf-ff682c0501b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ced423ac-c556-41dc-abdf-ff682c0501b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regressors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ke1A5Fh_9LGy",
        "outputId": "b442d8c2-a66e-49f3-9c28-3317d8ad1b1e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DummyClassifier(random_state=0, strategy='most_frequent'),\n",
              " LogisticRegression(max_iter=1000),\n",
              " LGBMClassifier(),\n",
              " XGBClassifier(),\n",
              " KNeighborsClassifier(n_neighbors=3),\n",
              " DecisionTreeClassifier(),\n",
              " RandomForestClassifier(),\n",
              " AdaBoostClassifier(),\n",
              " GradientBoostingClassifier(),\n",
              " GaussianNB()]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for regressor in regressors:\n",
        "    print(regressor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG1UaL6k9Ojz",
        "outputId": "b48b24d2-b46f-4098-a06e-8ad2415640d1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DummyClassifier(random_state=0, strategy='most_frequent')\n",
            "LogisticRegression(max_iter=1000)\n",
            "LGBMClassifier()\n",
            "XGBClassifier()\n",
            "KNeighborsClassifier(n_neighbors=3)\n",
            "DecisionTreeClassifier()\n",
            "RandomForestClassifier()\n",
            "AdaBoostClassifier()\n",
            "GradientBoostingClassifier()\n",
            "GaussianNB()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for regressor in regressors:\n",
        "    regressor.fit(X_train, y_train)\n",
        "    y_pred = regressor.predict(X_test)\n",
        "    \n",
        "    method = str(type(regressor)).split('.')[-1][:-2]\n",
        "    \n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)\n",
        "    avg_precision = average_precision_score(y_test, y_pred)\n",
        "    \n",
        "    row = {'model': method,\n",
        "        'tp': tp,\n",
        "        'tn': tn,\n",
        "        'fp': fp,\n",
        "        'fn': fn,\n",
        "        'correct': tp+tn,\n",
        "        'incorrect': fp+fn,\n",
        "        'accuracy': round(accuracy,3),\n",
        "        'precision': round(precision,3),\n",
        "        'recall': round(recall,3),\n",
        "        'f1': round(f1,3),\n",
        "        'roc_auc': round(roc_auc,3),\n",
        "        'avg_pre': round(avg_precision,3),\n",
        "    }\n",
        "\n",
        "    df_result = df_result.append(row, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "nSbEX0Zg9T8U"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "60omM0lt-xWP",
        "outputId": "48f730ac-b550-47eb-d896-9cc47fdc3241"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         model  tp  tn  fp  fn correct incorrect  accuracy  \\\n",
              "0                   GaussianNB  76  92   4  18     168        22     0.884   \n",
              "1              DummyClassifier  94   0  96   0      94        96     0.495   \n",
              "2           LogisticRegression  85  94   2   9     179        11     0.942   \n",
              "3               LGBMClassifier  83  93   3  11     176        14     0.926   \n",
              "4                XGBClassifier  82  93   3  12     175        15     0.921   \n",
              "5         KNeighborsClassifier  86  94   2   8     180        10     0.947   \n",
              "6       DecisionTreeClassifier  82  87   9  12     169        21     0.889   \n",
              "7       RandomForestClassifier  81  94   2  13     175        15     0.921   \n",
              "8           AdaBoostClassifier  84  92   4  10     176        14     0.926   \n",
              "9   GradientBoostingClassifier  82  92   4  12     174        16     0.916   \n",
              "10                  GaussianNB  76  92   4  18     168        22     0.884   \n",
              "\n",
              "    precision  recall     f1  roc_auc  avg_pre  \n",
              "0       0.950   0.809  0.874    0.883    0.863  \n",
              "1       0.495   1.000  0.662    0.500    0.495  \n",
              "2       0.977   0.904  0.939    0.942    0.931  \n",
              "3       0.965   0.883  0.922    0.926    0.910  \n",
              "4       0.965   0.872  0.916    0.921    0.905  \n",
              "5       0.977   0.915  0.945    0.947    0.936  \n",
              "6       0.901   0.872  0.886    0.889    0.849  \n",
              "7       0.976   0.862  0.915    0.920    0.909  \n",
              "8       0.955   0.894  0.923    0.926    0.906  \n",
              "9       0.953   0.872  0.911    0.915    0.895  \n",
              "10      0.950   0.809  0.874    0.883    0.863  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3491d516-4095-47b0-901d-6f01392d944c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>tp</th>\n",
              "      <th>tn</th>\n",
              "      <th>fp</th>\n",
              "      <th>fn</th>\n",
              "      <th>correct</th>\n",
              "      <th>incorrect</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>roc_auc</th>\n",
              "      <th>avg_pre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>76</td>\n",
              "      <td>92</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>168</td>\n",
              "      <td>22</td>\n",
              "      <td>0.884</td>\n",
              "      <td>0.950</td>\n",
              "      <td>0.809</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.883</td>\n",
              "      <td>0.863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DummyClassifier</td>\n",
              "      <td>94</td>\n",
              "      <td>0</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>94</td>\n",
              "      <td>96</td>\n",
              "      <td>0.495</td>\n",
              "      <td>0.495</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.662</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>85</td>\n",
              "      <td>94</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>179</td>\n",
              "      <td>11</td>\n",
              "      <td>0.942</td>\n",
              "      <td>0.977</td>\n",
              "      <td>0.904</td>\n",
              "      <td>0.939</td>\n",
              "      <td>0.942</td>\n",
              "      <td>0.931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LGBMClassifier</td>\n",
              "      <td>83</td>\n",
              "      <td>93</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>176</td>\n",
              "      <td>14</td>\n",
              "      <td>0.926</td>\n",
              "      <td>0.965</td>\n",
              "      <td>0.883</td>\n",
              "      <td>0.922</td>\n",
              "      <td>0.926</td>\n",
              "      <td>0.910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>82</td>\n",
              "      <td>93</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>175</td>\n",
              "      <td>15</td>\n",
              "      <td>0.921</td>\n",
              "      <td>0.965</td>\n",
              "      <td>0.872</td>\n",
              "      <td>0.916</td>\n",
              "      <td>0.921</td>\n",
              "      <td>0.905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>86</td>\n",
              "      <td>94</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>180</td>\n",
              "      <td>10</td>\n",
              "      <td>0.947</td>\n",
              "      <td>0.977</td>\n",
              "      <td>0.915</td>\n",
              "      <td>0.945</td>\n",
              "      <td>0.947</td>\n",
              "      <td>0.936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>82</td>\n",
              "      <td>87</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>169</td>\n",
              "      <td>21</td>\n",
              "      <td>0.889</td>\n",
              "      <td>0.901</td>\n",
              "      <td>0.872</td>\n",
              "      <td>0.886</td>\n",
              "      <td>0.889</td>\n",
              "      <td>0.849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>81</td>\n",
              "      <td>94</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>175</td>\n",
              "      <td>15</td>\n",
              "      <td>0.921</td>\n",
              "      <td>0.976</td>\n",
              "      <td>0.862</td>\n",
              "      <td>0.915</td>\n",
              "      <td>0.920</td>\n",
              "      <td>0.909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>84</td>\n",
              "      <td>92</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>176</td>\n",
              "      <td>14</td>\n",
              "      <td>0.926</td>\n",
              "      <td>0.955</td>\n",
              "      <td>0.894</td>\n",
              "      <td>0.923</td>\n",
              "      <td>0.926</td>\n",
              "      <td>0.906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>82</td>\n",
              "      <td>92</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>174</td>\n",
              "      <td>16</td>\n",
              "      <td>0.916</td>\n",
              "      <td>0.953</td>\n",
              "      <td>0.872</td>\n",
              "      <td>0.911</td>\n",
              "      <td>0.915</td>\n",
              "      <td>0.895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>76</td>\n",
              "      <td>92</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>168</td>\n",
              "      <td>22</td>\n",
              "      <td>0.884</td>\n",
              "      <td>0.950</td>\n",
              "      <td>0.809</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.883</td>\n",
              "      <td>0.863</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3491d516-4095-47b0-901d-6f01392d944c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3491d516-4095-47b0-901d-6f01392d944c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3491d516-4095-47b0-901d-6f01392d944c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dari model performance model diatas kita pilih 3 model terbaik  dengan nilai presisi yang tinggi yaitu : logistic regression, kneighbours classifier dan random forest classifier"
      ],
      "metadata": {
        "id": "7EuRliPMAu1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuning Hyperparameter"
      ],
      "metadata": {
        "id": "sWXxAuN63v35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper Parameter Tunning Logistic Regression"
      ],
      "metadata": {
        "id": "qsA0WoDTCKyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Undersampling before cross validation\n",
        "X = df_rs.drop('Class', axis=1)\n",
        "y = df_rs['Class']\n",
        "\n",
        "#Split the data using train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n"
      ],
      "metadata": {
        "id": "GY0q6-ysDHe_"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#List Hyperparameters yang akan diuji\n",
        "penalty = ['l1', 'l2']\n",
        "C = np.logspace(-4,4,20)\n",
        "#Menjadikan ke dalam bentuk dictionary\n",
        "hyperparameters = dict(penalty=penalty, C=C)\n",
        "#Membuat Object Logistic Regression\n",
        "logreg = LogisticRegression()\n",
        "#Memasukan ke Grid Search\n",
        "#CV itu Cross Validation\n",
        "#Menggunakan 10-Fold CV\n",
        "clf = GridSearchCV(logreg, hyperparameters, cv=10)\n",
        "#Fitting Model\n",
        "best_model = clf.fit(X,y)\n",
        "#Nilai hyperparameters terbaik\n",
        "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
        "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
        "#Prediksi menggunakan model baru\n",
        "y_pred = best_model.predict(X_test)\n",
        "#Check performa dari model\n",
        "print(classification_report(y_test, y_pred))\n",
        "roc_auc_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrFTDEWdCQJt",
        "outputId": "a4f97184-c748-4212-99d5-bc164e3a3808"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning:\n",
            "\n",
            "\n",
            "200 fits failed out of a total of 400.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "200 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning:\n",
            "\n",
            "One or more of the test scores are non-finite: [       nan 0.89427772        nan 0.90380739        nan 0.90909295\n",
            "        nan 0.92070549        nan 0.92706607        nan 0.93552072\n",
            "        nan 0.93866741        nan 0.93866741        nan 0.93234043\n",
            "        nan 0.92708847        nan 0.92604703        nan 0.9249944\n",
            "        nan 0.93129899        nan 0.93975364        nan 0.93868981\n",
            "        nan 0.93868981        nan 0.93868981        nan 0.93974244\n",
            "        nan 0.93974244        nan 0.93868981]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Penalty: l2\n",
            "Best C: 29.763514416313132\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96        96\n",
            "           1       1.00      0.91      0.96        94\n",
            "\n",
            "    accuracy                           0.96       190\n",
            "   macro avg       0.96      0.96      0.96       190\n",
            "weighted avg       0.96      0.96      0.96       190\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9574468085106382"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the confusion matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,7))\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=best_model.best_estimator_.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                             display_labels=best_model.best_estimator_.classes_)\n",
        "disp.plot(ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "JJh8PTwKFutN",
        "outputId": "d8487e90-953f-4ada-d569-3e6734da7170"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "setelah di tuning model logistic regresion mengalami peningkatan, diantaranya\n",
        "1. Precision dari 97.7% menjadi 99.9%\n",
        "2. F1 score dari 93.3% menjadi 96%\n",
        "\n"
      ],
      "metadata": {
        "id": "boVj-QfAHsVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparamater Tuning KNN"
      ],
      "metadata": {
        "id": "bxafBO2JKzEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Undersampling before cross validation\n",
        "X = df_rs.drop('Class', axis=1)\n",
        "y = df_rs['Class']\n",
        "\n",
        "#Split the data using train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "knn_clf = KNeighborsClassifier()"
      ],
      "metadata": {
        "id": "Xlui7-yjLBlf"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {\n",
        "    'n_neighbors': (2,3,4,5,6,7,8)\n",
        "}\n",
        "\n",
        "knn_clf_gridcv = GridSearchCV(knn_clf, parameters, cv=5, scoring='precision')\n",
        "knn_clf_gridcv.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Et-3hSLZLFkY",
        "outputId": "4a2be248-075b-4bc5-f751-98250c334d50"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
              "             param_grid={'n_neighbors': (2, 3, 4, 5, 6, 7, 8)},\n",
              "             scoring='precision')"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the compact results\n",
        "cv_result = pd.DataFrame(knn_clf_gridcv.cv_results_)\n",
        "retain_cols = ['params','mean_test_score','rank_test_score']\n",
        "cv_result[retain_cols]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "KO4cwX9DLZX3",
        "outputId": "2b62b176-1bdf-4397-8c21-a37804bac31d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               params  mean_test_score  rank_test_score\n",
              "0  {'n_neighbors': 2}         0.982160                6\n",
              "1  {'n_neighbors': 3}         0.974201                7\n",
              "2  {'n_neighbors': 4}         0.988190                2\n",
              "3  {'n_neighbors': 5}         0.988321                1\n",
              "4  {'n_neighbors': 6}         0.988190                2\n",
              "5  {'n_neighbors': 7}         0.985462                5\n",
              "6  {'n_neighbors': 8}         0.988146                4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ffbc2cc1-cf41-4619-9cd8-5bedb05e0ec0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'n_neighbors': 2}</td>\n",
              "      <td>0.982160</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'n_neighbors': 3}</td>\n",
              "      <td>0.974201</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'n_neighbors': 4}</td>\n",
              "      <td>0.988190</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'n_neighbors': 5}</td>\n",
              "      <td>0.988321</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'n_neighbors': 6}</td>\n",
              "      <td>0.988190</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'n_neighbors': 7}</td>\n",
              "      <td>0.985462</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>{'n_neighbors': 8}</td>\n",
              "      <td>0.988146</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffbc2cc1-cf41-4619-9cd8-5bedb05e0ec0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ffbc2cc1-cf41-4619-9cd8-5bedb05e0ec0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ffbc2cc1-cf41-4619-9cd8-5bedb05e0ec0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what if we also want to tune \"weights\" hyperparameter\n",
        "# \"uniform\": all K neighbors have the same influence\n",
        "# \"distance\": closer neighbor in those K neighbors has stronger influence\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {\n",
        "    'n_neighbors': (2,3,4,5,6,7,8),\n",
        "    'weights':('uniform','distance')\n",
        "}\n",
        "\n",
        "# now we use recall (sensitivity) as metric\n",
        "knn_clf_gridcv = GridSearchCV(knn_clf, parameters, cv=5, scoring='precision')\n",
        "knn_clf_gridcv.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqCHRQG_LguG",
        "outputId": "b67b1c8d-3ca1-404d-86c9-b5c0c3cb6550"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
              "             param_grid={'n_neighbors': (2, 3, 4, 5, 6, 7, 8),\n",
              "                         'weights': ('uniform', 'distance')},\n",
              "             scoring='precision')"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the results\n",
        "cv_result = pd.DataFrame(knn_clf_gridcv.cv_results_)\n",
        "retain_cols = ['params','mean_test_score','rank_test_score']\n",
        "cv_result[retain_cols].sort_values('rank_test_score')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "jUrNhgPfM9b1",
        "outputId": "c50433bb-a34f-4325-e0c0-3be3d7d2fe40"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       params  mean_test_score  \\\n",
              "6    {'n_neighbors': 5, 'weights': 'uniform'}         0.988321   \n",
              "7   {'n_neighbors': 5, 'weights': 'distance'}         0.988321   \n",
              "13  {'n_neighbors': 8, 'weights': 'distance'}         0.988278   \n",
              "4    {'n_neighbors': 4, 'weights': 'uniform'}         0.988190   \n",
              "8    {'n_neighbors': 6, 'weights': 'uniform'}         0.988190   \n",
              "12   {'n_neighbors': 8, 'weights': 'uniform'}         0.988146   \n",
              "10   {'n_neighbors': 7, 'weights': 'uniform'}         0.985462   \n",
              "11  {'n_neighbors': 7, 'weights': 'distance'}         0.985462   \n",
              "9   {'n_neighbors': 6, 'weights': 'distance'}         0.985337   \n",
              "0    {'n_neighbors': 2, 'weights': 'uniform'}         0.982160   \n",
              "2    {'n_neighbors': 3, 'weights': 'uniform'}         0.974201   \n",
              "3   {'n_neighbors': 3, 'weights': 'distance'}         0.974201   \n",
              "5   {'n_neighbors': 4, 'weights': 'distance'}         0.973996   \n",
              "1   {'n_neighbors': 2, 'weights': 'distance'}         0.932886   \n",
              "\n",
              "    rank_test_score  \n",
              "6                 1  \n",
              "7                 1  \n",
              "13                3  \n",
              "4                 4  \n",
              "8                 4  \n",
              "12                6  \n",
              "10                7  \n",
              "11                7  \n",
              "9                 9  \n",
              "0                10  \n",
              "2                11  \n",
              "3                11  \n",
              "5                13  \n",
              "1                14  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b78b388-2b5c-4b0d-b49b-21ef36725da2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>{'n_neighbors': 5, 'weights': 'uniform'}</td>\n",
              "      <td>0.988321</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>{'n_neighbors': 5, 'weights': 'distance'}</td>\n",
              "      <td>0.988321</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>{'n_neighbors': 8, 'weights': 'distance'}</td>\n",
              "      <td>0.988278</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'n_neighbors': 4, 'weights': 'uniform'}</td>\n",
              "      <td>0.988190</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>{'n_neighbors': 6, 'weights': 'uniform'}</td>\n",
              "      <td>0.988190</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>{'n_neighbors': 8, 'weights': 'uniform'}</td>\n",
              "      <td>0.988146</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>{'n_neighbors': 7, 'weights': 'uniform'}</td>\n",
              "      <td>0.985462</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>{'n_neighbors': 7, 'weights': 'distance'}</td>\n",
              "      <td>0.985462</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>{'n_neighbors': 6, 'weights': 'distance'}</td>\n",
              "      <td>0.985337</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'n_neighbors': 2, 'weights': 'uniform'}</td>\n",
              "      <td>0.982160</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'n_neighbors': 3, 'weights': 'uniform'}</td>\n",
              "      <td>0.974201</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'n_neighbors': 3, 'weights': 'distance'}</td>\n",
              "      <td>0.974201</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'n_neighbors': 4, 'weights': 'distance'}</td>\n",
              "      <td>0.973996</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'n_neighbors': 2, 'weights': 'distance'}</td>\n",
              "      <td>0.932886</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b78b388-2b5c-4b0d-b49b-21ef36725da2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b78b388-2b5c-4b0d-b49b-21ef36725da2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b78b388-2b5c-4b0d-b49b-21ef36725da2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting confusion matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,7))\n",
        "y_pred = knn_clf_gridcv.best_estimator_.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=knn_clf_gridcv.best_estimator_.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                             display_labels=knn_clf_gridcv.best_estimator_.classes_)\n",
        "disp.plot(ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "crf-qEc8NFr9",
        "outputId": "be8c93ce-d1c4-4023-c380-73bedbba1e91"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# classification report\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = knn_clf_gridcv.best_estimator_.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouj1ZPy7NNQR",
        "outputId": "f851d2ff-b8e4-4db1-afab-4ce11b65cbe4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.99      0.95        96\n",
            "           1       0.99      0.91      0.95        94\n",
            "\n",
            "    accuracy                           0.95       190\n",
            "   macro avg       0.96      0.95      0.95       190\n",
            "weighted avg       0.96      0.95      0.95       190\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dari hasil tuing KNN classifier dapat dilihat, diantaranya \n",
        "1. Precision meningkat dari 97,7% menjadi 99%\n",
        "2. F1 score meningkat dari 94.5% menjadi 95%\n"
      ],
      "metadata": {
        "id": "8GMvn7wyNQq_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning Random Forrest"
      ],
      "metadata": {
        "id": "brVupQUmN2mR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Undersampling before cross validation\n",
        "X = df_rs.drop('Class', axis=1)\n",
        "y = df_rs['Class']\n",
        "\n",
        "#Split the data using train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
      ],
      "metadata": {
        "id": "ubUmrqelNQR2"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define random forest classifier model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_clf = RandomForestClassifier(random_state=42)"
      ],
      "metadata": {
        "id": "sW7jwnxbOCFN"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# using random search CV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "parameters = {\n",
        "    'n_estimators': (10,20,30,40,50),\n",
        "    'max_depth':(1,2,3,4,5)\n",
        "}\n",
        "\n",
        "rf_clf_randomcv = RandomizedSearchCV(rf_clf, parameters, cv=5, \n",
        "                                     scoring='precision', n_iter=10)\n",
        "rf_clf_randomcv.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcjElsiVODyb",
        "outputId": "dd07797a-234a-411e-c0c3-c2891c2a0c15"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.54 s, sys: 10.8 ms, total: 3.55 s\n",
            "Wall time: 3.55 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the confusion matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,7))\n",
        "y_pred = rf_clf_randomcv.best_estimator_.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=rf_clf_randomcv.best_estimator_.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                             display_labels=rf_clf_randomcv.best_estimator_.classes_)\n",
        "disp.plot(ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "pkeyGeXvOaZN",
        "outputId": "f885fb6b-ab54-4635-dc02-65c3fb787d75"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# classification report\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = rf_clf_randomcv.best_estimator_.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwYkuNfYOdG_",
        "outputId": "44ebdd64-c907-4801-cef3-fe34f977f7b2"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91        96\n",
            "           1       1.00      0.80      0.89        94\n",
            "\n",
            "    accuracy                           0.90       190\n",
            "   macro avg       0.92      0.90      0.90       190\n",
            "weighted avg       0.92      0.90      0.90       190\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dari hasil tuning random forest didapat bahwa,\n",
        "1. Precision meningkat dari 97,6% menjadi 99%\n",
        "2. F1-score menurun dari 91,5% menjadi 89%"
      ],
      "metadata": {
        "id": "epjbOzPsOhK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Importance"
      ],
      "metadata": {
        "id": "Oer_HKX0TpDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "param_grid = [\n",
        "{'n_estimators': [10, 25], 'max_features': [5, 10], \n",
        " 'max_depth': [10, 50, None], 'bootstrap': [True, False]}\n",
        "]\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "grid_search_forest = GridSearchCV(rf, param_grid, cv=10, scoring='precision')\n",
        "grid_search_forest.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeZvU-cISGbk",
        "outputId": "09e181e7-3ee1-4bc9-be7c-0847b30eb847"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;30;43mOutput streaming akan dipotong hingga 5000 baris terakhir.\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:774: UserWarning:\n",
            "\n",
            "Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 221, in __call__\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1765, in precision_score\n",
            "    zero_division=zero_division,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\", line 95, in _check_targets\n",
            "    type_true, type_pred\n",
            "ValueError: Classification metrics can't handle a mix of binary and continuous targets\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning:\n",
            "\n",
            "One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, estimator=RandomForestRegressor(),\n",
              "             param_grid=[{'bootstrap': [True, False],\n",
              "                          'max_depth': [10, 50, None], 'max_features': [5, 10],\n",
              "                          'n_estimators': [10, 25]}],\n",
              "             scoring='precision')"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search_forest.best_estimator_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O35KZ1eySh72",
        "outputId": "f2865bb8-552b-4b5f-802d-aefc88475bf6"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(max_depth=10, max_features=5, n_estimators=10)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(n_estimators=10,max_features=5)\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "8j_Ls77BSp_A"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
        "                                   index = X.columns,\n",
        "                                   columns=['importance']).sort_values('importance', ascending=False)\n",
        "feature_importances\n",
        "\n",
        "fig, ax = plt.subplots(1,1, figsize=(10,15))\n",
        "sns.barplot(x='importance', y='index', color='#800000',data=feature_importances.reset_index())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "ntOX7fcGStwW",
        "outputId": "7347231b-d4c2-403b-c727-4b5cb1de1e2b"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9b0840a2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x1080 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Insight"
      ],
      "metadata": {
        "id": "8ZkiAujQ_Qgv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. Transaksi fraud terjadi selama 2 hari\n",
        "2. Transaksi fraud terjadi 473 kali dengan total 58.591,39 dollar \n",
        "3. Feature V2, V4, V11 & V19 memiliki korelasi possitif dengan Fraud\n",
        "Feature V10, V12, V14, V17 memiliki korelasi negatif dengan Fraud\n",
        "4. Top 5 feature Importance V14, V10, V16, V11, V3 paling berpengaruh terhadap fraud\n",
        "5. Model terbaik kita logistic regression (undersampling) memiliki presicion 99,9%. \n",
        "dengan benar dapat memprediksi 96 dari 104  fraud di dalam kumpulan data 284,795. dan tidak salah menandai fraud ketika orang-orang tidak curang.\n",
        "6. Berdasarkan  rata-rata  nilai transaksi fraud $ 123,87  sekali transaksi.\n",
        "Model kita dapat menghemat dana bank $5.945,76 per hari , dan $2.170.202,4 per tahun. "
      ],
      "metadata": {
        "id": "LYxa2YlTZtFh"
      }
    }
  ]
}